<html class="js" lang="en">
 <head>
  <link as="font" crossorigin="" href="/static/fonts/HardingText-Regular-Web-cecd90984f.woff2" rel="preload" type="font/woff2"/>
  <title>
   Mastering the game of Go without human knowledge | Nature
  </title>
  <script id="save-data-connection-testing">
   function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
  </script>
  <script data-consent="www-nature-com.proxy.lib.ohio-state.edu" src="/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js">
  </script>
  <link crossorigin="" href="https://push-content.springernature.io" rel="preconnect"/>
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="pc,mobile" name="applicable-device"/>
  <meta content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes" name="viewport"/>
  <meta content="5a2dc4ab3fcb9b0393241ffbbb490480" name="360-site-verification"/>
  <script data-test="dataLayer">
   window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"computational-science;computer-science;reward","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/nature24270"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["David Silver","Julian Schrittwieser","Karen Simonyan","Ioannis Antonoglou","Aja Huang","Arthur Guez","Thomas Hubert","Lucas Baker","Matthew Lai","Adrian Bolton","Yutian Chen","Timothy Lillicrap","Fan Hui","Laurent Sifre","George van den Driessche","Thore Graepel","Demis Hassabis"],"publishedAt":1508371200,"publishedAtString":"2017-10-19","title":"Mastering the game of Go without human knowledge","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"nature","title":"nature","volume":"550","issue":"7676"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        ga4ServerUrl: 'https://collect-nature-com.proxy.lib.ohio-state.edu',
        imprint: 'nature'
    });
  </script>
  <script>
   (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
  </script>
  <style>
   @media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-editorial-summary__container .c-article-editorial-summary__button:focus{outline:3px solid #fece3e;will-change:transform}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:16px}.c-recommendations-title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.24;margin:0;padding-bottom:16px}.c-recommendations-close{background-color:transparent;border:0;cursor:pointer;height:2em;margin-right:-10px;margin-top:-5px;width:2em}.c-recommendations-authors{line-height:1.24;margin:0}.c-recommendations-list-container{position:relative}.c-recommendations-list{display:flex;flex-wrap:nowrap;justify-content:space-between;margin:0 auto;overflow-x:hidden;padding:0 0 16px;scroll-behavior:smooth;scroll-snap-type:x mandatory;width:calc(100% - 128px)}@media only screen and (max-width:539px){.c-recommendations-list{display:block;height:40vh;overflow-y:auto;width:100%}}.c-recommendations-list__item{display:flex;flex:0 0 calc(33.3333% - 24px);margin:0 24px 0 0;scroll-snap-align:center}@media only screen and (max-width:539px){.c-recommendations-list__item{margin:0;padding:0 0 16px}}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 16px 0 0;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #d5d5d5;height:auto;min-height:0;position:relative;transform:translateY(0)}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:#069;text-decoration:none}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}@media only screen and (max-width:539px){.c-recommendations-column-switch{display:flex;flex-direction:column-reverse}}.js-greyout-page-background{background-color:rgba(34,34,34,.75);bottom:0;left:0;position:fixed;right:0;top:0}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a{color:inherit}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px;padding:0}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:540px){.u-hide-at-sm{display:none;visibility:hidden}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-display-flex{display:flex;width:100%}.u-flex-direction-column{flex-direction:column}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px} }
  </style>
  <link data-inline-css-source="critical-css" data-test="critical-css-handler" href="/static/css/enhanced-article-nature-branded-30b9d5ba44.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null" rel="stylesheet"/>
  <noscript>
   <link href="/static/css/enhanced-article-nature-branded-30b9d5ba44.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)" rel="stylesheet" type="text/css"/>
  </noscript>
  <link href="/static/css/article-print-122346e276.css" media="print" rel="stylesheet" type="text/css"/>
  <link href="/static/images/favicons/nature/apple-touch-icon-f39cb19454.png" rel="apple-touch-icon" sizes="180x180"/>
  <link href="/static/images/favicons/nature/favicon-32x32-3fe59ece92.png" rel="icon" sizes="32x32" type="image/png"/>
  <link href="/static/images/favicons/nature/favicon-16x16-951651ab72.png" rel="icon" sizes="16x16" type="image/png"/>
  <link crossorigin="use-credentials" href="/static/manifest.json" rel="manifest"/>
  <link color="#000000" href="/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg" rel="mask-icon"/>
  <link href="/static/images/favicons/nature/favicon.ico" rel="shortcut icon"/>
  <meta content="#000000" name="msapplication-TileColor"/>
  <meta content="/static/browserconfig.xml" name="msapplication-config"/>
  <meta content="#000000" name="theme-color"/>
  <meta content="Nature" name="application-name"/>
  <script>
   (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
  </script>
  <!-- Google Tag Manager -->
  <script data-test="gtm-head">
   window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
  </script>
  <!-- End Google Tag Manager -->
  <script>
   (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp-static-nature-com.proxy.lib.ohio-state.edu/production_live/consent-bundle-8-23.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp-static-nature-com.proxy.lib.ohio-state.edu/production_live/consent-bundle-8-23.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
  </script>
  <script id="js-position0">
   (function(w, d) {
        w.idpVerifyPrefix = 'https://verify-nature-com.proxy.lib.ohio-state.edu';
        w.ra21Host = 'https://wayf-springernature-com.proxy.lib.ohio-state.edu';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        var polyfillsUrl = function() {
            var features = {
                'IntersectionObserver': window.IntersectionObserver,
                'Promise': window.Promise,
                'URLSearchParams': window.URLSearchParams,
                'Symbol.iterator': window.Symbol && Symbol.iterator,
                'Array.from': Array.from,
                'Array.prototype.includes': Array.prototype.includes,
                'Array.prototype.find': Array.prototype.find,
                'Array.prototype.forEach': Array.prototype.forEach,
                'NodeList.prototype.forEach': NodeList.prototype.forEach,
                'Element.prototype.closest': Element.prototype.closest,
                'Element.prototype.prepend': Element.prototype.prepend,
                'Element.prototype.remove': Element.prototype.remove,
                'Object.assign': Object.assign
            };
            var req = [];
            for (var feature in features) {
                if (Object.prototype.hasOwnProperty.call(features, feature) && !features[feature]) {
                    req.push(feature);
                }
            }
            if (req.length) {
                return 'https://polyfill.io/v3/polyfill.min.js?features=' + req.join('%2C') + '&flags=always';
            }
            return null;
        };

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    {src: polyfillsUrl(), test: 'polyfills-js', noinit: true},
                    
                        {src: '/static/js/global-article-es6-bundle-62a1428781.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-ca6a20c074.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-7850fbb459.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-bd334e676d.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-c634a291c7.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        
                            var conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-2626f1bdf8.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-bd14bd0747.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2d5c465efd.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
  </script>
  <script data-test="global-article-js" defer="" id="js-position1" src="/static/js/global-article-es6-bundle-62a1428781.js">
  </script>
  <script data-test="shared-js" defer="" id="js-position2" src="/static/js/shared-es6-bundle-7850fbb459.js">
  </script>
  <script data-test="header-150-js" defer="" id="js-position3" src="/static/js/header-150-es6-bundle-5bb959eaa1.js">
  </script>
  <meta content="noarchive" name="robots"/>
  <meta content="Yes" name="access"/>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/search" rel="search"/>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/opensearch/opensearch.xml" rel="search" title="nature.com" type="application/opensearchdescription+xml"/>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/opensearch/request" rel="search" title="nature.com" type="application/sru+xml"/>
  <script type="application/ld+json">
   {"mainEntity":{"headline":"Mastering the game of Go without human knowledge","description":"A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo. Starting from zero knowledge and without human data, AlphaGo Zero was able to teach itself to play Go and to develop novel strategies that provide new insights into the oldest of games. To beat world champions at the game of Go, the computer program AlphaGo has relied largely on supervised learning from millions of human expert moves. David Silver and colleagues have now produced a system called AlphaGo Zero, which is based purely on reinforcement learning and learns solely from self-play. Starting from random moves, it can reach superhuman level in just a couple of days of training and five million games of self-play, and can now beat all previous versions of AlphaGo. Because the machine independently discovers the same fundamental principles of the game that took humans millennia to conceptualize, the work suggests that such principles have some universal character, beyond human bias.","datePublished":"2017-10-19","dateModified":"2017-10-19","pageStart":"354","pageEnd":"359","sameAs":"https://doi-org.proxy.lib.ohio-state.edu/10.1038/nature24270","keywords":"Computational science,Computer science,Reward,Science,Humanities and Social Sciences,multidisciplinary","image":"https://static-content.springer.com/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg","isPartOf":{"name":"Nature","issn":["1476-4687","0028-0836"],"volumeNumber":"550","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www-springernature-com.proxy.lib.ohio-state.edu/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"David Silver","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"email":"davidsilver@google.com","@type":"Person"},{"name":"Julian Schrittwieser","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Karen Simonyan","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Ioannis Antonoglou","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Aja Huang","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Arthur Guez","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Thomas Hubert","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Lucas Baker","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Matthew Lai","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Adrian Bolton","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Yutian Chen","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Timothy Lillicrap","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Fan Hui","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Laurent Sifre","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"George van den Driessche","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Thore Graepel","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Demis Hassabis","affiliation":[{"name":"DeepMind","address":{"name":"DeepMind, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}
  </script>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270" rel="canonical"/>
  <meta content="41586" name="journal_id"/>
  <meta content="Mastering the game of Go without human knowledge" name="dc.title"/>
  <meta content="Nature 2017 550:7676" name="dc.source"/>
  <meta content="text/html" name="dc.format"/>
  <meta content="Nature Publishing Group" name="dc.publisher"/>
  <meta content="2017-10-19" name="dc.date"/>
  <meta content="OriginalPaper" name="dc.type"/>
  <meta content="En" name="dc.language"/>
  <meta content="2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved." name="dc.copyright"/>
  <meta content="2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved." name="dc.rights"/>
  <meta content="journalpermissions@springernature.com" name="dc.rightsAgent"/>
  <meta content="A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo. Starting from zero knowledge and without human data, AlphaGo Zero was able to teach itself to play Go and to develop novel strategies that provide new insights into the oldest of games. To beat world champions at the game of Go, the computer program AlphaGo has relied largely on supervised learning from millions of human expert moves. David Silver and colleagues have now produced a system called AlphaGo Zero, which is based purely on reinforcement learning and learns solely from self-play. Starting from random moves, it can reach superhuman level in just a couple of days of training and five million games of self-play, and can now beat all previous versions of AlphaGo. Because the machine independently discovers the same fundamental principles of the game that took humans millennia to conceptualize, the work suggests that such principles have some universal character, beyond human bias." name="dc.description"/>
  <meta content="1476-4687" name="prism.issn"/>
  <meta content="Nature" name="prism.publicationName"/>
  <meta content="2017-10-19" name="prism.publicationDate"/>
  <meta content="550" name="prism.volume"/>
  <meta content="7676" name="prism.number"/>
  <meta content="OriginalPaper" name="prism.section"/>
  <meta content="354" name="prism.startingPage"/>
  <meta content="359" name="prism.endingPage"/>
  <meta content="2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved." name="prism.copyright"/>
  <meta content="journalpermissions@springernature.com" name="prism.rightsAgent"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270" name="prism.url"/>
  <meta content="doi:10.1038/nature24270" name="prism.doi"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270.pdf" name="citation_pdf_url"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270" name="citation_fulltext_html_url"/>
  <meta content="Nature" name="citation_journal_title"/>
  <meta content="Nature" name="citation_journal_abbrev"/>
  <meta content="Nature Publishing Group" name="citation_publisher"/>
  <meta content="1476-4687" name="citation_issn"/>
  <meta content="Mastering the game of Go without human knowledge" name="citation_title"/>
  <meta content="550" name="citation_volume"/>
  <meta content="7676" name="citation_issue"/>
  <meta content="2017/10" name="citation_publication_date"/>
  <meta content="2017/10/19" name="citation_online_date"/>
  <meta content="354" name="citation_firstpage"/>
  <meta content="359" name="citation_lastpage"/>
  <meta content="Article" name="citation_article_type"/>
  <meta content="en" name="citation_language"/>
  <meta content="doi:10.1038/nature24270" name="dc.identifier"/>
  <meta content="10.1038/nature24270" name="DOI"/>
  <meta content="175364" name="size"/>
  <meta content="10.1038/nature24270" name="citation_doi"/>
  <meta content="http://api.springer-com.proxy.lib.ohio-state.edu/xmldata/jats?q=doi:10.1038/nature24270&amp;api_key=" name="citation_springer_api_url"/>
  <meta content="A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo. Starting from zero knowledge and without human data, AlphaGo Zero was able to teach itself to play Go and to develop novel strategies that provide new insights into the oldest of games. To beat world champions at the game of Go, the computer program AlphaGo has relied largely on supervised learning from millions of human expert moves. David Silver and colleagues have now produced a system called AlphaGo Zero, which is based purely on reinforcement learning and learns solely from self-play. Starting from random moves, it can reach superhuman level in just a couple of days of training and five million games of self-play, and can now beat all previous versions of AlphaGo. Because the machine independently discovers the same fundamental principles of the game that took humans millennia to conceptualize, the work suggests that such principles have some universal character, beyond human bias." name="description"/>
  <meta content="Silver, David" name="dc.creator"/>
  <meta content="Schrittwieser, Julian" name="dc.creator"/>
  <meta content="Simonyan, Karen" name="dc.creator"/>
  <meta content="Antonoglou, Ioannis" name="dc.creator"/>
  <meta content="Huang, Aja" name="dc.creator"/>
  <meta content="Guez, Arthur" name="dc.creator"/>
  <meta content="Hubert, Thomas" name="dc.creator"/>
  <meta content="Baker, Lucas" name="dc.creator"/>
  <meta content="Lai, Matthew" name="dc.creator"/>
  <meta content="Bolton, Adrian" name="dc.creator"/>
  <meta content="Chen, Yutian" name="dc.creator"/>
  <meta content="Lillicrap, Timothy" name="dc.creator"/>
  <meta content="Hui, Fan" name="dc.creator"/>
  <meta content="Sifre, Laurent" name="dc.creator"/>
  <meta content="van den Driessche, George" name="dc.creator"/>
  <meta content="Graepel, Thore" name="dc.creator"/>
  <meta content="Hassabis, Demis" name="dc.creator"/>
  <meta content="Computational science" name="dc.subject"/>
  <meta content="Computer science" name="dc.subject"/>
  <meta content="Reward" name="dc.subject"/>
  <meta content="Friedman, J., Hastie, T. &amp; Tibshirani, R. The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer, 2009)" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Deep learning; citation_author=Y LeCun, Y Bengio, G Hinton; citation_volume=521; citation_publication_date=2015; citation_pages=436-444; citation_doi=10.1038/nature14539; citation_id=CR2" name="citation_reference"/>
  <meta content="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. In Adv. Neural Inf. Process. Syst. Vol. 25 (eds Pereira, F., Burges, C. J. C., Bottou, L. &amp; Weinberger, K. Q. ) 1097–1105 (2012)" name="citation_reference"/>
  <meta content="He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit. 770–778 (2016)" name="citation_reference"/>
  <meta content="Hayes-Roth, F., Waterman, D. &amp; Lenat, D. Building Expert Systems (Addison-Wesley, 1984)" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Human-level control through deep reinforcement learning; citation_author=V Mnih; citation_volume=518; citation_publication_date=2015; citation_pages=529-533; citation_doi=10.1038/nature14236; citation_id=CR6" name="citation_reference"/>
  <meta content="Guo, X., Singh, S. P., Lee, H., Lewis, R. L. &amp; Wang, X. Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning. In Adv. Neural Inf. Process. Syst. Vol. 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D. &amp; Weinberger, K. Q. ) 3338–3346 (2014)" name="citation_reference"/>
  <meta content="Mnih, V . et al. Asynchronous methods for deep reinforcement learning. In Proc. 33rd Int. Conf. Mach. Learn. Vol. 48 (eds Balcan, M. F. &amp; Weinberger, K. Q. ) 1928–1937 (2016)" name="citation_reference"/>
  <meta content="Jaderberg, M . et al. Reinforcement learning with unsupervised auxiliary tasks. In 5th Int. Conf. Learn. Representations (2017)" name="citation_reference"/>
  <meta content="Dosovitskiy, A. &amp; Koltun, V. Learning to act by predicting the future. In 5th Int. Conf. Learn. Representations (2017)" name="citation_reference"/>
  <meta content="Man´dziuk, J. in Challenges for Computational Intelligence ( Duch, W. &amp; Man´dziuk, J. ) 407–442 (Springer, 2007)" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Mastering the game of Go with deep neural networks and tree search; citation_author=D Silver; citation_volume=529; citation_publication_date=2016; citation_pages=484-489; citation_doi=10.1038/nature16961; citation_id=CR12" name="citation_reference"/>
  <meta content="Coulom, R. Efficient selectivity and backup operators in Monte-Carlo tree search. In 5th Int. Conf. Computers and Games (eds Ciancarini, P. &amp; van den Herik, H. J. ) 72–83 (2006)" name="citation_reference"/>
  <meta content="Kocsis, L. &amp; Szepesvári, C. Bandit based Monte-Carlo planning. In 15th Eu. Conf. Mach. Learn. 282–293 (2006)" name="citation_reference"/>
  <meta content="citation_journal_title=Comput. Intell. AI Games; citation_title=A survey of Monte Carlo tree search methods. IEEE Trans; citation_author=C Browne; citation_volume=4; citation_publication_date=2012; citation_pages=1-49; citation_doi=10.1109/TCIAIG.2012.2186810; citation_id=CR15" name="citation_reference"/>
  <meta content="citation_journal_title=Biol. Cybern.; citation_title=Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position; citation_author=K Fukushima; citation_volume=36; citation_publication_date=1980; citation_pages=193-202; citation_doi=10.1007/BF00344251; citation_id=CR16" name="citation_reference"/>
  <meta content="LeCun, Y. &amp; Bengio, Y. in The Handbook of Brain Theory and Neural Networks Ch. 3 (ed. Arbib, M. ) 276–278 (MIT Press, 1995)" name="citation_reference"/>
  <meta content="Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 448–456 (2015)" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit; citation_author=RHR Hahnloser, R Sarpeshkar, MA Mahowald, RJ Douglas, HS Seung; citation_volume=405; citation_publication_date=2000; citation_pages=947-951; citation_doi=10.1038/35016072; citation_id=CR19" name="citation_reference"/>
  <meta content="Howard, R. Dynamic Programming and Markov Processes (MIT Press, 1960)" name="citation_reference"/>
  <meta content="Sutton, R . &amp; Barto, A. Reinforcement Learning: an Introduction (MIT Press, 1998)" name="citation_reference"/>
  <meta content="citation_journal_title=J. Control Theory Appl.; citation_title=Approximate policy iteration: a survey and some new methods; citation_author=DP Bertsekas; citation_volume=9; citation_publication_date=2011; citation_pages=310-335; citation_doi=10.1007/s11768-011-1005-3; citation_id=CR22" name="citation_reference"/>
  <meta content="Scherrer, B. Approximate policy iteration schemes: a comparison. In Proc. 31st Int. Conf. Mach. Learn. Vol. 32 1314–1322 (2014)" name="citation_reference"/>
  <meta content="citation_journal_title=Ann. Math. Artif. Intell.; citation_title=Multi-armed bandits with episode context; citation_author=CD Rosin; citation_volume=61; citation_publication_date=2011; citation_pages=203-230; citation_doi=10.1007/s10472-011-9258-6; citation_id=CR24" name="citation_reference"/>
  <meta content="Coulom, R. Whole-history rating: a Bayesian rating system for players of time-varying strength. In Int. Conf. Comput. Games (eds van den Herik, H. J., Xu, X . Ma, Z . &amp; Winands, M. H. M. ) Vol. 5131 113–124 (Springer, 2008)" name="citation_reference"/>
  <meta content="citation_journal_title=Int. J. Knowledge-Based Intelligent Engineering Systems; citation_title=The world of independent learners is not Markovian; citation_author=GJ Laurent, L Matignon, N Le Fort-Piat; citation_volume=15; citation_publication_date=2011; citation_pages=55-64; citation_doi=10.3233/KES-2010-0206; citation_id=CR26" name="citation_reference"/>
  <meta content="Foerster, J. N . et al. Stabilising experience replay for deep multi-agent reinforcement learning. In Proc. 34th Int. Conf. Mach. Learn. Vol. 70 1146–1155 (2017)" name="citation_reference"/>
  <meta content="Heinrich, J . &amp; Silver, D. Deep reinforcement learning from self-play in imperfect-information games. In NIPS Deep Reinforcement Learning Workshop (2016)" name="citation_reference"/>
  <meta content="Jouppi, N. P . et al. In-datacenter performance analysis of a Tensor Processing Unit. Proc. 44th Annu. Int. Symp. Comp. Architecture Vol. 17 1–12 (2017)" name="citation_reference"/>
  <meta content="Maddison, C. J., Huang, A., Sutskever, I . &amp; Silver, D. Move evaluation in Go using deep convolutional neural networks. In 3rd Int. Conf. Learn. Representations. (2015)" name="citation_reference"/>
  <meta content="Clark, C . &amp; Storkey, A. J. Training deep convolutional neural networks to play Go. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 1766–1774 (2015)" name="citation_reference"/>
  <meta content="Tian, Y. &amp; Zhu, Y. Better computer Go player with neural network and long-term prediction. In 4th Int. Conf. Learn. Representations (2016)" name="citation_reference"/>
  <meta content="Cazenave, T. Residual networks for computer Go. IEEE Trans. Comput. Intell. AI Games 
                    https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042
                    
                   (2017)" name="citation_reference"/>
  <meta content="Huang, A. AlphaGo master online series of games. 
                    https://deepmind.com/research/AlphaGo/match-archive/master
                    
                   (2017)" name="citation_reference"/>
  <meta content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Monte Carlo matrix inversion and reinforcement learning; citation_author=AG Barto, M Duff; citation_volume=6; citation_publication_date=1994; citation_pages=687-694; citation_id=CR35" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.; citation_title=Reinforcement learning with replacing eligibility traces; citation_author=SP Singh, RS Sutton; citation_volume=22; citation_publication_date=1996; citation_pages=123-158; citation_id=CR36" name="citation_reference"/>
  <meta content="Lagoudakis, M. G. &amp; Parr, R. Reinforcement learning as classification: leveraging modern classifiers. In Proc. 20th Int. Conf. Mach. Learn. 424–431 (2003)" name="citation_reference"/>
  <meta content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Approximate modified policy iteration and its application to the game of Tetris; citation_author=B Scherrer, M Ghavamzadeh, V Gabillon, B Lesner, M Geist; citation_volume=16; citation_publication_date=2015; citation_pages=1629-1676; citation_id=CR38" name="citation_reference"/>
  <meta content="Littman, M. L. Markov games as a framework for multi-agent reinforcement learning. In Proc. 11th Int. Conf. Mach. Learn. 157–163 (1994)" name="citation_reference"/>
  <meta content="Enzenberger, M. The integration of a priori knowledge into a Go playing neural network. 
                    http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html
                    
                   (1996)" name="citation_reference"/>
  <meta content="Enzenberger, M. in Advances in Computer Games (eds Van Den Herik, H. J., Iida, H. &amp; Heinz, E. A. ) 97–108 (2003)" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.; citation_title=Learning to predict by the method of temporal differences; citation_author=R Sutton; citation_volume=3; citation_publication_date=1988; citation_pages=9-44; citation_id=CR42" name="citation_reference"/>
  <meta content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Temporal difference learning of position evaluation in the game of Go; citation_author=NN Schraudolph, P Dayan, TJ Sejnowski; citation_volume=6; citation_publication_date=1994; citation_pages=817-824; citation_id=CR43" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.; citation_title=Temporal-difference search in computer Go; citation_author=D Silver, R Sutton, M Müller; citation_volume=87; citation_publication_date=2012; citation_pages=183-219; citation_doi=10.1007/s10994-012-5280-0; citation_id=CR44" name="citation_reference"/>
  <meta content="Silver, D. Reinforcement Learning and Simulation-Based Search in Computer Go. PhD thesis, Univ. Alberta, Edmonton, Canada (2009)" name="citation_reference"/>
  <meta content="citation_journal_title=Artif. Intell.; citation_title=Monte-Carlo tree search and rapid action value estimation in computer Go; citation_author=S Gelly, D Silver; citation_volume=175; citation_publication_date=2011; citation_pages=1856-1875; citation_doi=10.1016/j.artint.2011.03.007; citation_id=CR46" name="citation_reference"/>
  <meta content="citation_journal_title=Int. Comput. Games Assoc. J.; citation_title=Computing Elo ratings of move patterns in the game of Go; citation_author=R Coulom; citation_volume=30; citation_publication_date=2007; citation_pages=198-208; citation_id=CR47" name="citation_reference"/>
  <meta content="Gelly, S., Wang, Y., Munos, R. &amp; Teytaud, O. Modification of UCT with patterns in Monte-Carlo Go. Report No. 6062 (INRIA, 2006)" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.; citation_title=Learning to play chess using temporal differences; citation_author=J Baxter, A Tridgell, L Weaver; citation_volume=40; citation_publication_date=2000; citation_pages=243-263; citation_doi=10.1023/A:1007634325138; citation_id=CR49" name="citation_reference"/>
  <meta content="Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In Adv. Neural Inf. Process. Syst. 1937–1945 (2009)" name="citation_reference"/>
  <meta content="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)" name="citation_reference"/>
  <meta content="Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In Proc. 17th Int. Jt Conf. Artif. Intell. Vol. 1 529–534 (2001)" name="citation_reference"/>
  <meta content="citation_journal_title=Neural Comput.; citation_title=TD-gammon, a self-teaching backgammon program, achieves master-level play; citation_author=G Tesauro; citation_volume=6; citation_publication_date=1994; citation_pages=215-219; citation_doi=10.1162/neco.1994.6.2.215; citation_id=CR53" name="citation_reference"/>
  <meta content="Buro, M. From simple features to sophisticated evaluation functions. In Proc. 1st Int. Conf. Comput. Games 126–145 (1999)" name="citation_reference"/>
  <meta content="citation_journal_title=Artif. Intell.; citation_title=World-championship-caliber Scrabble; citation_author=B Sheppard; citation_volume=134; citation_publication_date=2002; citation_pages=241-275; citation_doi=10.1016/S0004-3702(01)00166-7; citation_id=CR55" name="citation_reference"/>
  <meta content="citation_journal_title=Science; citation_title=DeepStack: expert-level artificial intelligence in heads-up no-limit poker; citation_author=M Moravcˇík; citation_volume=356; citation_publication_date=2017; citation_pages=508-513; citation_doi=10.1126/science.aam6960; citation_id=CR56" name="citation_reference"/>
  <meta content="Tesauro, G &amp; Galperin, G. On-line policy improvement using Monte-Carlo search. In Adv. Neural Inf. Process. Syst. 1068–1074 (1996)" name="citation_reference"/>
  <meta content="Tesauro, G. Neurogammon: a neural-network backgammon program. In Proc. Int. Jt Conf. Neural Netw. Vol. 3, 33–39 (1990)" name="citation_reference"/>
  <meta content="citation_journal_title=IBM J. Res. Develop.; citation_title=Some studies in machine learning using the game of checkers II - recent progress; citation_author=AL Samuel; citation_volume=11; citation_publication_date=1967; citation_pages=601-617; citation_doi=10.1147/rd.116.0601; citation_id=CR59" name="citation_reference"/>
  <meta content="citation_journal_title=Int. J. Robot. Res.; citation_title=Reinforcement learning in robotics: a survey; citation_author=J Kober, JA Bagnell, J Peters; citation_volume=32; citation_publication_date=2013; citation_pages=1238-1274; citation_doi=10.1177/0278364913495721; citation_id=CR60" name="citation_reference"/>
  <meta content="Zhang, W. &amp; Dietterich, T. G. A reinforcement learning approach to job-shop scheduling. In Proc. 14th Int. Jt Conf. Artif. Intell. 1114–1120 (1995)" name="citation_reference"/>
  <meta content="Cazenave, T., Balbo, F. &amp; Pinson, S. Using a Monte-Carlo approach for bus regulation. In Int. IEEE Conf. Intell. Transport. Syst. 1–6 (2009)" name="citation_reference"/>
  <meta content="Evans, R. &amp; Gao, J. Deepmind AI reduces Google data centre cooling bill by 40%. 
                    https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/
                    
                   (2016)" name="citation_reference"/>
  <meta content="Abe, N . et al. Empirical comparison of various reinforcement learning strategies for sequential targeted marketing. In IEEE Int. Conf. Data Mining 3–10 (2002)" name="citation_reference"/>
  <meta content="Silver, D., Newnham, L., Barker, D., Weller, S. &amp; McFall, J. Concurrent reinforcement learning from customer interactions. In Proc. 30th Int. Conf. Mach. Learn. Vol. 28 924–932 (2013)" name="citation_reference"/>
  <meta content="Tromp, J. Tromp–Taylor rules. 
                    http://tromp.github.io/go.html
                    
                   (1995)" name="citation_reference"/>
  <meta content="citation_journal_title=Artif. Intell.; citation_title=Computer Go; citation_author=M Müller; citation_volume=134; citation_publication_date=2002; citation_pages=145-179; citation_doi=10.1016/S0004-3702(01)00121-7; citation_id=CR67" name="citation_reference"/>
  <meta content="citation_journal_title=Proc. IEEE; citation_title=Taking the human out of the loop: a review of Bayesian optimization; citation_author=B Shahriari, K Swersky, Z Wang, RP Adams, N de Freitas; citation_volume=104; citation_publication_date=2016; citation_pages=148-175; citation_doi=10.1109/JPROC.2015.2494218; citation_id=CR68" name="citation_reference"/>
  <meta content="citation_journal_title=Comput. Games; citation_title=On the scalability of parallel UCT; citation_author=RB Segal; citation_volume=6515; citation_publication_date=2011; citation_pages=36-47; citation_doi=10.1007/978-3-642-17928-0_4; citation_id=CR69" name="citation_reference"/>
  <meta content="Silver, David" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Schrittwieser, Julian" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Simonyan, Karen" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Antonoglou, Ioannis" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Huang, Aja" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Guez, Arthur" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Hubert, Thomas" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Baker, Lucas" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Lai, Matthew" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Bolton, Adrian" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Chen, Yutian" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Lillicrap, Timothy" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Hui, Fan" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Sifre, Laurent" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="van den Driessche, George" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Graepel, Thore" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="Hassabis, Demis" name="citation_author"/>
  <meta content="DeepMind, London, UK" name="citation_author_institution"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/platform/readcube-access" name="access_endpoint"/>
  <meta content="@nature" name="twitter:site"/>
  <meta content="summary_large_image" name="twitter:card"/>
  <meta content="Content cover image" name="twitter:image:alt"/>
  <meta content="Mastering the game of Go without human knowledge" name="twitter:title"/>
  <meta content="Nature - To beat world champions at the game of Go, the computer program AlphaGo has relied largely on supervised learning from millions of human expert moves. David Silver and colleagues have now..." name="twitter:description"/>
  <meta content="https://media-springernature-com.proxy.lib.ohio-state.edu/full/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg" name="twitter:image"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270" property="og:url"/>
  <meta content="article" property="og:type"/>
  <meta content="Nature" property="og:site_name"/>
  <meta content="Mastering the game of Go without human knowledge - Nature" property="og:title"/>
  <meta content="Starting from zero knowledge and without human data, AlphaGo Zero was able to teach itself to play Go and to develop novel strategies that provide new insights into the oldest of games." property="og:description"/>
  <meta content="https://media-springernature-com.proxy.lib.ohio-state.edu/m685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg" property="og:image"/>
  <script>
   window.eligibleForRa21 = 'true';
  </script>
  <style type="text/css">
   .c-cookie-banner {
			background-color: #01324b;
			color: white;
			font-size: 1rem;
			position: fixed;
			bottom: 0;
			left: 0;
			right: 0;
			padding: 16px 0;
			font-family: sans-serif;
			z-index: 100002;
			text-align: center;
		}
		.c-cookie-banner__container {
			margin: 0 auto;
			max-width: 1280px;
			padding: 0 16px;
		}
		.c-cookie-banner p {
			margin-bottom: 8px;
		}
		.c-cookie-banner p:last-child {
			margin-bottom: 0;
		}	
		.c-cookie-banner__dismiss {
			background-color: transparent;
			border: 0;
			padding: 0;
			margin-left: 4px;
			color: inherit;
			text-decoration: underline;
			font-size: inherit;
		}
		.c-cookie-banner__dismiss:hover {
			text-decoration: none;
		}
  </style>
  <script async="" src="https://injections.readcube.com/nature/inject.ef8e25d3.js" type="text/javascript">
  </script>
  <link href="https://injections.readcube.com/styles/nature_checkout.7bec98da.css" rel="stylesheet" type="text/css"/>
  <script>
   window.dataLayer = window.dataLayer || [];
            window.dataLayer.push({
                recommendations: {
                    recommender: 'personalised',
                    model: 'xgboost',
                    policy_id: 'speedy-BootstrappedUCB',
                    timestamp: 1698031191,
                    embedded_user: 'null'
                }
            });
  </script>
 </head>
 <body class="article-page">
  <noscript>
   <iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ" style="display:none;visibility:hidden" width="0">
   </iframe>
  </noscript>
  <div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
   <a class="c-skip-link" href="#content">
    Skip to main content
   </a>
   <div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
     <p>
      Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.
     </p>
    </div>
   </div>
   <div class="u-lazy-ad-wrapper u-mbs-0">
    <div class="deferred-placeholder" data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container" data-replace="true">
    </div>
    <aside class="c-ad c-ad--728x90">
     <div class="c-ad__inner" data-container-type="banner-advert">
      <p class="c-ad__label">
       Advertisement
      </p>
      <div class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide" data-ad-type="top" data-gpt="" data-gpt-sizes="728x90" data-gpt-targeting="type=article;pos=top;artid=nature24270;doi=10.1038/nature24270;techmeta=129,139;subjmeta=1042,117,1788,378,631,639,705;kwrd=Computational+science,Computer+science,Reward" data-gpt-unitpath="/285/nature.com/article" data-pa11y-ignore="" data-test="top-ad" id="div-gpt-ad-top-1">
       <noscript>
        <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=728x90&amp;c=-96983186&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnature24270%26doi%3D10.1038/nature24270%26techmeta%3D129,139%26subjmeta%3D1042,117,1788,378,631,639,705%26kwrd%3DComputational+science,Computer+science,Reward">
         <img alt="Advertisement" data-test="gpt-advert-fallback-img" height="90" src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=728x90&amp;c=-96983186&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnature24270%26doi%3D10.1038/nature24270%26techmeta%3D129,139%26subjmeta%3D1042,117,1788,378,631,639,705%26kwrd%3DComputational+science,Computer+science,Reward" width="728"/>
        </a>
       </noscript>
      </div>
     </div>
    </aside>
   </div>
   <header class="c-header" data-header="" data-track-component="nature-150-split-header" id="header" style="border-color:#000">
    <div class="c-header__row">
     <div class="c-header__container">
      <div class="c-header__split">
       <div class="c-header__logo-container">
        <a data-track="click" data-track-action="home" data-track-label="image" href="/">
         <picture class="c-header__logo">
          <source media="(min-width: 875px)" srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/full/nature-cms/uploads/product/nature/header-86f1267ea01eccd46b530284be10585e.svg"/>
          <img alt="Nature" height="32" src="https://media-springernature-com.proxy.lib.ohio-state.edu/full/nature-cms/uploads/product/nature/header-86f1267ea01eccd46b530284be10585e.svg"/>
         </picture>
        </a>
       </div>
       <ul class="c-header__menu c-header__menu--global">
        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
         <a class="c-header__link" data-test="siteindex-link" data-track="click" data-track-action="open nature research index" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/siteindex">
          <span>
           View all journals
          </span>
         </a>
        </li>
        <li class="c-header__item c-header__item--padding c-header__item--pipe">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button" href="javascript:;" role="button">
          <span>
           Search
          </span>
          <svg aria-hidden="true" focusable="false" height="22" role="img" viewbox="0 0 18 18" width="22" xmlns="http://www.w3.org/2000/svg">
           <path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z">
           </path>
          </svg>
         </a>
         <div class="c-header__dropdown c-header__dropdown--full-width has-tethered u-js-hide" data-track-component="nature-150-split-header" hidden="" id="search-menu">
          <div class="c-header__container">
           <h2 class="c-header__visually-hidden">
            Search
           </h2>
           <form action="/search" autocomplete="off" class="c-header__search-form" data-test="inline-search" method="get" role="search">
            <label class="c-header__heading" for="keywords">
             Search articles by subject, keyword or author
            </label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
             <div>
              <input class="c-header__input" id="keywords" name="q" required="" type="text" value=""/>
             </div>
             <div class="c-header__search-layout">
              <div>
               <label class="c-header__visually-hidden" for="results-from">
                Show results from
               </label>
               <select class="c-header__select" id="results-from" name="journal">
                <option selected="" value="">
                 All journals
                </option>
                <option value="nature">
                 This journal
                </option>
               </select>
              </div>
              <div>
               <button class="c-header__search-button" type="submit">
                Search
               </button>
              </div>
             </div>
            </div>
           </form>
           <div class="c-header__flush">
            <a class="c-header__link" data-track="click" data-track-action="advanced search" data-track-label="link" href="/search/advanced">
             Advanced search
            </a>
           </div>
           <h3 class="c-header__heading c-header__heading--keyline">
            Quick links
           </h3>
           <ul class="c-header__list">
            <li>
             <a class="c-header__link" data-track="click" data-track-action="explore articles by subject" data-track-label="link" href="/subjects">
              Explore articles by subject
             </a>
            </li>
            <li>
             <a class="c-header__link" data-track="click" data-track-action="find a job" data-track-label="link" href="/naturecareers">
              Find a job
             </a>
            </li>
            <li>
             <a class="c-header__link" data-track="click" data-track-action="guide to authors" data-track-label="link" href="/authors/index.html">
              Guide to authors
             </a>
            </li>
            <li>
             <a class="c-header__link" data-track="click" data-track-action="editorial policies" data-track-label="link" href="/authors/editorial_policies/">
              Editorial policies
             </a>
            </li>
           </ul>
          </div>
         </div>
        </li>
        <li class="c-header__item c-header__item--padding">
         <a class="c-header__link eds-c-header__link" href="https://idp-nature-com.proxy.lib.ohio-state.edu/auth/personal/springernature?redirect_uri=https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270" id="identity-account-widget">
          Log in
         </a>
        </li>
       </ul>
      </div>
     </div>
    </div>
    <div class="c-header__row">
     <div class="c-header__container" data-test="navigation-row">
      <div class="c-header__split">
       <ul class="c-header__menu c-header__menu--journal">
        <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" data-test="menu-button--explore" data-track="click" data-track-action="open explore expander" data-track-label="button" href="javascript:;" role="button">
          <span>
           <span class="c-header__show-text">
            Explore
           </span>
           content
          </span>
          <svg aria-hidden="true" focusable="false" height="16" role="img" viewbox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg">
           <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)">
           </path>
          </svg>
         </a>
         <nav aria-labelledby="Explore-content" class="c-header__dropdown has-tethered u-js-hide" data-test="Explore-content" data-track-component="nature-150-split-header" hidden="" id="explore">
          <div class="c-header__container">
           <h2 class="c-header__heading c-header__heading--js-hide" id="Explore-content">
            Explore content
           </h2>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="research articles" data-track-label="link" href="/nature/research-articles">
              Research articles
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="news" data-track-label="link" href="/news">
              News
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="opinion" data-track-label="link" href="/opinion">
              Opinion
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="research analysis" data-track-label="link" href="/research-analysis">
              Research Analysis
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="careers" data-track-label="link" href="/careers">
              Careers
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="books &amp; culture" data-track-label="link" href="/books-culture">
              Books &amp; Culture
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="podcasts" data-track-label="link" href="/nature/podcasts">
              Podcasts
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="videos" data-track-label="link" href="/nature/videos">
              Videos
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="current issue" data-track-label="link" href="/nature/current-issue">
              Current issue
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="browse issues" data-track-label="link" href="/nature/browse-issues">
              Browse issues
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="collections" data-track-label="link" href="/nature/collections">
              Collections
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="subjects" data-track-label="link" href="/nature/browse-subjects">
              Subjects
             </a>
            </li>
           </ul>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="facebook" data-track-label="link" href="https://www.facebook.com/Nature">
              Follow us on Facebook
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="twitter" data-track-label="link" href="https://twitter.com/nature">
              Follow us on Twitter
             </a>
            </li>
            <li class="c-header__item c-header__item--hide-lg">
             <a class="c-header__link" data-track="click" data-track-action="Sign up for alerts" data-track-external="" data-track-label="link (mobile dropdown)" href="https://www-nature-com.proxy.lib.ohio-state.edu/my-account/alerts/subscribe-journal?list-id=1" rel="nofollow">
              Sign up for alerts
              <svg aria-hidden="true" focusable="false" height="18" role="img" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg">
               <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff">
               </path>
              </svg>
             </a>
            </li>
            <li class="c-header__item c-header__item--hide-lg">
             <a class="c-header__link" data-track="click" data-track-action="rss feed" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nature.rss">
              <span>
               RSS feed
              </span>
             </a>
            </li>
           </ul>
          </div>
         </nav>
        </li>
        <li class="c-header__item c-header__item--dropdown-menu">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" data-test="menu-button--about-the-journal" data-track="click" data-track-action="open about the journal expander" data-track-label="button" href="javascript:;" role="button">
          <span>
           About
           <span class="c-header__show-text">
            the journal
           </span>
          </span>
          <svg aria-hidden="true" focusable="false" height="16" role="img" viewbox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg">
           <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)">
           </path>
          </svg>
         </a>
         <nav aria-labelledby="About-the-journal" class="c-header__dropdown has-tethered u-js-hide" data-test="about-the-journal" data-track-component="nature-150-split-header" hidden="" id="about-the-journal">
          <div class="c-header__container">
           <h2 class="c-header__heading c-header__heading--js-hide" id="About-the-journal">
            About the journal
           </h2>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="journal staff" data-track-label="link" href="/nature/journal-staff">
              Journal Staff
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="about the editors" data-track-label="link" href="/nature/editors">
              About the Editors
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="journal information" data-track-label="link" href="/nature/journal-information">
              Journal Information
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="our publishing models" data-track-label="link" href="/nature/our-publishing-models">
              Our publishing models
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="editorial values statement" data-track-label="link" href="/nature/editorial-values-statement">
              Editorial Values Statement
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="journal metrics" data-track-label="link" href="/nature/journal-impact">
              Journal Metrics
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="awards" data-track-label="link" href="/nature/awards">
              Awards
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="contact" data-track-label="link" href="/nature/contact">
              Contact
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="editorial policies" data-track-label="link" href="/nature/editorial-policies">
              Editorial policies
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="history of nature" data-track-label="link" href="/nature/history-of-nature">
              History of Nature
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="send a news tip" data-track-label="link" href="/nature/send-a-news-tip">
              Send a news tip
             </a>
            </li>
           </ul>
          </div>
         </nav>
        </li>
        <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link c-header__link--dropdown-menu" data-header-expander="" data-test="menu-button--publish" data-track="click" data-track-action="open publish with us expander" data-track-label="button" href="javascript:;" role="button">
          <span>
           Publish
           <span class="c-header__show-text">
            with us
           </span>
          </span>
          <svg aria-hidden="true" focusable="false" height="16" role="img" viewbox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg">
           <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)">
           </path>
          </svg>
         </a>
         <nav aria-labelledby="Publish-with-us-label" class="c-header__dropdown has-tethered u-js-hide" data-test="publish-with-us" data-track-component="nature-150-split-header" hidden="" id="publish-with-us">
          <div class="c-header__container">
           <h2 class="c-header__heading c-header__heading--js-hide" id="Publish-with-us-label">
            Publish with us
           </h2>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="for authors" data-track-label="link" href="/nature/for-authors">
              For Authors
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="for referees" data-track-label="link" href="/nature/for-referees">
              For Referees
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="nature-author-services" data-track="click" data-track-action="manuscript author services" data-track-label="link manuscript author services" href="https://authorservices-springernature-com.proxy.lib.ohio-state.edu/go/sn/?utm_source=For+Authors&amp;utm_medium=Website_Nature&amp;utm_campaign=Platform+Experimentation+2022&amp;utm_id=PE2022">
              Language editing services
             </a>
            </li>
            <li class="c-header__item c-header__item--keyline">
             <a class="c-header__link" data-track="click" data-track-action="submit manuscript" data-track-external="" data-track-label="link (publish with us dropdown menu)" href="https://mts-nature-nature-com.proxy.lib.ohio-state.edu/">
              Submit manuscript
              <svg aria-hidden="true" focusable="false" height="18" role="img" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg">
               <path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff">
               </path>
              </svg>
             </a>
            </li>
           </ul>
          </div>
         </nav>
        </li>
       </ul>
       <ul class="c-header__menu c-header__menu--hide-lg-max">
        <li class="c-header__item">
         <a class="c-header__link" data-track="click" data-track-action="Sign up for alerts" data-track-external="" data-track-label="link (desktop site header)" href="https://www-nature-com.proxy.lib.ohio-state.edu/my-account/alerts/subscribe-journal?list-id=1" rel="nofollow">
          <span>
           Sign up for alerts
          </span>
          <svg aria-hidden="true" focusable="false" height="18" role="img" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg">
           <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222">
           </path>
          </svg>
         </a>
        </li>
        <li class="c-header__item c-header__item--pipe">
         <a class="c-header__link" data-track="click" data-track-action="rss feed" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nature.rss">
          <span>
           RSS feed
          </span>
         </a>
        </li>
       </ul>
      </div>
     </div>
    </div>
   </header>
   <nav aria-label="breadcrumbs" class="u-mb-16">
    <div class="u-container">
     <ol class="c-breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList">
      <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
       <a class="c-breadcrumbs__link" data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature" href="/" itemprop="item">
        <span itemprop="name">
         nature
        </span>
       </a>
       <meta content="1" itemprop="position"/>
       <svg aria-hidden="true" class="c-breadcrumbs__chevron" focusable="false" height="10" role="img" viewbox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
        </path>
       </svg>
      </li>
      <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
       <a class="c-breadcrumbs__link" data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles" href="/nature/articles?type=article" itemprop="item">
        <span itemprop="name">
         articles
        </span>
       </a>
       <meta content="2" itemprop="position"/>
       <svg aria-hidden="true" class="c-breadcrumbs__chevron" focusable="false" height="10" role="img" viewbox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
        </path>
       </svg>
      </li>
      <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
       <span itemprop="name">
        article
       </span>
       <meta content="3" itemprop="position"/>
      </li>
     </ol>
    </div>
   </nav>
  </div>
  <div class="u-container u-mt-32 u-mb-32 u-clearfix" data-component="article-container" data-container-type="article" id="content">
   <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
    <div aria-hidden="true" class="c-context-bar u-hide" data-context-bar="" data-context-bar-with-recommendations="" data-test="context-bar">
     <div class="c-context-bar__container u-container">
      <div class="c-context-bar__title">
       Mastering the game of Go without human knowledge
      </div>
      <div class="c-pdf-download u-clear-both js-pdf-download">
       <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature24270.pdf">
        <span class="c-pdf-download__text">
         Download PDF
        </span>
        <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
         <use xlink:href="#icon-download">
         </use>
        </svg>
       </a>
      </div>
     </div>
     <div id="recommendations">
      <div class="c-recommendations__container u-container u-display-none" data-component-recommendations="">
       <aside class="c-status-message c-status-message--success u-display-none" data-component-status-msg="">
        <svg aria-label="success:" class="c-status-message__icon" focusable="false" height="24" role="img" width="24">
         <use xlink:href="#icon-success">
         </use>
        </svg>
        <div class="c-status-message__message" id="success-message" tabindex="-1">
         Your content has downloaded
        </div>
       </aside>
       <div class="c-recommendations-header u-display-flex u-justify-content-space-between">
        <h2 class="c-recommendations-title" id="recommendation-heading">
         Similar content being viewed by others
        </h2>
        <button aria-label="Close" class="c-recommendations-close u-flex-static" data-track="click" data-track-action="close recommendations" type="button">
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
          <use xlink:href="#icon-close">
          </use>
         </svg>
        </button>
       </div>
       <section aria-labelledby="recommendation-heading" aria-roledescription="carousel">
        <p class="u-visually-hidden">
         Slider with three content items shown per slide. Use the Previous and Next buttons to navigate the slides or the slide controller buttons at the end to navigate through each slide.
        </p>
        <div class="c-recommendations-list-container">
         <div class="c-recommendations-list">
          <div aria-label="Recommendation 1 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs42256-019-0070-z/MediaObjects/42256_2019_70_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 1" data-track-label="10.1038/s42256-019-0070-z" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s42256-019-0070-z" itemprop="url">
                 Solving the Rubik’s cube with deep reinforcement learning and search
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 15 July 2019
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Forest Agostinelli, Stephen McAleer, … Pierre Baldi
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 2 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41586-023-06124-2/MediaObjects/41586_2023_6124_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 2" data-track-label="10.1038/s41586-023-06124-2" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41586-023-06124-2" itemprop="url">
                 Expertise increases planning depth in human gameplay
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 31 May 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Bas van Opheusden, Ionatan Kuperwajs, … Wei Ji Ma
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 3 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41598-022-08863-0/MediaObjects/41598_2022_8863_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 3" data-track-label="10.1038/s41598-022-08863-0" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41598-022-08863-0" itemprop="url">
                 Using deep learning to predict human decisions and using cognitive models to explain deep learning models
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 18 March 2022
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Matan Fintz, Margarita Osadchy &amp; Uri Hertz
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 4 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41562-023-01648-z/MediaObjects/41562_2023_1648_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 4" data-track-label="10.1038/s41562-023-01648-z" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41562-023-01648-z" itemprop="url">
                 Accelerating science with human-aware artificial intelligence
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 13 July 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Jamshid Sourati &amp; James A. Evans
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 5 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41562-022-01332-8/MediaObjects/41562_2022_1332_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 5" data-track-label="10.1038/s41562-022-01332-8" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41562-022-01332-8" itemprop="url">
                 Rational use of cognitive resources in human planning
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 28 April 2022
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Frederick Callaway, Bas van Opheusden, … Falk Lieder
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 6 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs42256-020-00266-y/MediaObjects/42256_2020_266_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 6" data-track-label="10.1038/s42256-020-00266-y" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s42256-020-00266-y" itemprop="url">
                 Understanding adversarial examples requires a theory of artefacts for deep learning
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 23 November 2020
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Cameron Buckner
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 7 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41593-019-0520-2/MediaObjects/41593_2019_520_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 7" data-track-label="10.1038/s41593-019-0520-2" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41593-019-0520-2" itemprop="url">
                 A deep learning framework for neuroscience
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 28 October 2019
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Blake A. Richards, Timothy P. Lillicrap, … Konrad P. Kording
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 8 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs42256-021-00433-9/MediaObjects/42256_2021_433_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 8" data-track-label="10.1038/s42256-021-00433-9" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s42256-021-00433-9" itemprop="url">
                 Intelligent problem-solving as integrated hierarchical reinforcement learning
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 25 January 2022
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Manfred Eppe, Christian Gumbsch, … Stefan Wermter
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 9 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs42256-019-0025-4/MediaObjects/42256_2019_25_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 9" data-track-label="10.1038/s42256-019-0025-4" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s42256-019-0025-4" itemprop="url">
                 Reinforcement learning in artificial and biological systems
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 04 March 2019
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Emre O. Neftci &amp; Bruno B. Averbeck
              </p>
             </div>
            </div>
           </article>
          </div>
         </div>
        </div>
       </section>
      </div>
      <div class="js-greyout-page-background" data-component-grey-background="" style="display:none">
      </div>
     </div>
    </div>
    <article lang="en">
     <div class="c-article-header">
      <header>
       <ul class="c-article-identifiers" data-test="article-identifier">
        <li class="c-article-identifiers__item">
         <a data-track="click" data-track-action="publication date" data-track-label="link" href="#article-info">
          Published:
          <time datetime="2017-10-19">
           19 October 2017
          </time>
         </a>
        </li>
       </ul>
       <h1 class="c-article-title" data-article-title="" data-test="article-title">
        Mastering the game of Go without human knowledge
       </h1>
       <ul class="c-article-author-list c-article-author-list--short js-no-scroll" data-component-authors-activator="authors-list" data-test="authors-list">
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-David-Silver-Aff1" data-corresp-id="c1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David-Silver-Aff1">
          David Silver
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
           <use xlink:href="#icon-email-new" xmlns:xlink="http://www.w3.org/1999/xlink">
           </use>
          </svg>
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         <sup class="u-js-hide">
          <a href="#na1" tabindex="-1">
           na1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Julian-Schrittwieser-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Julian-Schrittwieser-Aff1">
          Julian Schrittwieser
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         <sup class="u-js-hide">
          <a href="#na1" tabindex="-1">
           na1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Karen-Simonyan-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Karen-Simonyan-Aff1">
          Karen Simonyan
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         <sup class="u-js-hide">
          <a href="#na1" tabindex="-1">
           na1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Ioannis-Antonoglou-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ioannis-Antonoglou-Aff1">
          Ioannis Antonoglou
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Aja-Huang-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Aja-Huang-Aff1">
          Aja Huang
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Arthur-Guez-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Arthur-Guez-Aff1">
          Arthur Guez
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Thomas-Hubert-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Thomas-Hubert-Aff1">
          Thomas Hubert
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Lucas-Baker-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Lucas-Baker-Aff1">
          Lucas Baker
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Matthew-Lai-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Matthew-Lai-Aff1">
          Matthew Lai
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Adrian-Bolton-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Adrian-Bolton-Aff1">
          Adrian Bolton
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Yutian-Chen-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Yutian-Chen-Aff1">
          Yutian Chen
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Timothy-Lillicrap-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Timothy-Lillicrap-Aff1">
          Timothy Lillicrap
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Fan-Hui-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fan-Hui-Aff1">
          Fan Hui
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Laurent-Sifre-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Laurent-Sifre-Aff1">
          Laurent Sifre
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-George-van_den_Driessche-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-George-van_den_Driessche-Aff1">
          George van den Driessche
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Thore-Graepel-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Thore-Graepel-Aff1">
          Thore Graepel
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         &amp;
        </li>
        <li aria-label="Show all 17 authors for this article" class="c-article-author-list__show-more" title="Show all 17 authors for this article">
         …
        </li>
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Demis-Hassabis-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Demis-Hassabis-Aff1">
          Demis Hassabis
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
        </li>
       </ul>
       <button aria-expanded="false" class="c-article-author-list__button">
        <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
         <use xlink:href="#icon-plus" xmlns:xlink="http://www.w3.org/1999/xlink">
         </use>
        </svg>
        <span>
         Show authors
        </span>
       </button>
       <p class="c-article-info-details" data-container-section="info">
        <a data-test="journal-link" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link" href="/">
         <i data-test="journal-title">
          Nature
         </i>
        </a>
        <b data-test="journal-volume">
         <span class="u-visually-hidden">
          volume
         </span>
         550
        </b>
        ,
        <span class="u-visually-hidden">
         pages
        </span>
        354–359 (
        <span data-test="article-publication-year">
         2017
        </span>
        )
        <a class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link" href="#citeas">
         Cite this article
        </a>
       </p>
       <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__count">
           349k
           <span class="c-article-metrics-bar__label">
            Accesses
           </span>
          </p>
         </li>
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__count">
           4431
           <span class="c-article-metrics-bar__label">
            Citations
           </span>
          </p>
         </li>
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__count">
           2516
           <span class="c-article-metrics-bar__label">
            Altmetric
           </span>
          </p>
         </li>
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__details">
           <a data-track="click" data-track-action="view metrics" data-track-label="link" href="/articles/nature24270/metrics" rel="nofollow">
            Metrics
            <span class="u-visually-hidden">
             details
            </span>
           </a>
          </p>
         </li>
        </ul>
       </div>
      </header>
     </div>
     <div class="c-article-body">
      <section aria-labelledby="Abs1" data-title="Abstract" lang="en">
       <div class="c-article-section" id="Abs1-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">
         Abstract
        </h2>
        <div class="c-article-section__content" id="Abs1-content">
         <p>
          A long-standing goal of artificial intelligence is an algorithm that learns,
          <i>
           tabula rasa
          </i>
          , superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting
          <b>
           <i>
            tabula rasa
           </i>
          </b>
          , our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.
         </p>
        </div>
       </div>
      </section>
      <noscript>
       <div class="c-nature-box c-nature-box--side" data-component="entitlement-box">
        <p class="c-nature-box__text js-text">
         You have full access to this article via your institution.
        </p>
        <div class="c-pdf-download u-clear-both js-pdf-download">
         <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature24270.pdf">
          <span class="c-pdf-download__text">
           Download PDF
          </span>
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
           <use xlink:href="#icon-download">
           </use>
          </svg>
         </a>
        </div>
       </div>
      </noscript>
      <div class="js-context-bar-sticky-point-mobile">
       <div aria-hidden="true" class="c-nature-box c-nature-box--side u-display-none u-hide-print" data-component="entitlement-box" id="entitlement-box-entitled-mobile">
        <p aria-hidden="true" class="c-nature-box__text js-text u-display-none">
         You have full access to this article via
         <strong>
          Ohio State University Libraries
         </strong>
        </p>
        <div class="c-pdf-download u-clear-both js-pdf-download">
         <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature24270.pdf">
          <span class="c-pdf-download__text">
           Download PDF
          </span>
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
           <use xlink:href="#icon-download">
           </use>
          </svg>
         </a>
        </div>
       </div>
      </div>
      <div class="main-content">
       <section data-title="Main">
        <div class="c-article-section" id="Sec1-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">
          Main
         </h2>
         <div class="c-article-section__content" id="Sec1-content">
          <p>
           Much progress towards artificial intelligence has been made using supervised learning systems that are trained to replicate the decisions of human experts
           <sup>
            <a aria-label="Reference 1" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR1" id="ref-link-section-d261570943e543" title="Friedman, J., Hastie, T. &amp; Tibshirani, R. The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer, 2009)">
             1
            </a>
            ,
            <a aria-label="Reference 2" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR2" id="ref-link-section-d261570943e546" title="LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning. Nature 521, 436–444 (2015)">
             2
            </a>
            ,
            <a aria-label="Reference 3" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR3" id="ref-link-section-d261570943e549" title="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. In Adv. Neural Inf. Process. Syst. Vol. 25 (eds Pereira, F., Burges, C. J. C., Bottou, L. &amp; Weinberger, K. Q. ) 1097–1105 (2012)">
             3
            </a>
            ,
            <a aria-label="Reference 4" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR4" id="ref-link-section-d261570943e552" title="He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit. 770–778 (2016)">
             4
            </a>
           </sup>
           . However, expert data sets are often expensive, unreliable or simply unavailable. Even when reliable data sets are available, they may impose a ceiling on the performance of systems trained in this manner
           <sup>
            <a aria-label="Reference 5" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR5" id="ref-link-section-d261570943e556" title="Hayes-Roth, F., Waterman, D. &amp; Lenat, D. Building Expert Systems (Addison-Wesley, 1984)">
             5
            </a>
           </sup>
           . By contrast, reinforcement learning systems are trained from their own experience, in principle allowing them to exceed human capabilities, and to operate in domains where human expertise is lacking. Recently, there has been rapid progress towards this goal, using deep neural networks trained by reinforcement learning. These systems have outperformed humans in computer games, such as Atari
           <sup>
            <a aria-label="Reference 6" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR6" id="ref-link-section-d261570943e560" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)">
             6
            </a>
            ,
            <a aria-label="Reference 7" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR7" id="ref-link-section-d261570943e563" title="Guo, X., Singh, S. P., Lee, H., Lewis, R. L. &amp; Wang, X. Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning. In Adv. Neural Inf. Process. Syst. Vol. 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D. &amp; Weinberger, K. Q. ) 3338–3346 (2014)">
             7
            </a>
           </sup>
           and 3D virtual environments
           <sup>
            <a aria-label="Reference 8" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR8" id="ref-link-section-d261570943e567" title="Mnih, V . et al. Asynchronous methods for deep reinforcement learning. In Proc. 33rd Int. Conf. Mach. Learn. Vol. 48 (eds Balcan, M. F. &amp; Weinberger, K. Q. ) 1928–1937 (2016)">
             8
            </a>
            ,
            <a aria-label="Reference 9" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR9" id="ref-link-section-d261570943e570" title="Jaderberg, M . et al. Reinforcement learning with unsupervised auxiliary tasks. In 5th Int. Conf. Learn. Representations (2017)">
             9
            </a>
            ,
            <a aria-label="Reference 10" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR10" id="ref-link-section-d261570943e573" title="Dosovitskiy, A. &amp; Koltun, V. Learning to act by predicting the future. In 5th Int. Conf. Learn. Representations (2017)">
             10
            </a>
           </sup>
           . However, the most challenging domains in terms of human intellect—such as the game of Go, widely viewed as a grand challenge for artificial intelligence
           <sup>
            <a aria-label="Reference 11" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR11" id="ref-link-section-d261570943e577" title="Man´dziuk, J. in Challenges for Computational Intelligence ( Duch, W. &amp; Man´dziuk, J. ) 407–442 (Springer, 2007)">
             11
            </a>
           </sup>
           —require a precise and sophisticated lookahead in vast search spaces. Fully general methods have not previously achieved human-level performance in these domains.
          </p>
          <p>
           AlphaGo was the first program to achieve superhuman performance in Go. The published version
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e584" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           , which we refer to as AlphaGo Fan, defeated the European champion Fan Hui in October 2015. AlphaGo Fan used two deep neural networks: a policy network that outputs move probabilities and a value network that outputs a position evaluation. The policy network was trained initially by supervised learning to accurately predict human expert moves, and was subsequently refined by policy-gradient reinforcement learning. The value network was trained to predict the winner of games played by the policy network against itself. Once trained, these networks were combined with a Monte Carlo tree search (MCTS)
           <sup>
            <a aria-label="Reference 13" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR13" id="ref-link-section-d261570943e588" title="Coulom, R. Efficient selectivity and backup operators in Monte-Carlo tree search. In 5th Int. Conf. Computers and Games (eds Ciancarini, P. &amp; van den Herik, H. J. ) 72–83 (2006)">
             13
            </a>
            ,
            <a aria-label="Reference 14" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR14" id="ref-link-section-d261570943e591" title="Kocsis, L. &amp; Szepesvári, C. Bandit based Monte-Carlo planning. In 15th Eu. Conf. Mach. Learn. 282–293 (2006)">
             14
            </a>
            ,
            <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR15" id="ref-link-section-d261570943e594" title="Browne, C. et al. A survey of Monte Carlo tree search methods. IEEE Trans. Comput. Intell. AI Games 4, 1–49 (2012)">
             15
            </a>
           </sup>
           to provide a lookahead search, using the policy network to narrow down the search to high-probability moves, and using the value network (in conjunction with Monte Carlo rollouts using a fast rollout policy) to evaluate positions in the tree. A subsequent version, which we refer to as AlphaGo Lee, used a similar approach (see Methods), and defeated Lee Sedol, the winner of 18 international titles, in March 2016.
          </p>
          <p>
           Our program, AlphaGo Zero, differs from AlphaGo Fan and AlphaGo Lee
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e601" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           in several important aspects. First and foremost, it is trained solely by self-play reinforcement learning, starting from random play, without any supervision or use of human data. Second, it uses only the black and white stones from the board as input features. Third, it uses a single neural network, rather than separate policy and value networks. Finally, it uses a simpler tree search that relies upon this single neural network to evaluate positions and sample moves, without performing any Monte Carlo rollouts. To achieve these results, we introduce a new reinforcement learning algorithm that incorporates lookahead search inside the training loop, resulting in rapid improvement and precise and stable learning. Further technical differences in the search algorithm, training procedure and network architecture are described in Methods.
          </p>
         </div>
        </div>
       </section>
       <section data-title="Reinforcement learning in AlphaGo Zero">
        <div class="c-article-section" id="Sec2-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">
          Reinforcement learning in AlphaGo Zero
         </h2>
         <div class="c-article-section__content" id="Sec2-content">
          <p>
           Our new method uses a deep neural network
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           with parameters
           <i>
            θ
           </i>
           . This neural network takes as an input the raw board representation
           <i>
            s
           </i>
           of the position and its history, and outputs both move probabilities and a value, (
           <b>
            <i>
             p
            </i>
           </b>
           ,
           <i>
            v
           </i>
           ) =
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           (
           <i>
            s
           </i>
           ). The vector of move probabilities
           <b>
            <i>
             p
            </i>
           </b>
           represents the probability of selecting each move
           <i>
            a
           </i>
           (including pass),
           <i>
            p
           </i>
           <sub>
            <i>
             a
            </i>
           </sub>
           = Pr(
           <i>
            a
           </i>
           |
           <i>
            s
           </i>
           ). The value
           <i>
            v
           </i>
           is a scalar evaluation, estimating the probability of the current player winning from position
           <i>
            s
           </i>
           . This neural network combines the roles of both policy network and value network
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e666" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           into a single architecture. The neural network consists of many residual blocks
           <sup>
            <a aria-label="Reference 4" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR4" id="ref-link-section-d261570943e670" title="He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit. 770–778 (2016)">
             4
            </a>
           </sup>
           of convolutional layers
           <sup>
            <a aria-label="Reference 16" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR16" id="ref-link-section-d261570943e675" title="Fukushima, K. Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biol. Cybern. 36, 193–202 (1980)">
             16
            </a>
            ,
            <a aria-label="Reference 17" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR17" id="ref-link-section-d261570943e678" title="LeCun, Y. &amp; Bengio, Y. in The Handbook of Brain Theory and Neural Networks Ch. 3 (ed. Arbib, M. ) 276–278 (MIT Press, 1995)">
             17
            </a>
           </sup>
           with batch normalization
           <sup>
            <a aria-label="Reference 18" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR18" id="ref-link-section-d261570943e682" title="Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 448–456 (2015)">
             18
            </a>
           </sup>
           and rectifier nonlinearities
           <sup>
            <a aria-label="Reference 19" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR19" id="ref-link-section-d261570943e686" title="Hahnloser, R. H. R., Sarpeshkar, R., Mahowald, M. A., Douglas, R. J. &amp; Seung, H. S. Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit. Nature 405, 947–951 (2000)">
             19
            </a>
           </sup>
           (see Methods).
          </p>
          <p>
           The neural network in AlphaGo Zero is trained from games of self-play by a novel reinforcement learning algorithm. In each position
           <i>
            s
           </i>
           , an MCTS search is executed, guided by the neural network
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           . The MCTS search outputs probabilities
           <i>
            π
           </i>
           of playing each move. These search probabilities usually select much stronger moves than the raw move probabilities
           <b>
            <i>
             p
            </i>
           </b>
           of the neural network
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           (
           <i>
            s
           </i>
           ); MCTS may therefore be viewed as a powerful policy improvement operator
           <sup>
            <a aria-label="Reference 20" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR20" id="ref-link-section-d261570943e718" title="Howard, R. Dynamic Programming and Markov Processes (MIT Press, 1960)">
             20
            </a>
            ,
            <a aria-label="Reference 21" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR21" id="ref-link-section-d261570943e721" title="Sutton, R . &amp; Barto, A. Reinforcement Learning: an Introduction (MIT Press, 1998)">
             21
            </a>
           </sup>
           . Self-play with search—using the improved MCTS-based policy to select each move, then using the game winner
           <i>
            z
           </i>
           as a sample of the value—may be viewed as a powerful policy evaluation operator. The main idea of our reinforcement learning algorithm is to use these search operators repeatedly in a policy iteration procedure
           <sup>
            <a aria-label="Reference 22" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR22" id="ref-link-section-d261570943e728" title="Bertsekas, D. P. Approximate policy iteration: a survey and some new methods. J. Control Theory Appl. 9, 310–335 (2011)">
             22
            </a>
            ,
            <a aria-label="Reference 23" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR23" id="ref-link-section-d261570943e731" title="Scherrer, B. Approximate policy iteration schemes: a comparison. In Proc. 31st Int. Conf. Mach. Learn. Vol. 32 1314–1322 (2014)">
             23
            </a>
           </sup>
           : the neural network’s parameters are updated to make the move probabilities and value (
           <b>
            <i>
             p
            </i>
           </b>
           ,
           <i>
            v
           </i>
           ) =
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           (
           <i>
            s
           </i>
           ) more closely match the improved search probabilities and self-play winner (
           <i>
            π
           </i>
           ,
           <i>
            z
           </i>
           ); these new parameters are used in the next iteration of self-play to make the search even stronger.
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig1">
            Figure 1
           </a>
           illustrates the self-play training pipeline.
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Self-play reinforcement learning in AlphaGo Zero." id="figure-1">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig1">
              Figure 1: Self-play reinforcement learning in AlphaGo Zero.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature24270/figures/1" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 1" aria-describedby="Fig1" height="621" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc">
              <p>
               <b>
                a
               </b>
               , The program plays a game
               <i>
                s
               </i>
               <sub>
                1
               </sub>
               , ...,
               <i>
                s
               </i>
               <sub>
                <i>
                 T
                </i>
               </sub>
               against itself. In each position
               <i>
                s
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               , an MCTS
               <i>
                α
               </i>
               <sub>
                <i>
                 θ
                </i>
               </sub>
               is executed (see
               <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
                Fig. 2
               </a>
               ) using the latest neural network
               <i>
                f
               </i>
               <sub>
                <i>
                 θ
                </i>
               </sub>
               . Moves are selected according to the search probabilities computed by the MCTS,
               <i>
                a
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               <span class="stix">
                ∼
               </span>
               <i>
                π
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               . The terminal position
               <i>
                s
               </i>
               <sub>
                <i>
                 T
                </i>
               </sub>
               is scored according to the rules of the game to compute the game winner
               <i>
                z
               </i>
               .
               <b>
                b
               </b>
               , Neural network training in AlphaGo Zero. The neural network takes the raw board position
               <i>
                s
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               as its input, passes it through many convolutional layers with parameters
               <i>
                θ
               </i>
               , and outputs both a vector
               <b>
                <i>
                 p
                </i>
               </b>
               <sub>
                <i>
                 t
                </i>
               </sub>
               , representing a probability distribution over moves, and a scalar value
               <i>
                v
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               , representing the probability of the current player winning in position
               <i>
                s
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               . The neural network parameters
               <i>
                θ
               </i>
               are updated to maximize the similarity of the policy vector
               <b>
                <i>
                 p
                </i>
               </b>
               <sub>
                <i>
                 t
                </i>
               </sub>
               to the search probabilities
               <i>
                π
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               , and to minimize the error between the predicted winner
               <i>
                v
               </i>
               <sub>
                <i>
                 t
                </i>
               </sub>
               and the game winner
               <i>
                z
               </i>
               (see equation (1)). The new parameters are used in the next iteration of self-play as in
               <b>
                a
               </b>
               .
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM3">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 1" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure1 Full size image" data-track-label="button" href="/articles/nature24270/figures/1" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           The MCTS uses the neural network
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           to guide its simulations (see
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2
           </a>
           ). Each edge (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) in the search tree stores a prior probability
           <i>
            P
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ), a visit count
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ), and an action value
           <i>
            Q
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ). Each simulation starts from the root state and iteratively selects moves that maximize an upper confidence bound
           <i>
            Q
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) +
           <i>
            U
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ), where
           <i>
            U
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           )
           <span class="stix">
            ∝
           </span>
           <i>
            P
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) / (1 +
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           )) (refs
           <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e996" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
            12
           </a>
           ,
           <a aria-label="Reference 24" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR24" id="ref-link-section-d261570943e1000" title="Rosin, C. D. Multi-armed bandits with episode context. Ann. Math. Artif. Intell. 61, 203–230 (2011)">
            24
           </a>
           ), until a leaf node
           <i>
            s′
           </i>
           is encountered. This leaf position is expanded and evaluated only once by the network to generate both prior probabilities and evaluation, (
           <i>
            P
           </i>
           (
           <i>
            s
           </i>
           ′, ·),
           <i>
            V
           </i>
           (
           <i>
            s
           </i>
           ′)) =
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           (
           <i>
            s
           </i>
           ′). Each edge (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) traversed in the simulation is updated to increment its visit count
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ), and to update its action value to the mean evaluation over these simulations,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw257/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq1_HTML.gif"/>
           where
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           →
           <i>
            s
           </i>
           ′ indicates that a simulation eventually reached
           <i>
            s
           </i>
           ′ after taking move
           <i>
            a
           </i>
           from position
           <i>
            s
           </i>
           .
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="MCTS in AlphaGo Zero." id="figure-2">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig2">
              Figure 2: MCTS in AlphaGo Zero.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature24270/figures/2" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig2_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 2" aria-describedby="Fig2" height="185" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig2_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc">
              <p>
               <b>
                a
               </b>
               , Each simulation traverses the tree by selecting the edge with maximum action value
               <i>
                Q
               </i>
               , plus an upper confidence bound
               <i>
                U
               </i>
               that depends on a stored prior probability
               <i>
                P
               </i>
               and visit count
               <i>
                N
               </i>
               for that edge (which is incremented once traversed).
               <b>
                b
               </b>
               , The leaf node is expanded and the associated position
               <i>
                s
               </i>
               is evaluated by the neural network (
               <i>
                P
               </i>
               (
               <i>
                s
               </i>
               , ·),
               <i>
                V
               </i>
               (
               <i>
                s
               </i>
               )) =
               <i>
                f
               </i>
               <sub>
                <i>
                 θ
                </i>
               </sub>
               (
               <i>
                s
               </i>
               ); the vector of
               <i>
                P
               </i>
               values are stored in the outgoing edges from
               <i>
                s
               </i>
               .
               <b>
                c
               </b>
               , Action value
               <i>
                Q
               </i>
               is updated to track the mean of all evaluations
               <i>
                V
               </i>
               in the subtree below that action.
               <b>
                d
               </b>
               , Once the search is complete, search probabilities
               <i>
                π
               </i>
               are returned, proportional to
               <i>
                N
               </i>
               <sup>
                1/
                <i>
                 τ
                </i>
               </sup>
               , where
               <i>
                N
               </i>
               is the visit count of each move from the root state and
               <i>
                τ
               </i>
               is a parameter controlling temperature.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM4">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 2" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure2 Full size image" data-track-label="button" href="/articles/nature24270/figures/2" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           MCTS may be viewed as a self-play algorithm that, given neural network parameters
           <i>
            θ
           </i>
           and a root position
           <i>
            s
           </i>
           , computes a vector of search probabilities recommending moves to play,
           <i>
            π
           </i>
           =
           <i>
            α
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           (
           <i>
            s
           </i>
           ), proportional to the exponentiated visit count for each move,
           <i>
            π
           </i>
           <sub>
            <i>
             a
            </i>
           </sub>
           <span class="stix">
            ∝
           </span>
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           )
           <sup>
            1/
            <i>
             τ
            </i>
           </sup>
           , where
           <i>
            τ
           </i>
           is a temperature parameter.
          </p>
          <p>
           The neural network is trained by a self-play reinforcement learning algorithm that uses MCTS to play each move. First, the neural network is initialized to random weights
           <i>
            θ
           </i>
           <sub>
            0
           </sub>
           . At each subsequent iteration
           <i>
            i
           </i>
           ≥ 1, games of self-play are generated (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig1">
            Fig. 1a
           </a>
           ). At each time-step
           <i>
            t
           </i>
           , an MCTS search
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw99/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq2_HTML.gif" style="width:99px;max-width:none;"/>
           is executed using the previous iteration of neural network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw31/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq3_HTML.gif" style="width:31px;max-width:none;"/>
           and a move is played by sampling the search probabilities
           <i>
            π
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           . A game terminates at step
           <i>
            T
           </i>
           when both players pass, when the search value drops below a resignation threshold or when the game exceeds a maximum length; the game is then scored to give a final reward of
           <i>
            r
           </i>
           <sub>
            <i>
             T
            </i>
           </sub>
           <span class="stix">
            ∈
           </span>
           {−1,+1} (see Methods for details). The data for each time-step
           <i>
            t
           </i>
           is stored as (
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            π
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            z
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ), where
           <i>
            z
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           = ±
           <i>
            r
           </i>
           <sub>
            <i>
             T
            </i>
           </sub>
           is the game winner from the perspective of the current player at step
           <i>
            t
           </i>
           . In parallel (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig1">
            Fig. 1b
           </a>
           ), new network parameters
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           are trained from data (
           <i>
            s
           </i>
           ,
           <i>
            π
           </i>
           ,
           <i>
            z
           </i>
           ) sampled uniformly among all time-steps of the last iteration(s) of self-play. The neural network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw97/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq4_HTML.gif" style="width:97px;max-width:none;"/>
           is adjusted to minimize the error between the predicted value
           <i>
            v
           </i>
           and the self-play winner
           <i>
            z
           </i>
           , and to maximize the similarity of the neural network move probabilities
           <b>
            <i>
             p
            </i>
           </b>
           to the search probabilities
           <i>
            π
           </i>
           . Specifically, the parameters
           <i>
            θ
           </i>
           are adjusted by gradient descent on a loss function
           <i>
            l
           </i>
           that sums over the mean-squared error and cross-entropy losses, respectively:
          </p>
          <div class="c-article-equation" id="Equ1">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw461/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Equ1_HTML.gif"/>
           </div>
          </div>
          <p>
           where
           <i>
            c
           </i>
           is a parameter controlling the level of L2 weight regularization (to prevent overfitting).
          </p>
         </div>
        </div>
       </section>
       <section data-title="Empirical analysis of AlphaGo Zero training">
        <div class="c-article-section" id="Sec3-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">
          Empirical analysis of AlphaGo Zero training
         </h2>
         <div class="c-article-section__content" id="Sec3-content">
          <p>
           We applied our reinforcement learning pipeline to train our program AlphaGo Zero. Training started from completely random behaviour and continued without human intervention for approximately three days.
          </p>
          <p>
           Over the course of training, 4.9 million games of self-play were generated, using 1,600 simulations for each MCTS, which corresponds to approximately 0.4 s thinking time per move. Parameters were updated from 700,000 mini-batches of 2,048 positions. The neural network contained 20 residual blocks (see Methods for further details).
          </p>
          <p>
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig3">
            Figure 3a
           </a>
           shows the performance of AlphaGo Zero during self-play reinforcement learning, as a function of training time, on an Elo scale
           <sup>
            <a aria-label="Reference 25" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR25" id="ref-link-section-d261570943e1383" title="Coulom, R. Whole-history rating: a Bayesian rating system for players of time-varying strength. In Int. Conf. Comput. Games (eds van den Herik, H. J., Xu, X . Ma, Z . &amp; Winands, M. H. M. ) Vol. 5131 113–124 (Springer, 2008)">
             25
            </a>
           </sup>
           . Learning progressed smoothly throughout training, and did not suffer from the oscillations or catastrophic forgetting that have been suggested in previous literature
           <sup>
            <a aria-label="Reference 26" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR26" id="ref-link-section-d261570943e1387" title="Laurent, G. J., Matignon, L. &amp; Le Fort-Piat, N. The world of independent learners is not Markovian. Int. J. Knowledge-Based Intelligent Engineering Systems 15, 55–64 (2011)">
             26
            </a>
            ,
            <a aria-label="Reference 27" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR27" id="ref-link-section-d261570943e1390" title="Foerster, J. N . et al. Stabilising experience replay for deep multi-agent reinforcement learning. In Proc. 34th Int. Conf. Mach. Learn. Vol. 70 1146–1155 (2017)">
             27
            </a>
            ,
            <a aria-label="Reference 28" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR28" id="ref-link-section-d261570943e1393" title="Heinrich, J . &amp; Silver, D. Deep reinforcement learning from self-play in imperfect-information games. In NIPS Deep Reinforcement Learning Workshop (2016)">
             28
            </a>
           </sup>
           . Surprisingly, AlphaGo Zero outperformed AlphaGo Lee after just 36 h. In comparison, AlphaGo Lee was trained over several months. After 72 h, we evaluated AlphaGo Zero against the exact version of AlphaGo Lee that defeated Lee Sedol, under the same 2 h time controls and match conditions that were used in the man–machine match in Seoul (see Methods). AlphaGo Zero used a single machine with 4 tensor processing units (TPUs)
           <sup>
            <a aria-label="Reference 29" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR29" id="ref-link-section-d261570943e1397" title="Jouppi, N. P . et al. In-datacenter performance analysis of a Tensor Processing Unit. Proc. 44th Annu. Int. Symp. Comp. Architecture Vol. 17 1–12 (2017)">
             29
            </a>
           </sup>
           , whereas AlphaGo Lee was distributed over many machines and used 48 TPUs. AlphaGo Zero defeated AlphaGo Lee by 100 games to 0 (see
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig7">
            Extended Data Fig. 1
           </a>
           and
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
            Supplementary Information
           </a>
           ).
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Empirical evaluation of AlphaGo Zero." id="figure-3">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig3">
              Figure 3: Empirical evaluation of AlphaGo Zero.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature24270/figures/3" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig3_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 3" aria-describedby="Fig3" height="219" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig3_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc">
              <p>
               <b>
                a
               </b>
               , Performance of self-play reinforcement learning. The plot shows the performance of each MCTS player
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq22_HTML.gif" style="width:19px;max-width:none;"/>
               from each iteration
               <i>
                i
               </i>
               of reinforcement learning in AlphaGo Zero. Elo ratings were computed from evaluation games between different players, using 0.4 s of thinking time per move (see Methods). For comparison, a similar player trained by supervised learning from human data, using the KGS dataset, is also shown.
               <b>
                b
               </b>
               , Prediction accuracy on human professional moves. The plot shows the accuracy of the neural network
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw16/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq23_HTML.gif" style="width:16px;max-width:none;"/>
               , at each iteration of self-play
               <i>
                i
               </i>
               , in predicting human professional moves from the GoKifu dataset. The accuracy measures the percentage of positions in which the neural network assigns the highest probability to the human move. The accuracy of a neural network trained by supervised learning is also shown.
               <b>
                c
               </b>
               , Mean-squared error (MSE) of human professional game outcomes. The plot shows the MSE of the neural network
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw16/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq24_HTML.gif" style="width:16px;max-width:none;"/>
               , at each iteration of self-play
               <i>
                i
               </i>
               , in predicting the outcome of human professional games from the GoKifu dataset. The MSE is between the actual outcome
               <i>
                z
               </i>
               <span class="stix">
                ∈
               </span>
               {−1, +1} and the neural network value
               <i>
                v
               </i>
               , scaled by a factor of
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw9/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq25_HTML.gif" style="width:9px;max-width:none;"/>
               to the range of 0–1. The MSE of a neural network trained by supervised learning is also shown.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM5">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 3" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure3 Full size image" data-track-label="button" href="/articles/nature24270/figures/3" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           To assess the merits of self-play reinforcement learning, compared to learning from human data, we trained a second neural network (using the same architecture) to predict expert moves in the KGS Server dataset; this achieved state-of-the-art prediction accuracy compared to previous work
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e1493" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
            ,
            <a aria-label="Reference 30" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR30" id="ref-link-section-d261570943e1496" title="Maddison, C. J., Huang, A., Sutskever, I . &amp; Silver, D. Move evaluation in Go using deep convolutional neural networks. In 3rd Int. Conf. Learn. Representations. (2015)">
             30
            </a>
            ,
            <a aria-label="Reference 31" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR31" id="ref-link-section-d261570943e1499" title="Clark, C . &amp; Storkey, A. J. Training deep convolutional neural networks to play Go. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 1766–1774 (2015)">
             31
            </a>
            ,
            <a aria-label="Reference 32" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR32" id="ref-link-section-d261570943e1502" title="Tian, Y. &amp; Zhu, Y. Better computer Go player with neural network and long-term prediction. In 4th Int. Conf. Learn. Representations (2016)">
             32
            </a>
            ,
            <a aria-label="Reference 33" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR33" id="ref-link-section-d261570943e1505" title="Cazenave, T. Residual networks for computer Go. IEEE Trans. Comput. Intell. AI Games 
                    https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042
                    
                   (2017)">
             33
            </a>
           </sup>
           (see
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature24270#Tab1">
            Extended Data Tables 1
           </a>
           and
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature24270#Tab2">
            2
           </a>
           for current and previous results, respectively). Supervised learning achieved a better initial performance, and was better at predicting human professional moves (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig3">
            Fig. 3
           </a>
           ). Notably, although supervised learning achieved higher move prediction accuracy, the self-learned player performed much better overall, defeating the human-trained player within the first 24 h of training. This suggests that AlphaGo Zero may be learning a strategy that is qualitatively different to human play.
          </p>
          <p>
           To separate the contributions of architecture and algorithm, we compared the performance of the neural network architecture in AlphaGo Zero with the previous neural network architecture used in AlphaGo Lee (see
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig4">
            Fig. 4
           </a>
           ). Four neural networks were created, using either separate policy and value networks, as were used in AlphaGo Lee, or combined policy and value networks, as used in AlphaGo Zero; and using either the convolutional network architecture from AlphaGo Lee or the residual network architecture from AlphaGo Zero. Each network was trained to minimize the same loss function (equation (1)), using a fixed dataset of self-play games generated by AlphaGo Zero after 72 h of self-play training. Using a residual network was more accurate, achieved lower error and improved performance in AlphaGo by over 600 Elo. Combining policy and value together into a single network slightly reduced the move prediction accuracy, but reduced the value error and boosted playing performance in AlphaGo by around another 600 Elo. This is partly due to improved computational efficiency, but more importantly the dual objective regularizes the network to a common representation that supports multiple use cases.
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Comparison of neural network architectures in AlphaGo Zero and AlphaGo Lee." id="figure-4">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig4">
              Figure 4: Comparison of neural network architectures in AlphaGo Zero and AlphaGo Lee.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature24270/figures/4" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig4_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 4" aria-describedby="Fig4" height="330" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig4_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc">
              <p>
               Comparison of neural network architectures using either separate (sep) or combined policy and value (dual) networks, and using either convolutional (conv) or residual (res) networks. The combinations ‘dual–res’ and ‘sep–conv’ correspond to the neural network architectures used in AlphaGo Zero and AlphaGo Lee, respectively. Each network was trained on a fixed dataset generated by a previous run of AlphaGo Zero.
               <b>
                a
               </b>
               , Each trained network was combined with AlphaGo Zero’s search to obtain a different player. Elo ratings were computed from evaluation games between these different players, using 5 s of thinking time per move.
               <b>
                b
               </b>
               , Prediction accuracy on human professional moves (from the GoKifu dataset) for each network architecture.
               <b>
                c
               </b>
               MSE of human professional game outcomes (from the GoKifu dataset) for each network architecture.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM6">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 4" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure4 Full size image" data-track-label="button" href="/articles/nature24270/figures/4" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
         </div>
        </div>
       </section>
       <section data-title="Knowledge learned by AlphaGo Zero">
        <div class="c-article-section" id="Sec4-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">
          Knowledge learned by AlphaGo Zero
         </h2>
         <div class="c-article-section__content" id="Sec4-content">
          <p>
           AlphaGo Zero discovered a remarkable level of Go knowledge during its self-play training process. This included not only fundamental elements of human Go knowledge, but also non-standard strategies beyond the scope of traditional Go knowledge.
          </p>
          <p>
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig5">
            Figure 5
           </a>
           shows a timeline indicating when professional
           <i>
            joseki
           </i>
           (corner sequences) were discovered (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig5">
            Fig. 5a
           </a>
           and
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig8">
            Extended Data Fig. 2
           </a>
           ); ultimately AlphaGo Zero preferred new
           <i>
            joseki
           </i>
           variants that were previously unknown (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig5">
            Fig. 5b
           </a>
           and
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig9">
            Extended Data Fig. 3
           </a>
           ).
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig5">
            Figure 5c
           </a>
           shows several fast self-play games played at different stages of training (see
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
            Supplementary Information
           </a>
           ). Tournament length games played at regular intervals throughout training are shown in
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig10">
            Extended Data Fig. 4
           </a>
           and in the
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
            Supplementary Information
           </a>
           . AlphaGo Zero rapidly progressed from entirely random moves towards a sophisticated understanding of Go concepts, including
           <i>
            fuseki
           </i>
           (opening),
           <i>
            tesuji
           </i>
           (tactics), life-and-death,
           <i>
            ko
           </i>
           (repeated board situations),
           <i>
            yose
           </i>
           (endgame), capturing races,
           <i>
            sente
           </i>
           (initiative), shape, influence and territory, all discovered from first principles. Surprisingly,
           <i>
            shicho
           </i>
           (‘ladder’ capture sequences that may span the whole board)—one of the first elements of Go knowledge learned by humans—were only understood by AlphaGo Zero much later in training.
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Go knowledge learned by AlphaGo Zero." id="figure-5">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig5">
              Figure 5: Go knowledge learned by AlphaGo Zero.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature24270/figures/5" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig5_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 5" aria-describedby="Fig5" height="602" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig5_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc">
              <p>
               <b>
                a
               </b>
               , Five human
               <i>
                joseki
               </i>
               (common corner sequences) discovered during AlphaGo Zero training. The associated timestamps indicate the first time each sequence occurred (taking account of rotation and reflection) during self-play training.
               <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig8">
                Extended Data Figure 2
               </a>
               provides the frequency of occurence over training for each sequence.
               <b>
                b
               </b>
               , Five
               <i>
                joseki
               </i>
               favoured at different stages of self-play training. Each displayed corner sequence was played with the greatest frequency, among all corner sequences, during an iteration of self-play training. The timestamp of that iteration is indicated on the timeline. At 10 h a weak corner move was preferred. At 47 h the 3–3 invasion was most frequently played. This
               <i>
                joseki
               </i>
               is also common in human professional play; however AlphaGo Zero later discovered and preferred a new variation.
               <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig9">
                Extended Data Figure 3
               </a>
               provides the frequency of occurence over time for all five sequences and the new variation.
               <b>
                c
               </b>
               , The first 80 moves of three self-play games that were played at different stages of training, using 1,600 simulations (around 0.4 s) per search. At 3 h, the game focuses greedily on capturing stones, much like a human beginner. At 19 h, the game exhibits the fundamentals of life-and-death, influence and territory. At 70 h, the game is remarkably balanced, involving multiple battles and a complicated
               <i>
                ko
               </i>
               fight, eventually resolving into a half-point win for white. See
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
                Supplementary Information
               </a>
               for the full games.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM7">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 5" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure5 Full size image" data-track-label="button" href="/articles/nature24270/figures/5" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
         </div>
        </div>
       </section>
       <section data-title="Final performance of AlphaGo Zero">
        <div class="c-article-section" id="Sec5-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">
          Final performance of AlphaGo Zero
         </h2>
         <div class="c-article-section__content" id="Sec5-content">
          <p>
           We subsequently applied our reinforcement learning pipeline to a second instance of AlphaGo Zero using a larger neural network and over a longer duration. Training again started from completely random behaviour and continued for approximately 40 days.
          </p>
          <p>
           Over the course of training, 29 million games of self-play were generated. Parameters were updated from 3.1 million mini-batches of 2,048 positions each. The neural network contained 40 residual blocks. The learning curve is shown in
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig6">
            Fig. 6a
           </a>
           . Games played at regular intervals throughout training are shown in
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig11">
            Extended Data Fig. 5
           </a>
           and in the
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
            Supplementary Information
           </a>
           .
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Performance of AlphaGo Zero." id="figure-6">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig6">
              Figure 6: Performance of AlphaGo Zero.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature24270/figures/6" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig6_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 6" aria-describedby="Fig6" height="276" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig6_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc">
              <p>
               <b>
                a
               </b>
               , Learning curve for AlphaGo Zero using a larger 40-block residual network over 40 days. The plot shows the performance of each player
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq26_HTML.gif" style="width:19px;max-width:none;"/>
               from each iteration
               <i>
                i
               </i>
               of our reinforcement learning algorithm. Elo ratings were computed from evaluation games between different players, using 0.4 s per search (see Methods).
               <b>
                b
               </b>
               , Final performance of AlphaGo Zero. AlphaGo Zero was trained for 40 days using a 40-block residual neural network. The plot shows the results of a tournament between: AlphaGo Zero, AlphaGo Master (defeated top human professionals 60–0 in online games), AlphaGo Lee (defeated Lee Sedol), AlphaGo Fan (defeated Fan Hui), as well as previous Go programs Crazy Stone, Pachi and GnuGo. Each program was given 5 s of thinking time per move. AlphaGo Zero and AlphaGo Master played on a single machine on the Google Cloud; AlphaGo Fan and AlphaGo Lee were distributed over many machines. The raw neural network from AlphaGo Zero is also included, which directly selects the move
               <i>
                a
               </i>
               with maximum probability
               <i>
                p
               </i>
               <sub>
                <i>
                 a
                </i>
               </sub>
               , without using MCTS. Programs were evaluated on an Elo scale
               <sup>
                <a aria-label="Reference 25" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR25" id="ref-link-section-d261570943e1737" title="Coulom, R. Whole-history rating: a Bayesian rating system for players of time-varying strength. In Int. Conf. Comput. Games (eds van den Herik, H. J., Xu, X . Ma, Z . &amp; Winands, M. H. M. ) Vol. 5131 113–124 (Springer, 2008)">
                 25
                </a>
               </sup>
               : a 200-point gap corresponds to a 75% probability of winning.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM8">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 6" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure6 Full size image" data-track-label="button" href="/articles/nature24270/figures/6" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           We evaluated the fully trained AlphaGo Zero using an internal tournament against AlphaGo Fan, AlphaGo Lee and several previous Go programs. We also played games against the strongest existing program, AlphaGo Master—a program based on the algorithm and architecture presented in this paper but using human data and features (see Methods)—which defeated the strongest human professional players 60–0 in online games in January 2017
           <sup>
            <a aria-label="Reference 34" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR34" id="ref-link-section-d261570943e1758" title="Huang, A. AlphaGo master online series of games. 
                    https://deepmind.com/research/AlphaGo/match-archive/master
                    
                   (2017)">
             34
            </a>
           </sup>
           . In our evaluation, all programs were allowed 5 s of thinking time per move; AlphaGo Zero and AlphaGo Master each played on a single machine with 4 TPUs; AlphaGo Fan and AlphaGo Lee were distributed over 176 GPUs and 48 TPUs, respectively. We also included a player based solely on the raw neural network of AlphaGo Zero; this player simply selected the move with maximum probability.
          </p>
          <p>
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig6">
            Figure 6b
           </a>
           shows the performance of each program on an Elo scale. The raw neural network, without using any lookahead, achieved an Elo rating of 3,055. AlphaGo Zero achieved a rating of 5,185, compared to 4,858 for AlphaGo Master, 3,739 for AlphaGo Lee and 3,144 for AlphaGo Fan.
          </p>
          <p>
           Finally, we evaluated AlphaGo Zero head to head against AlphaGo Master in a 100-game match with 2-h time controls. AlphaGo Zero won by 89 games to 11 (see
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig12">
            Extended Data Fig. 6
           </a>
           and
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
            Supplementary Information
           </a>
           ).
          </p>
         </div>
        </div>
       </section>
       <section data-title="Conclusion">
        <div class="c-article-section" id="Sec6-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6">
          Conclusion
         </h2>
         <div class="c-article-section__content" id="Sec6-content">
          <p>
           Our results comprehensively demonstrate that a pure reinforcement learning approach is fully feasible, even in the most challenging of domains: it is possible to train to superhuman level, without human examples or guidance, given no knowledge of the domain beyond basic rules. Furthermore, a pure reinforcement learning approach requires just a few more hours to train, and achieves much better asymptotic performance, compared to training on human expert data. Using this approach, AlphaGo Zero defeated the strongest previous versions of AlphaGo, which were trained from human data using handcrafted features, by a large margin.
          </p>
          <p>
           Humankind has accumulated Go knowledge from millions of games played over thousands of years, collectively distilled into patterns, proverbs and books. In the space of a few days, starting
           <i>
            tabula rasa
           </i>
           , AlphaGo Zero was able to rediscover much of this Go knowledge, as well as novel strategies that provide new insights into the oldest of games.
          </p>
         </div>
        </div>
       </section>
       <section data-title="Methods">
        <div class="c-article-section" id="Sec7-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">
          Methods
         </h2>
         <div class="c-article-section__content" id="Sec7-content">
          <h3 class="c-article__sub-heading" id="Sec8">
           Reinforcement learning
          </h3>
          <p>
           Policy iteration
           <sup>
            <a aria-label="Reference 20" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR20" id="ref-link-section-d261570943e1804" title="Howard, R. Dynamic Programming and Markov Processes (MIT Press, 1960)">
             20
            </a>
            ,
            <a aria-label="Reference 21" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR21" id="ref-link-section-d261570943e1807" title="Sutton, R . &amp; Barto, A. Reinforcement Learning: an Introduction (MIT Press, 1998)">
             21
            </a>
           </sup>
           is a classic algorithm that generates a sequence of improving policies, by alternating between policy evaluation—estimating the value function of the current policy—and policy improvement—using the current value function to generate a better policy. A simple approach to policy evaluation is to estimate the value function from the outcomes of sampled trajectories
           <sup>
            <a aria-label="Reference 35" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR35" id="ref-link-section-d261570943e1811" title="Barto, A. G. &amp; Duff, M. Monte Carlo matrix inversion and reinforcement learning. Adv. Neural Inf. Process. Syst. 6, 687–694 (1994)">
             35
            </a>
            ,
            <a aria-label="Reference 36" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR36" id="ref-link-section-d261570943e1814" title="Singh, S. P. &amp; Sutton, R. S. Reinforcement learning with replacing eligibility traces. Mach. Learn. 22, 123–158 (1996)">
             36
            </a>
           </sup>
           . A simple approach to policy improvement is to select actions greedily with respect to the value function
           <sup>
            <a aria-label="Reference 20" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR20" id="ref-link-section-d261570943e1818" title="Howard, R. Dynamic Programming and Markov Processes (MIT Press, 1960)">
             20
            </a>
           </sup>
           . In large state spaces, approximations are necessary to evaluate each policy and to represent its improvement
           <sup>
            <a aria-label="Reference 22" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR22" id="ref-link-section-d261570943e1822" title="Bertsekas, D. P. Approximate policy iteration: a survey and some new methods. J. Control Theory Appl. 9, 310–335 (2011)">
             22
            </a>
            ,
            <a aria-label="Reference 23" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR23" id="ref-link-section-d261570943e1825" title="Scherrer, B. Approximate policy iteration schemes: a comparison. In Proc. 31st Int. Conf. Mach. Learn. Vol. 32 1314–1322 (2014)">
             23
            </a>
           </sup>
           .
          </p>
          <p>
           Classification-based reinforcement learning
           <sup>
            <a aria-label="Reference 37" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR37" id="ref-link-section-d261570943e1832" title="Lagoudakis, M. G. &amp; Parr, R. Reinforcement learning as classification: leveraging modern classifiers. In Proc. 20th Int. Conf. Mach. Learn. 424–431 (2003)">
             37
            </a>
           </sup>
           improves the policy using a simple Monte Carlo search. Many rollouts are executed for each action; the action with the maximum mean value provides a positive training example, while all other actions provide negative training examples; a policy is then trained to classify actions as positive or negative, and used in subsequent rollouts. This may be viewed as a precursor to the policy component of AlphaGo Zero’s training algorithm when
           <i>
            τ
           </i>
           →0.
          </p>
          <p>
           A more recent instantiation, classification-based modified policy iteration (CBMPI), also performs policy evaluation by regressing a value function towards truncated rollout values, similar to the value component of AlphaGo Zero; this achieved state-of-the-art results in the game of Tetris
           <sup>
            <a aria-label="Reference 38" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR38" id="ref-link-section-d261570943e1842" title="Scherrer, B., Ghavamzadeh, M., Gabillon, V., Lesner, B. &amp; Geist, M. Approximate modified policy iteration and its application to the game of Tetris. J. Mach. Learn. Res. 16, 1629–1676 (2015)">
             38
            </a>
           </sup>
           . However, this previous work was limited to simple rollouts and linear function approximation using handcrafted features.
          </p>
          <p>
           The AlphaGo Zero self-play algorithm can similarly be understood as an approximate policy iteration scheme in which MCTS is used for both policy improvement and policy evaluation. Policy improvement starts with a neural network policy, executes an MCTS based on that policy’s recommendations, and then projects the (much stronger) search policy back into the function space of the neural network. Policy evaluation is applied to the (much stronger) search policy: the outcomes of self-play games are also projected back into the function space of the neural network. These projection steps are achieved by training the neural network parameters to match the search probabilities and self-play game outcome respectively.
          </p>
          <p>
           Guo
           <i>
            et al
           </i>
           .
           <sup>
            <a aria-label="Reference 7" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR7" id="ref-link-section-d261570943e1856" title="Guo, X., Singh, S. P., Lee, H., Lewis, R. L. &amp; Wang, X. Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning. In Adv. Neural Inf. Process. Syst. Vol. 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D. &amp; Weinberger, K. Q. ) 3338–3346 (2014)">
             7
            </a>
           </sup>
           also project the output of MCTS into a neural network, either by regressing a value network towards the search value, or by classifying the action selected by MCTS. This approach was used to train a neural network for playing Atari games; however, the MCTS was fixed—there was no policy iteration—and did not make any use of the trained networks.
          </p>
          <h3 class="c-article__sub-heading" id="Sec9">
           Self-play reinforcement learning in games
          </h3>
          <p>
           Our approach is most directly applicable to Zero-sum games of perfect information. We follow the formalism of alternating Markov games described in previous work
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e1868" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           , noting that algorithms based on value or policy iteration extend naturally to this setting
           <sup>
            <a aria-label="Reference 39" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR39" id="ref-link-section-d261570943e1872" title="Littman, M. L. Markov games as a framework for multi-agent reinforcement learning. In Proc. 11th Int. Conf. Mach. Learn. 157–163 (1994)">
             39
            </a>
           </sup>
           .
          </p>
          <p>
           Self-play reinforcement learning has previously been applied to the game of Go. NeuroGo
           <sup>
            <a aria-label="Reference 40" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR40" id="ref-link-section-d261570943e1879" title="Enzenberger, M. The integration of a priori knowledge into a Go playing neural network. 
                    http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html
                    
                   (1996)">
             40
            </a>
            ,
            <a aria-label="Reference 41" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR41" id="ref-link-section-d261570943e1882" title="Enzenberger, M. in Advances in Computer Games (eds Van Den Herik, H. J., Iida, H. &amp; Heinz, E. A. ) 97–108 (2003)">
             41
            </a>
           </sup>
           used a neural network to represent a value function, using a sophisticated architecture based on Go knowledge regarding connectivity, territory and eyes. This neural network was trained by temporal-difference learning
           <sup>
            <a aria-label="Reference 42" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR42" id="ref-link-section-d261570943e1886" title="Sutton, R. Learning to predict by the method of temporal differences. Mach. Learn. 3, 9–44 (1988)">
             42
            </a>
           </sup>
           to predict territory in games of self-play, building on previous work
           <sup>
            <a aria-label="Reference 43" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR43" id="ref-link-section-d261570943e1890" title="Schraudolph, N. N., Dayan, P. &amp; Sejnowski, T. J. Temporal difference learning of position evaluation in the game of Go. Adv. Neural Inf. Process. Syst. 6, 817–824 (1994)">
             43
            </a>
           </sup>
           . A related approach, RLGO
           <sup>
            <a aria-label="Reference 44" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR44" id="ref-link-section-d261570943e1894" title="Silver, D., Sutton, R. &amp; Müller, M. Temporal-difference search in computer Go. Mach. Learn. 87, 183–219 (2012)">
             44
            </a>
           </sup>
           , represented the value function instead by a linear combination of features, exhaustively enumerating all 3 × 3 patterns of stones; it was trained by temporal-difference learning to predict the winner in games of self-play. Both NeuroGo and RLGO achieved a weak amateur level of play.
          </p>
          <p>
           MCTS may also be viewed as a form of self-play reinforcement learning
           <sup>
            <a aria-label="Reference 45" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR45" id="ref-link-section-d261570943e1901" title="Silver, D. Reinforcement Learning and Simulation-Based Search in Computer Go. PhD thesis, Univ. Alberta, Edmonton, Canada (2009)">
             45
            </a>
           </sup>
           . The nodes of the search tree contain the value function for the positions encountered during search; these values are updated to predict the winner of simulated games of self-play. MCTS programs have previously achieved strong amateur level in Go
           <sup>
            <a aria-label="Reference 46" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR46" id="ref-link-section-d261570943e1905" title="Gelly, S. &amp; Silver, D. Monte-Carlo tree search and rapid action value estimation in computer Go. Artif. Intell. 175, 1856–1875 (2011)">
             46
            </a>
            ,
            <a aria-label="Reference 47" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR47" id="ref-link-section-d261570943e1908" title="Coulom, R. Computing Elo ratings of move patterns in the game of Go. Int. Comput. Games Assoc. J. 30, 198–208 (2007)">
             47
            </a>
           </sup>
           , but used substantial domain expertise: a fast rollout policy, based on handcrafted features
           <sup>
            <a aria-label="Reference 13" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR13" id="ref-link-section-d261570943e1912" title="Coulom, R. Efficient selectivity and backup operators in Monte-Carlo tree search. In 5th Int. Conf. Computers and Games (eds Ciancarini, P. &amp; van den Herik, H. J. ) 72–83 (2006)">
             13
            </a>
            ,
            <a aria-label="Reference 48" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR48" id="ref-link-section-d261570943e1915" title="Gelly, S., Wang, Y., Munos, R. &amp; Teytaud, O. Modification of UCT with patterns in Monte-Carlo Go. Report No. 6062 (INRIA, 2006)">
             48
            </a>
           </sup>
           , that evaluates positions by running simulations until the end of the game; and a tree policy, also based on handcrafted features, that selects moves within the search tree
           <sup>
            <a aria-label="Reference 47" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR47" id="ref-link-section-d261570943e1919" title="Coulom, R. Computing Elo ratings of move patterns in the game of Go. Int. Comput. Games Assoc. J. 30, 198–208 (2007)">
             47
            </a>
           </sup>
           .
          </p>
          <p>
           Self-play reinforcement learning approaches have achieved high levels of performance in other games: chess
           <sup>
            <a aria-label="Reference 49" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR49" id="ref-link-section-d261570943e1926" title="Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences. Mach. Learn. 40, 243–263 (2000)">
             49
            </a>
            ,
            <a aria-label="Reference 50" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR50" id="ref-link-section-d261570943e1929" title="Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In Adv. Neural Inf. Process. Syst. 1937–1945 (2009)">
             50
            </a>
            ,
            <a aria-label="Reference 51" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR51" id="ref-link-section-d261570943e1932" title="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)">
             51
            </a>
           </sup>
           , checkers
           <sup>
            <a aria-label="Reference 52" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR52" id="ref-link-section-d261570943e1936" title="Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In Proc. 17th Int. Jt Conf. Artif. Intell. Vol. 1 529–534 (2001)">
             52
            </a>
           </sup>
           , backgammon
           <sup>
            <a aria-label="Reference 53" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR53" id="ref-link-section-d261570943e1940" title="Tesauro, G. TD-gammon, a self-teaching backgammon program, achieves master-level play. Neural Comput. 6, 215–219 (1994)">
             53
            </a>
           </sup>
           , othello
           <sup>
            <a aria-label="Reference 54" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR54" id="ref-link-section-d261570943e1944" title="Buro, M. From simple features to sophisticated evaluation functions. In Proc. 1st Int. Conf. Comput. Games 126–145 (1999)">
             54
            </a>
           </sup>
           , Scrabble
           <sup>
            <a aria-label="Reference 55" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR55" id="ref-link-section-d261570943e1948" title="Sheppard, B. World-championship-caliber Scrabble. Artif. Intell. 134, 241–275 (2002)">
             55
            </a>
           </sup>
           and most recently poker
           <sup>
            <a aria-label="Reference 56" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR56" id="ref-link-section-d261570943e1953" title="Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker. Science 356, 508–513 (2017)">
             56
            </a>
           </sup>
           . In all of these examples, a value function was trained by regression
           <sup>
            <a aria-label="Reference 54" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR54" id="ref-link-section-d261570943e1957" title="Buro, M. From simple features to sophisticated evaluation functions. In Proc. 1st Int. Conf. Comput. Games 126–145 (1999)">
             54
            </a>
            ,
            <a aria-label="Reference 55" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR55" id="ref-link-section-d261570943e1960" title="Sheppard, B. World-championship-caliber Scrabble. Artif. Intell. 134, 241–275 (2002)">
             55
            </a>
            ,
            <a aria-label="Reference 56" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR56" id="ref-link-section-d261570943e1963" title="Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker. Science 356, 508–513 (2017)">
             56
            </a>
           </sup>
           or temporal-difference learning
           <sup>
            <a aria-label="Reference 49" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR49" id="ref-link-section-d261570943e1967" title="Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences. Mach. Learn. 40, 243–263 (2000)">
             49
            </a>
            ,
            <a aria-label="Reference 50" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR50" id="ref-link-section-d261570943e1970" title="Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In Adv. Neural Inf. Process. Syst. 1937–1945 (2009)">
             50
            </a>
            ,
            <a aria-label="Reference 51" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR51" id="ref-link-section-d261570943e1973" title="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)">
             51
            </a>
            ,
            <a aria-label="Reference 52" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR52" id="ref-link-section-d261570943e1976" title="Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In Proc. 17th Int. Jt Conf. Artif. Intell. Vol. 1 529–534 (2001)">
             52
            </a>
            ,
            <a aria-label="Reference 53" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR53" id="ref-link-section-d261570943e1979" title="Tesauro, G. TD-gammon, a self-teaching backgammon program, achieves master-level play. Neural Comput. 6, 215–219 (1994)">
             53
            </a>
           </sup>
           from training data generated by self-play. The trained value function was used as an evaluation function in an alpha–beta search
           <sup>
            <a aria-label="Reference 49" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR49" id="ref-link-section-d261570943e1983" title="Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences. Mach. Learn. 40, 243–263 (2000)">
             49
            </a>
            ,
            <a aria-label="Reference 50" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR50" id="ref-link-section-d261570943e1986" title="Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In Adv. Neural Inf. Process. Syst. 1937–1945 (2009)">
             50
            </a>
            ,
            <a aria-label="Reference 51" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR51" id="ref-link-section-d261570943e1989" title="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)">
             51
            </a>
            ,
            <a aria-label="Reference 52" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR52" id="ref-link-section-d261570943e1992" title="Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In Proc. 17th Int. Jt Conf. Artif. Intell. Vol. 1 529–534 (2001)">
             52
            </a>
            ,
            <a aria-label="Reference 53" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR53" id="ref-link-section-d261570943e1995" title="Tesauro, G. TD-gammon, a self-teaching backgammon program, achieves master-level play. Neural Comput. 6, 215–219 (1994)">
             53
            </a>
            ,
            <a aria-label="Reference 54" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR54" id="ref-link-section-d261570943e1998" title="Buro, M. From simple features to sophisticated evaluation functions. In Proc. 1st Int. Conf. Comput. Games 126–145 (1999)">
             54
            </a>
           </sup>
           , a simple Monte Carlo search
           <sup>
            <a aria-label="Reference 55" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR55" id="ref-link-section-d261570943e2002" title="Sheppard, B. World-championship-caliber Scrabble. Artif. Intell. 134, 241–275 (2002)">
             55
            </a>
            ,
            <a aria-label="Reference 57" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR57" id="ref-link-section-d261570943e2005" title="Tesauro, G &amp; Galperin, G. On-line policy improvement using Monte-Carlo search. In Adv. Neural Inf. Process. Syst. 1068–1074 (1996)">
             57
            </a>
           </sup>
           or counterfactual regret minimization
           <sup>
            <a aria-label="Reference 56" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR56" id="ref-link-section-d261570943e2009" title="Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker. Science 356, 508–513 (2017)">
             56
            </a>
           </sup>
           . However, these methods used handcrafted input features
           <sup>
            <a aria-label="Reference 49" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR49" id="ref-link-section-d261570943e2014" title="Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences. Mach. Learn. 40, 243–263 (2000)">
             49
            </a>
            ,
            <a aria-label="Reference 50" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR50" id="ref-link-section-d261570943e2017" title="Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In Adv. Neural Inf. Process. Syst. 1937–1945 (2009)">
             50
            </a>
            ,
            <a aria-label="Reference 51" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR51" id="ref-link-section-d261570943e2020" title="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)">
             51
            </a>
            ,
            <a aria-label="Reference 52" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR52" id="ref-link-section-d261570943e2023" title="Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In Proc. 17th Int. Jt Conf. Artif. Intell. Vol. 1 529–534 (2001)">
             52
            </a>
            ,
            <a aria-label="Reference 53" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR53" id="ref-link-section-d261570943e2026" title="Tesauro, G. TD-gammon, a self-teaching backgammon program, achieves master-level play. Neural Comput. 6, 215–219 (1994)">
             53
            </a>
            ,
            <a aria-label="Reference 56" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR56" id="ref-link-section-d261570943e2029" title="Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker. Science 356, 508–513 (2017)">
             56
            </a>
           </sup>
           or handcrafted feature templates
           <sup>
            <a aria-label="Reference 54" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR54" id="ref-link-section-d261570943e2033" title="Buro, M. From simple features to sophisticated evaluation functions. In Proc. 1st Int. Conf. Comput. Games 126–145 (1999)">
             54
            </a>
            ,
            <a aria-label="Reference 55" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR55" id="ref-link-section-d261570943e2036" title="Sheppard, B. World-championship-caliber Scrabble. Artif. Intell. 134, 241–275 (2002)">
             55
            </a>
           </sup>
           . In addition, the learning process used supervised learning to initialize weights
           <sup>
            <a aria-label="Reference 58" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR58" id="ref-link-section-d261570943e2040" title="Tesauro, G. Neurogammon: a neural-network backgammon program. In Proc. Int. Jt Conf. Neural Netw. Vol. 3, 33–39 (1990)">
             58
            </a>
           </sup>
           , hand-selected weights for piece values
           <sup>
            <a aria-label="Reference 49" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR49" id="ref-link-section-d261570943e2044" title="Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences. Mach. Learn. 40, 243–263 (2000)">
             49
            </a>
            ,
            <a aria-label="Reference 51" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR51" id="ref-link-section-d261570943e2047" title="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)">
             51
            </a>
            ,
            <a aria-label="Reference 52" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR52" id="ref-link-section-d261570943e2050" title="Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In Proc. 17th Int. Jt Conf. Artif. Intell. Vol. 1 529–534 (2001)">
             52
            </a>
           </sup>
           , handcrafted restrictions on the action space
           <sup>
            <a aria-label="Reference 56" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR56" id="ref-link-section-d261570943e2054" title="Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker. Science 356, 508–513 (2017)">
             56
            </a>
           </sup>
           or used pre-existing computer programs as training opponents
           <sup>
            <a aria-label="Reference 49" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR49" id="ref-link-section-d261570943e2058" title="Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences. Mach. Learn. 40, 243–263 (2000)">
             49
            </a>
            ,
            <a aria-label="Reference 50" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR50" id="ref-link-section-d261570943e2061" title="Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In Adv. Neural Inf. Process. Syst. 1937–1945 (2009)">
             50
            </a>
           </sup>
           , or to generate game records
           <sup>
            <a aria-label="Reference 51" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR51" id="ref-link-section-d261570943e2066" title="Lai, M. Giraffe: Using Deep Reinforcement Learning to Play Chess. MSc thesis, Imperial College London (2015)">
             51
            </a>
           </sup>
           .
          </p>
          <p>
           Many of the most successful and widely used reinforcement learning methods were first introduced in the context of Zero-sum games: temporal-difference learning was first introduced for a checkers-playing program
           <sup>
            <a aria-label="Reference 59" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR59" id="ref-link-section-d261570943e2074" title="Samuel, A. L. Some studies in machine learning using the game of checkers II - recent progress. IBM J. Res. Develop. 11, 601–617 (1967)">
             59
            </a>
           </sup>
           , while MCTS was introduced for the game of Go
           <sup>
            <a aria-label="Reference 13" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR13" id="ref-link-section-d261570943e2078" title="Coulom, R. Efficient selectivity and backup operators in Monte-Carlo tree search. In 5th Int. Conf. Computers and Games (eds Ciancarini, P. &amp; van den Herik, H. J. ) 72–83 (2006)">
             13
            </a>
           </sup>
           . However, very similar algorithms have subsequently proven highly effective in video games
           <sup>
            <a aria-label="Reference 6" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR6" id="ref-link-section-d261570943e2082" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)">
             6
            </a>
            ,
            <a aria-label="Reference 7" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR7" id="ref-link-section-d261570943e2085" title="Guo, X., Singh, S. P., Lee, H., Lewis, R. L. &amp; Wang, X. Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning. In Adv. Neural Inf. Process. Syst. Vol. 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D. &amp; Weinberger, K. Q. ) 3338–3346 (2014)">
             7
            </a>
            ,
            <a aria-label="Reference 8" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR8" id="ref-link-section-d261570943e2088" title="Mnih, V . et al. Asynchronous methods for deep reinforcement learning. In Proc. 33rd Int. Conf. Mach. Learn. Vol. 48 (eds Balcan, M. F. &amp; Weinberger, K. Q. ) 1928–1937 (2016)">
             8
            </a>
            ,
            <a aria-label="Reference 10" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR10" id="ref-link-section-d261570943e2091" title="Dosovitskiy, A. &amp; Koltun, V. Learning to act by predicting the future. In 5th Int. Conf. Learn. Representations (2017)">
             10
            </a>
           </sup>
           , robotics
           <sup>
            <a aria-label="Reference 60" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR60" id="ref-link-section-d261570943e2095" title="Kober, J., Bagnell, J. A. &amp; Peters, J. Reinforcement learning in robotics: a survey. Int. J. Robot. Res. 32, 1238–1274 (2013)">
             60
            </a>
           </sup>
           , industrial control
           <sup>
            <a aria-label="Reference 61" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR61" id="ref-link-section-d261570943e2099" title="Zhang, W. &amp; Dietterich, T. G. A reinforcement learning approach to job-shop scheduling. In Proc. 14th Int. Jt Conf. Artif. Intell. 1114–1120 (1995)">
             61
            </a>
            ,
            <a aria-label="Reference 62" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR62" id="ref-link-section-d261570943e2102" title="Cazenave, T., Balbo, F. &amp; Pinson, S. Using a Monte-Carlo approach for bus regulation. In Int. IEEE Conf. Intell. Transport. Syst. 1–6 (2009)">
             62
            </a>
            ,
            <a aria-label="Reference 63" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR63" id="ref-link-section-d261570943e2105" title="Evans, R. &amp; Gao, J. Deepmind AI reduces Google data centre cooling bill by 40%. 
                    https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/
                    
                   (2016)">
             63
            </a>
           </sup>
           and online recommendation systems
           <sup>
            <a aria-label="Reference 64" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR64" id="ref-link-section-d261570943e2110" title="Abe, N . et al. Empirical comparison of various reinforcement learning strategies for sequential targeted marketing. In IEEE Int. Conf. Data Mining 3–10 (2002)">
             64
            </a>
            ,
            <a aria-label="Reference 65" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR65" id="ref-link-section-d261570943e2113" title="Silver, D., Newnham, L., Barker, D., Weller, S. &amp; McFall, J. Concurrent reinforcement learning from customer interactions. In Proc. 30th Int. Conf. Mach. Learn. Vol. 28 924–932 (2013)">
             65
            </a>
           </sup>
           .
          </p>
          <h3 class="c-article__sub-heading" id="Sec10">
           AlphaGo versions
          </h3>
          <p>
           We compare three distinct versions of AlphaGo:
          </p>
          <p>
           (1) AlphaGo Fan is the previously published program
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2128" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           that played against Fan Hui in October 2015. This program was distributed over many machines using 176 GPUs.
          </p>
          <p>
           (2) AlphaGo Lee is the program that defeated Lee Sedol 4–1 in March 2016. It was previously unpublished, but is similar in most regards to AlphaGo Fan
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2135" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           . However, we highlight several key differences to facilitate a fair comparison. First, the value network was trained from the outcomes of fast games of self-play by AlphaGo, rather than games of self-play by the policy network; this procedure was iterated several times—an initial step towards the
           <i>
            tabula rasa
           </i>
           algorithm presented in this paper. Second, the policy and value networks were larger than those described in the original paper—using 12 convolutional layers of 256 planes—and were trained for more iterations. This player was also distributed over many machines using 48 TPUs, rather than GPUs, enabling it to evaluate neural networks faster during search.
          </p>
          <p>
           (3) AlphaGo Master is the program that defeated top human players by 60–0 in January 2017
           <sup>
            <a aria-label="Reference 34" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR34" id="ref-link-section-d261570943e2145" title="Huang, A. AlphaGo master online series of games. 
                    https://deepmind.com/research/AlphaGo/match-archive/master
                    
                   (2017)">
             34
            </a>
           </sup>
           . It was previously unpublished, but uses the same neural network architecture, reinforcement learning algorithm, and MCTS algorithm as described in this paper. However, it uses the same handcrafted features and rollouts as AlphaGo Lee
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2149" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           and training was initialized by supervised learning from human data.
          </p>
          <p>
           (4) AlphaGo Zero is the program described in this paper. It learns from self-play reinforcement learning, starting from random initial weights, without using rollouts, with no human supervision and using only the raw board history as input features. It uses just a single machine in the Google Cloud with 4 TPUs (AlphaGo Zero could also be distributed, but we chose to use the simplest possible search algorithm).
          </p>
          <h3 class="c-article__sub-heading" id="Sec11">
           Domain knowledge
          </h3>
          <p>
           Our primary contribution is to demonstrate that superhuman performance can be achieved without human domain knowledge. To clarify this contribution, we enumerate the domain knowledge that AlphaGo Zero uses, explicitly or implicitly, either in its training procedure or its MCTS; these are the items of knowledge that would need to be replaced for AlphaGo Zero to learn a different (alternating Markov) game.
          </p>
          <p>
           (1) AlphaGo Zero is provided with perfect knowledge of the game rules. These are used during MCTS, to simulate the positions resulting from a sequence of moves, and to score any simulations that reach a terminal state. Games terminate when both players pass or after 19 × 19 × 2 = 722 moves. In addition, the player is provided with the set of legal moves in each position.
          </p>
          <p>
           (2) AlphaGo Zero uses Tromp–Taylor scoring
           <sup>
            <a aria-label="Reference 66" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR66" id="ref-link-section-d261570943e2171" title="Tromp, J. Tromp–Taylor rules. 
                    http://tromp.github.io/go.html
                    
                   (1995)">
             66
            </a>
           </sup>
           during MCTS simulations and self-play training. This is because human scores (Chinese, Japanese or Korean rules) are not well-defined if the game terminates before territorial boundaries are resolved. However, all tournament and evaluation games were scored using Chinese rules.
          </p>
          <p>
           (3) The input features describing the position are structured as a 19 × 19 image; that is, the neural network architecture is matched to the grid-structure of the board.
          </p>
          <p>
           (4) The rules of Go are invariant under rotation and reflection; this knowledge has been used in AlphaGo Zero both by augmenting the dataset during training to include rotations and reflections of each position, and to sample random rotations or reflections of the position during MCTS (see Search algorithm). Aside from
           <i>
            komi
           </i>
           , the rules of Go are also invariant to colour transposition; this knowledge is exploited by representing the board from the perspective of the current player (see Neural network architecture).
          </p>
          <p>
           AlphaGo Zero does not use any form of domain knowledge beyond the points listed above. It only uses its deep neural network to evaluate leaf nodes and to select moves (see ‘Search algorithm’). It does not use any rollout policy or tree policy, and the MCTS is not augmented by any other heuristics or domain-specific rules. No legal moves are excluded—even those filling in the player’s own eyes (a standard heuristic used in all previous programs
           <sup>
            <a aria-label="Reference 67" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR67" id="ref-link-section-d261570943e2188" title="Müller, M. Computer Go. Artif. Intell. 134, 145–179 (2002)">
             67
            </a>
           </sup>
           ).
          </p>
          <p>
           The algorithm was started with random initial parameters for the neural network. The neural network architecture (see ‘Neural network architecture’) is based on the current state of the art in image recognition
           <sup>
            <a aria-label="Reference 4" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR4" id="ref-link-section-d261570943e2195" title="He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit. 770–778 (2016)">
             4
            </a>
            ,
            <a aria-label="Reference 18" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR18" id="ref-link-section-d261570943e2198" title="Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 448–456 (2015)">
             18
            </a>
           </sup>
           , and hyperparameters for training were chosen accordingly (see ‘Self-play training pipeline’). MCTS search parameters were selected by Gaussian process optimization
           <sup>
            <a aria-label="Reference 68" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR68" id="ref-link-section-d261570943e2202" title="Shahriari, B., Swersky, K., Wang, Z., Adams, R. P. &amp; de Freitas, N. Taking the human out of the loop: a review of Bayesian optimization. Proc. IEEE 104, 148–175 (2016)">
             68
            </a>
           </sup>
           , so as to optimize self-play performance of AlphaGo Zero using a neural network trained in a preliminary run. For the larger run (40 blocks, 40 days), MCTS search parameters were re-optimized using the neural network trained in the smaller run (20 blocks, 3 days). The training algorithm was executed autonomously without human intervention.
          </p>
          <h3 class="c-article__sub-heading" id="Sec12">
           Self-play training pipeline
          </h3>
          <p>
           AlphaGo Zero’
           <i>
            s
           </i>
           self-play training pipeline consists of three main components, all executed asynchronously in parallel. Neural network parameters
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           are continually optimized from recent self-play data; AlphaGo Zero players
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq5_HTML.gif" style="width:19px;max-width:none;"/>
           are continually evaluated; and the best performing player so far,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw21/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq6_HTML.gif" style="width:21px;max-width:none;"/>
           , is used to generate new self-play data.
          </p>
          <h3 class="c-article__sub-heading" id="Sec13">
           Optimization
          </h3>
          <p>
           Each neural network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw16/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq7_HTML.gif" style="width:16px;max-width:none;"/>
           is optimized on the Google Cloud using TensorFlow, with 64 GPU workers and 19 CPU parameter servers. The batch-size is 32 per worker, for a total mini-batch size of 2,048. Each mini-batch of data is sampled uniformly at random from all positions of the most recent 500,000 games of self-play. Neural network parameters are optimized by stochastic gradient descent with momentum and learning rate annealing, using the loss in equation (1). The learning rate is annealed according to the standard schedule in
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature24270#Tab3">
            Extended Data Table 3
           </a>
           . The momentum parameter is set to 0.9. The cross-entropy and MSE losses are weighted equally (this is reasonable because rewards are unit scaled,
           <i>
            r
           </i>
           <span class="stix">
            ∈
           </span>
           {−1, +1}) and the L2 regularization parameter is set to
           <i>
            c
           </i>
           = 10
           <sup>
            −4
           </sup>
           . The optimization process produces a new checkpoint every 1,000 training steps. This checkpoint is evaluated by the evaluator and it may be used for generating the next batch of self-play games, as we explain next.
          </p>
          <h3 class="c-article__sub-heading" id="Sec14">
           Evaluator
          </h3>
          <p>
           To ensure we always generate the best quality data, we evaluate each new neural network checkpoint against the current best network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw17/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq8_HTML.gif" style="width:17px;max-width:none;"/>
           before using it for data generation. The neural network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw16/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq9_HTML.gif" style="width:16px;max-width:none;"/>
           is evaluated by the performance of an MCTS search
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq10_HTML.gif" style="width:19px;max-width:none;"/>
           that uses
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw16/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq11_HTML.gif" style="width:16px;max-width:none;"/>
           to evaluate leaf positions and prior probabilities (see Search algorithm). Each evaluation consists of 400 games, using an MCTS with 1,600 simulations to select each move, using an infinitesimal temperature
           <i>
            τ
           </i>
           →0 (that is, we deterministically select the move with maximum visit count, to give the strongest possible play). If the new player wins by a margin of &gt;55% (to avoid selecting on noise alone) then it becomes the best player
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw21/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq12_HTML.gif" style="width:21px;max-width:none;"/>
           , and is subsequently used for self-play generation, and also becomes the baseline for subsequent comparisons.
          </p>
          <h3 class="c-article__sub-heading" id="Sec15">
           Self-play
          </h3>
          <p>
           The best current player
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw21/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq13_HTML.gif" style="width:21px;max-width:none;"/>
           , as selected by the evaluator, is used to generate data. In each iteration,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw21/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq14_HTML.gif" style="width:21px;max-width:none;"/>
           plays 25,000 games of self-play, using 1,600 simulations of MCTS to select each move (this requires approximately 0.4 s per search). For the first 30 moves of each game, the temperature is set to
           <i>
            τ
           </i>
           = 1; this selects moves proportionally to their visit count in MCTS, and ensures a diverse set of positions are encountered. For the remainder of the game, an infinitesimal temperature is used,
           <i>
            τ
           </i>
           →0. Additional exploration is achieved by adding Dirichlet noise to the prior probabilities in the root node
           <i>
            s
           </i>
           <sub>
            0
           </sub>
           , specifically
           <i>
            P
           </i>
           (
           <i>
            s
           </i>
           , a) = (1 −
           <i>
            ε
           </i>
           )
           <b>
            <i>
             p
            </i>
           </b>
           <sub>
            <b>
             <i>
              a
             </i>
            </b>
           </sub>
           +
           <i>
            ε
           </i>
           <i>
            η
           </i>
           <sub>
            <i>
             a
            </i>
           </sub>
           , where
           <i>
            η
           </i>
           <span class="stix">
            ∼
           </span>
           Dir(0.03) and
           <i>
            ε
           </i>
           = 0.25; this noise ensures that all moves may be tried, but the search may still overrule bad moves. In order to save computation, clearly lost games are resigned. The resignation threshold
           <i>
            v
           </i>
           <sub>
            resign
           </sub>
           is selected automatically to keep the fraction of false positives (games that could have been won if AlphaGo had not resigned) below 5%. To measure false positives, we disable resignation in 10% of self-play games and play until termination.
          </p>
          <h3 class="c-article__sub-heading" id="Sec16">
           Supervised learning
          </h3>
          <p>
           For comparison, we also trained neural network parameters
           <i>
            θ
           </i>
           <sub>
            SL
           </sub>
           by supervised learning. The neural network architecture was identical to AlphaGo Zero. Mini-batches of data (
           <i>
            s
           </i>
           ,
           <i>
            π
           </i>
           ,
           <i>
            z
           </i>
           ) were sampled at random from the KGS dataset, setting
           <i>
            π
           </i>
           <sub>
            <i>
             a
            </i>
           </sub>
           = 1 for the human expert move
           <i>
            a
           </i>
           . Parameters were optimized by stochastic gradient descent with momentum and learning rate annealing, using the same loss as in equation (1), but weighting the MSE component by a factor of 0.01. The learning rate was annealed according to the standard schedule in
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature24270#Tab3">
            Extended Data Table 3
           </a>
           . The momentum parameter was set to 0.9, and the L2 regularization parameter was set to
           <i>
            c
           </i>
           = 10
           <sup>
            −4
           </sup>
           .
          </p>
          <p>
           By using a combined policy and value network architecture, and by using a low weight on the value component, it was possible to avoid overfitting to the values (a problem described in previous work
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2431" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           ). After 72 h the move prediction accuracy exceeded the state of the art reported in previous work
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2435" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
            ,
            <a aria-label="Reference 30" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR30" id="ref-link-section-d261570943e2438" title="Maddison, C. J., Huang, A., Sutskever, I . &amp; Silver, D. Move evaluation in Go using deep convolutional neural networks. In 3rd Int. Conf. Learn. Representations. (2015)">
             30
            </a>
            ,
            <a aria-label="Reference 31" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR31" id="ref-link-section-d261570943e2441" title="Clark, C . &amp; Storkey, A. J. Training deep convolutional neural networks to play Go. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 1766–1774 (2015)">
             31
            </a>
            ,
            <a aria-label="Reference 32" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR32" id="ref-link-section-d261570943e2444" title="Tian, Y. &amp; Zhu, Y. Better computer Go player with neural network and long-term prediction. In 4th Int. Conf. Learn. Representations (2016)">
             32
            </a>
            ,
            <a aria-label="Reference 33" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR33" id="ref-link-section-d261570943e2447" title="Cazenave, T. Residual networks for computer Go. IEEE Trans. Comput. Intell. AI Games 
                    https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042
                    
                   (2017)">
             33
            </a>
           </sup>
           , reaching 60.4% on the KGS test set; the value prediction error was also substantially better than previously reported
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2451" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           . The validation set was composed of professional games from GoKifu. Accuracies and MSEs are reported in
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature24270#Tab1">
            Extended Data Table 1
           </a>
           and
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature24270#Tab2">
            Extended Data Table 2
           </a>
           , respectively.
          </p>
          <h3 class="c-article__sub-heading" id="Sec17">
           Search algorithm
          </h3>
          <p>
           AlphaGo Zero uses a much simpler variant of the asynchronous policy and value MCTS algorithm (APV-MCTS) used in AlphaGo Fan and AlphaGo Lee.
          </p>
          <p>
           Each node
           <i>
            s
           </i>
           in the search tree contains edges (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) for all legal actions
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw55/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq15_HTML.gif" style="width:55px;max-width:none;"/>
           . Each edge stores a set of statistics,
          </p>
          <div class="c-article-equation" id="Equ2">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw213/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Equ2_HTML.gif"/>
           </div>
          </div>
          <p>
           where
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) is the visit count,
           <i>
            W
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) is the total action value,
           <i>
            Q
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) is the mean action value and
           <i>
            P
           </i>
           (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ) is the prior probability of selecting that edge. Multiple simulations are executed in parallel on separate search threads. The algorithm proceeds by iterating over three phases (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2a–c
           </a>
           ), and then selects a move to play (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2d
           </a>
           ).
          </p>
          <h3 class="c-article__sub-heading" id="Sec18">
           Select (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2a
           </a>
           )
          </h3>
          <p>
           The selection phase is almost identical to AlphaGo Fan
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e2555" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           ; we recapitulate here for completeness. The first in-tree phase of each simulation begins at the root node of the search tree,
           <i>
            s
           </i>
           <sub>
            0
           </sub>
           , and finishes when the simulation reaches a leaf node
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           at time-step
           <i>
            L
           </i>
           . At each of these time-steps,
           <i>
            t
           </i>
           &lt;
           <i>
            L
           </i>
           , an action is selected according to the statistics in the search tree,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw214/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq16_HTML.gif" style="width:214px;max-width:none;"/>
           , using a variant of the PUCT algorithm
           <sup>
            <a aria-label="Reference 24" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR24" id="ref-link-section-d261570943e2587" title="Rosin, C. D. Multi-armed bandits with episode context. Ann. Math. Artif. Intell. 61, 203–230 (2011)">
             24
            </a>
           </sup>
           ,
          </p>
          <div class="c-article-equation" id="Equ3">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw222/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Equ3_HTML.gif"/>
           </div>
          </div>
          <p>
           where
           <i>
            c
           </i>
           <sub>
            puct
           </sub>
           is a constant determining the level of exploration; this search control strategy initially prefers actions with high prior probability and low visit count, but asympotically prefers actions with high action value.
          </p>
          <h3 class="c-article__sub-heading" id="Sec19">
           Expand and evaluate (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2b
           </a>
           )
          </h3>
          <p>
           The leaf node
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           is added to a queue for neural network evaluation, (
           <i>
            d
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           (
           <b>
            <i>
             p
            </i>
           </b>
           ),
           <i>
            v
           </i>
           ) =
           <i>
            f
           </i>
           <sub>
            <i>
             θ
            </i>
           </sub>
           (
           <i>
            d
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           )), where
           <i>
            d
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           is a dihedral reflection or rotation selected uniformly at random from
           <i>
            i
           </i>
           in [1..8]. Positions in the queue are evaluated by the neural network using a mini-batch size of 8; the search thread is locked until evaluation completes. The leaf node is expanded and each edge (
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           ) is initialized to{
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           ) = 0,
           <i>
            W
           </i>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           ) = 0,
           <i>
            Q
           </i>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           ) = 0,
           <i>
            P
           </i>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             L
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           ) =
           <i>
            p
           </i>
           <sub>
            <i>
             a
            </i>
           </sub>
           }; the value
           <i>
            v
           </i>
           is then backed up.
          </p>
          <h3 class="c-article__sub-heading" id="Sec20">
           Backup (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2c
           </a>
           )
          </h3>
          <p>
           The edge statistics are updated in a backward pass through each step
           <i>
            t
           </i>
           ≤
           <i>
            L
           </i>
           . The visit counts are incremented,
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ) =
           <i>
            N
           </i>
           (
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ) + 1, and the action value is updated to the mean value,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw299/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq17_HTML.gif"/>
          </p>
          <h3 class="c-article__sub-heading" id="Sec21">
           Play (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig2">
            Fig. 2d
           </a>
           )
          </h3>
          <p>
           At the end of the search AlphaGo Zero selects a move
           <i>
            a
           </i>
           to play in the root position
           <i>
            s
           </i>
           <sub>
            0
           </sub>
           , proportional to its exponentiated visit count,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw241/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq18_HTML.gif" style="width:241px;max-width:none;"/>
           , where
           <i>
            τ
           </i>
           is a temperature parameter that controls the level of exploration. The search tree is reused at subsequent time-steps: the child node corresponding to the played action becomes the new root node; the subtree below this child is retained along with all its statistics, while the remainder of the tree is discarded. AlphaGo Zero resigns if its root value and best child value are lower than a threshold value
           <i>
            v
           </i>
           <sub>
            resign
           </sub>
           .
          </p>
          <p>
           Compared to the MCTS in AlphaGo Fan and AlphaGo Lee, the principal differences are that AlphaGo Zero does not use any rollouts; it uses a single neural network instead of separate policy and value networks; leaf nodes are always expanded, rather than using dynamic expansion; each search thread simply waits for the neural network evaluation, rather than performing evaluation and backup asynchronously; and there is no tree policy. A transposition table was also used in the large (40 blocks, 40 days) instance of AlphaGo Zero.
          </p>
          <h3 class="c-article__sub-heading" id="Sec22">
           Neural network architecture
          </h3>
          <p>
           The input to the neural network is a 19 × 19 × 17 image stack comprising 17 binary feature planes. Eight feature planes,
           <i>
            X
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           , consist of binary values indicating the presence of the current player’s stones (
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw37/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq19_HTML.gif" style="width:37px;max-width:none;"/>
           if intersection
           <i>
            i
           </i>
           contains a stone of the player’s colour at time-step
           <i>
            t
           </i>
           ; 0 if the intersection is empty, contains an opponent stone, or if
           <i>
            t
           </i>
           &lt; 0). A further 8 feature planes,
           <i>
            Y
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           , represent the corresponding features for the opponent’s stones. The final feature plane,
           <i>
            C
           </i>
           , represents the colour to play, and has a constant value of either 1 if black is to play or 0 if white is to play. These planes are concatenated together to give input features
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           = [
           <i>
            X
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            Y
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            X
           </i>
           <sub>
            <i>
             t
            </i>
            −1
           </sub>
           ,
           <i>
            Y
           </i>
           <sub>
            <i>
             t
            </i>
            −1
           </sub>
           ,...,
           <i>
            X
           </i>
           <sub>
            <i>
             t
            </i>
            −7
           </sub>
           ,
           <i>
            Y
           </i>
           <sub>
            <i>
             t
            </i>
            −7
           </sub>
           ,
           <i>
            C
           </i>
           ]. History features
           <i>
            X
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            Y
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           are necessary, because Go is not fully observable solely from the current stones, as repetitions are forbidden; similarly, the colour feature
           <i>
            C
           </i>
           is necessary, because the
           <i>
            komi
           </i>
           is not observable.
          </p>
          <p>
           The input features
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           are processed by a residual tower that consists of a single convolutional block followed by either 19 or 39 residual blocks
           <sup>
            <a aria-label="Reference 4" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR4" id="ref-link-section-d261570943e2946" title="He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit. 770–778 (2016)">
             4
            </a>
           </sup>
           .
          </p>
          <p>
           The convolutional block applies the following modules:
          </p>
          <p>
           (1) A convolution of 256 filters of kernel size 3 × 3 with stride 1
          </p>
          <p>
           (2) Batch normalization
           <sup>
            <a aria-label="Reference 18" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR18" id="ref-link-section-d261570943e2960" title="Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proc. 32nd Int. Conf. Mach. Learn. Vol. 37 448–456 (2015)">
             18
            </a>
           </sup>
          </p>
          <p>
           (3) A rectifier nonlinearity
          </p>
          <p>
           Each residual block applies the following modules sequentially to its input:
          </p>
          <p>
           (1) A convolution of 256 filters of kernel size 3 × 3 with stride 1
          </p>
          <p>
           (2) Batch normalization
          </p>
          <p>
           (3) A rectifier nonlinearity
          </p>
          <p>
           (4) A convolution of 256 filters of kernel size 3 × 3 with stride 1
          </p>
          <p>
           (5) Batch normalization
          </p>
          <p>
           (6) A skip connection that adds the input to the block
          </p>
          <p>
           (7) A rectifier nonlinearity
          </p>
          <p>
           The output of the residual tower is passed into two separate ‘heads’ for computing the policy and value. The policy head applies the following modules:
          </p>
          <p>
           (1) A convolution of 2 filters of kernel size 1 × 1 with stride 1
          </p>
          <p>
           (2) Batch normalization
          </p>
          <p>
           (3) A rectifier nonlinearity
          </p>
          <p>
           (4) A fully connected linear layer that outputs a vector of size 19
           <sup>
            2
           </sup>
           + 1 = 362, corresponding to logit probabilities for all intersections and the pass move
          </p>
          <p>
           The value head applies the following modules:
          </p>
          <p>
           (1) A convolution of 1 filter of kernel size 1 × 1 with stride 1
          </p>
          <p>
           (2) Batch normalization
          </p>
          <p>
           (3) A rectifier nonlinearity
          </p>
          <p>
           (4) A fully connected linear layer to a hidden layer of size 256
          </p>
          <p>
           (5) A rectifier nonlinearity
          </p>
          <p>
           (6) A fully connected linear layer to a scalar
          </p>
          <p>
           (7) A tanh nonlinearity outputting a scalar in the range [−1, 1]
          </p>
          <p>
           The overall network depth, in the 20- or 40-block network, is 39 or 79 parameterized layers, respectively, for the residual tower, plus an additional 2 layers for the policy head and 3 layers for the value head.
          </p>
          <p>
           We note that a different variant of residual networks was simultaneously applied to computer Go
           <sup>
            <a aria-label="Reference 33" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR33" id="ref-link-section-d261570943e3041" title="Cazenave, T. Residual networks for computer Go. IEEE Trans. Comput. Intell. AI Games 
                    https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042
                    
                   (2017)">
             33
            </a>
           </sup>
           and achieved an amateur dan-level performance; however, this was restricted to a single-headed policy network trained solely by supervised learning.
          </p>
          <h3 class="c-article__sub-heading" id="Sec23">
           Neural network architecture comparison
          </h3>
          <p>
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig4">
            Figure 4
           </a>
           shows the results of a comparison between network architectures. Specifically, we compared four different neural networks:
          </p>
          <p>
           (1) dual–res: the network contains a 20-block residual tower, as described above, followed by both a policy head and a value head. This is the architecture used in AlphaGo Zero.
          </p>
          <p>
           (2) sep–res: the network contains two 20-block residual towers. The first tower is followed by a policy head and the second tower is followed by a value head.
          </p>
          <p>
           (3) dual–conv: the network contains a non-residual tower of 12 convolutional blocks, followed by both a policy head and a value head.
          </p>
          <p>
           (4) sep–conv: the network contains two non-residual towers of 12 convolutional blocks. The first tower is followed by a policy head and the second tower is followed by a value head. This is the architecture used in AlphaGo Lee.
          </p>
          <p>
           Each network was trained on a fixed dataset containing the final 2 million games of self-play data generated by a previous run of AlphaGo Zero, using stochastic gradient descent with the annealing rate, momentum and regularization hyperparameters described for the supervised learning experiment; however, cross-entropy and MSE components were weighted equally, since more data was available.
          </p>
          <h3 class="c-article__sub-heading" id="Sec24">
           Evaluation
          </h3>
          <p>
           We evaluated the relative strength of AlphaGo Zero (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig3">
            Figs 3a
           </a>
           ,
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig6">
            6
           </a>
           ) by measuring the Elo rating of each player. We estimate the probability that player
           <i>
            a
           </i>
           will defeat player
           <i>
            b
           </i>
           by a logistic function
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw239/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq20_HTML.gif" style="width:239px;max-width:none;"/>
           , and estimate the ratings
           <i>
            e
           </i>
           (·) by Bayesian logistic regression, computed by the BayesElo program
           <sup>
            <a aria-label="Reference 25" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR25" id="ref-link-section-d261570943e3104" title="Coulom, R. Whole-history rating: a Bayesian rating system for players of time-varying strength. In Int. Conf. Comput. Games (eds van den Herik, H. J., Xu, X . Ma, Z . &amp; Winands, M. H. M. ) Vol. 5131 113–124 (Springer, 2008)">
             25
            </a>
           </sup>
           using the standard constant
           <i>
            c
           </i>
           <sub>
            elo
           </sub>
           = 1/400.
          </p>
          <p>
           Elo ratings were computed from the results of a 5 s per move tournament between AlphaGo Zero, AlphaGo Master, AlphaGo Lee and AlphaGo Fan. The raw neural network from AlphaGo Zero was also included in the tournament. The Elo ratings of AlphaGo Fan, Crazy Stone, Pachi and GnuGo were anchored to the tournament values from previous work
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e3115" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           , and correspond to the players reported in that work. The results of the matches of AlphaGo Fan against Fan Hui and AlphaGo Lee against Lee Sedol were also included to ground the scale to human references, as otherwise the Elo ratings of AlphaGo are unrealistically high due to self-play bias.
          </p>
          <p>
           The Elo ratings in
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig3">
            Figs 3a
           </a>
           ,
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig4">
            4a
           </a>
           ,
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature24270#Fig6">
            6a
           </a>
           were computed from the results of evaluation games between each iteration of player
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_IEq21_HTML.gif" style="width:19px;max-width:none;"/>
           during self-play training. Further evaluations were also performed against baseline players with Elo ratings anchored to the previously published values
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature24270#ref-CR12" id="ref-link-section-d261570943e3139" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)">
             12
            </a>
           </sup>
           .
          </p>
          <p>
           We measured the head-to-head performance of AlphaGo Zero against AlphaGo Lee, and the 40-block instance of AlphaGo Zero against AlphaGo Master, using the same player and match conditions that were used against Lee Sedol in Seoul, 2016. Each player received 2 h of thinking time plus 3 byoyomi periods of 60 s per move. All games were scored using Chinese rules with a
           <i>
            komi
           </i>
           of 7.5 points.
          </p>
          <h3 class="c-article__sub-heading" id="Sec25">
           Data availability
          </h3>
          <p>
           The datasets used for validation and testing are the GoKifu dataset (available from
           <a href="http://gokifu.com/">
            http://gokifu.com/
           </a>
           ) and the KGS dataset (available from
           <a href="https://u-go.net/gamerecords/">
            https://u-go.net/gamerecords/
           </a>
           ).
          </p>
         </div>
        </div>
       </section>
      </div>
      <div>
       <div id="MagazineFulltextArticleBodySuffix">
        <section aria-labelledby="Bib1" data-title="References">
         <div class="c-article-section" id="Bib1-section">
          <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">
           References
          </h2>
          <div class="c-article-section__content" id="Bib1-content">
           <div data-container-section="references">
            <ol class="c-article-references" data-track-component="outbound reference">
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1">
              <p class="c-article-references__text" id="ref-CR1">
               Friedman, J., Hastie, T. &amp; Tibshirani, R.
               <i>
                The Elements of Statistical Learning: Data Mining, Inference, and Prediction
               </i>
               (Springer, 2009)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2">
              <p class="c-article-references__text" id="ref-CR2">
               LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning.
               <i>
                Nature
               </i>
               <b>
                521
               </b>
               , 436–444 (2015)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 2" data-doi="10.1038/nature14539" data-track="click" data-track-action="article reference" data-track-label="10.1038/nature14539" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature14539" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 2" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXht1WlurzP" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="ADS reference 2" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2015Natur.521..436L" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="Google Scholar reference 2" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning&amp;journal=Nature&amp;doi=10.1038%2Fnature14539&amp;volume=521&amp;pages=436-444&amp;publication_year=2015&amp;author=LeCun%2CY&amp;author=Bengio%2CY&amp;author=Hinton%2CG" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3">
              <p class="c-article-references__text" id="ref-CR3">
               Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. In
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               Vol. 25 (eds Pereira, F., Burges, C. J. C., Bottou, L. &amp; Weinberger, K. Q. ) 1097–1105 (2012)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4">
              <p class="c-article-references__text" id="ref-CR4">
               He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In
               <i>
                Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit.
               </i>
               770–778 (2016)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5">
              <p class="c-article-references__text" id="ref-CR5">
               Hayes-Roth, F., Waterman, D. &amp; Lenat, D.
               <i>
                Building Expert Systems
               </i>
               (Addison-Wesley, 1984)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6">
              <p class="c-article-references__text" id="ref-CR6">
               Mnih, V. et al. Human-level control through deep reinforcement learning.
               <i>
                Nature
               </i>
               <b>
                518
               </b>
               , 529–533 (2015)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 6" data-doi="10.1038/nature14236" data-track="click" data-track-action="article reference" data-track-label="10.1038/nature14236" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature14236" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 6" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXjsVagur0%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="ADS reference 6" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2015Natur.518..529M" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="Google Scholar reference 6" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Human-level%20control%20through%20deep%20reinforcement%20learning&amp;journal=Nature&amp;doi=10.1038%2Fnature14236&amp;volume=518&amp;pages=529-533&amp;publication_year=2015&amp;author=Mnih%2CV" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7">
              <p class="c-article-references__text" id="ref-CR7">
               Guo, X., Singh, S. P., Lee, H., Lewis, R. L. &amp; Wang, X. Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning. In
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               Vol. 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D. &amp; Weinberger, K. Q. ) 3338–3346 (2014)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8">
              <p class="c-article-references__text" id="ref-CR8">
               Mnih, V . et al. Asynchronous methods for deep reinforcement learning. In
               <i>
                Proc. 33rd Int. Conf. Mach. Learn.
               </i>
               Vol. 48 (eds Balcan, M. F. &amp; Weinberger, K. Q. ) 1928–1937 (2016)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9">
              <p class="c-article-references__text" id="ref-CR9">
               Jaderberg, M . et al. Reinforcement learning with unsupervised auxiliary tasks. In
               <i>
                5th Int. Conf. Learn. Representations
               </i>
               (2017)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10">
              <p class="c-article-references__text" id="ref-CR10">
               Dosovitskiy, A. &amp; Koltun, V. Learning to act by predicting the future. In
               <i>
                5th Int. Conf. Learn. Representations
               </i>
               (2017)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11">
              <p class="c-article-references__text" id="ref-CR11">
               Man´dziuk, J. in
               <i>
                Challenges for Computational Intelligence
               </i>
               ( Duch, W. &amp; Man´dziuk, J. ) 407–442 (Springer, 2007)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12">
              <p class="c-article-references__text" id="ref-CR12">
               Silver, D. et al. Mastering the game of Go with deep neural networks and tree search.
               <i>
                Nature
               </i>
               <b>
                529
               </b>
               , 484–489 (2016)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 12" data-doi="10.1038/nature16961" data-track="click" data-track-action="article reference" data-track-label="10.1038/nature16961" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature16961" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 12" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12is7w%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="ADS reference 12" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016Natur.529..484S" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="Google Scholar reference 12" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Mastering%20the%20game%20of%20Go%20with%20deep%20neural%20networks%20and%20tree%20search&amp;journal=Nature&amp;doi=10.1038%2Fnature16961&amp;volume=529&amp;pages=484-489&amp;publication_year=2016&amp;author=Silver%2CD" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13">
              <p class="c-article-references__text" id="ref-CR13">
               Coulom, R. Efficient selectivity and backup operators in Monte-Carlo tree search. In
               <i>
                5th Int. Conf. Computers and Games
               </i>
               (eds Ciancarini, P. &amp; van den Herik, H. J. ) 72–83 (2006)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14">
              <p class="c-article-references__text" id="ref-CR14">
               Kocsis, L. &amp; Szepesvári, C. Bandit based Monte-Carlo planning. In
               <i>
                15th Eu. Conf. Mach. Learn.
               </i>
               282–293 (2006)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15">
              <p class="c-article-references__text" id="ref-CR15">
               Browne, C. et al. A survey of Monte Carlo tree search methods. IEEE Trans.
               <i>
                Comput. Intell. AI Games
               </i>
               <b>
                4
               </b>
               , 1–49 (2012)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 15" data-doi="10.1109/TCIAIG.2012.2186810" data-track="click" data-track-action="article reference" data-track-label="10.1109/TCIAIG.2012.2186810" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTCIAIG.2012.2186810" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 15" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20Monte%20Carlo%20tree%20search%20methods.%20IEEE%20Trans&amp;journal=Comput.%20Intell.%20AI%20Games&amp;doi=10.1109%2FTCIAIG.2012.2186810&amp;volume=4&amp;pages=1-49&amp;publication_year=2012&amp;author=Browne%2CC" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16">
              <p class="c-article-references__text" id="ref-CR16">
               Fukushima, K. Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.
               <i>
                Biol. Cybern.
               </i>
               <b>
                36
               </b>
               , 193–202 (1980)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 16" data-doi="10.1007/BF00344251" data-track="click" data-track-action="article reference" data-track-label="10.1007/BF00344251" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2FBF00344251" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 16" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:STN:280:DyaL3c7nsFKntw%3D%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 16" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocognitron%3A%20a%20self%20organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern%20recognition%20unaffected%20by%20shift%20in%20position&amp;journal=Biol.%20Cybern.&amp;doi=10.1007%2FBF00344251&amp;volume=36&amp;pages=193-202&amp;publication_year=1980&amp;author=Fukushima%2CK" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17">
              <p class="c-article-references__text" id="ref-CR17">
               LeCun, Y. &amp; Bengio, Y. in
               <i>
                The Handbook of Brain Theory and Neural Networks
               </i>
               Ch. 3 (ed. Arbib, M. ) 276–278 (MIT Press, 1995)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18">
              <p class="c-article-references__text" id="ref-CR18">
               Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In
               <i>
                Proc. 32nd Int. Conf. Mach. Learn.
               </i>
               Vol. 37 448–456 (2015)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19">
              <p class="c-article-references__text" id="ref-CR19">
               Hahnloser, R. H. R., Sarpeshkar, R., Mahowald, M. A., Douglas, R. J. &amp; Seung, H. S. Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit.
               <i>
                Nature
               </i>
               <b>
                405
               </b>
               , 947–951 (2000)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 19" data-doi="10.1038/35016072" data-track="click" data-track-action="article reference" data-track-label="10.1038/35016072" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F35016072" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 19" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BD3cXks1WltrY%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="ADS reference 19" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2000Natur.405..947H" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="Google Scholar reference 19" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Digital%20selection%20and%20analogue%20amplification%20coexist%20in%20a%20cortex-inspired%20silicon%20circuit&amp;journal=Nature&amp;doi=10.1038%2F35016072&amp;volume=405&amp;pages=947-951&amp;publication_year=2000&amp;author=Hahnloser%2CRHR&amp;author=Sarpeshkar%2CR&amp;author=Mahowald%2CMA&amp;author=Douglas%2CRJ&amp;author=Seung%2CHS" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20">
              <p class="c-article-references__text" id="ref-CR20">
               Howard, R.
               <i>
                Dynamic Programming and Markov Processes
               </i>
               (MIT Press, 1960)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21">
              <p class="c-article-references__text" id="ref-CR21">
               Sutton, R . &amp; Barto, A.
               <i>
                Reinforcement Learning: an Introduction
               </i>
               (MIT Press, 1998)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22">
              <p class="c-article-references__text" id="ref-CR22">
               Bertsekas, D. P. Approximate policy iteration: a survey and some new methods.
               <i>
                J. Control Theory Appl.
               </i>
               <b>
                9
               </b>
               , 310–335 (2011)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 22" data-doi="10.1007/s11768-011-1005-3" data-track="click" data-track-action="article reference" data-track-label="10.1007/s11768-011-1005-3" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs11768-011-1005-3" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 22" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2833999" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 22" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Approximate%20policy%20iteration%3A%20a%20survey%20and%20some%20new%20methods&amp;journal=J.%20Control%20Theory%20Appl.&amp;doi=10.1007%2Fs11768-011-1005-3&amp;volume=9&amp;pages=310-335&amp;publication_year=2011&amp;author=Bertsekas%2CDP" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23">
              <p class="c-article-references__text" id="ref-CR23">
               Scherrer, B. Approximate policy iteration schemes: a comparison. In
               <i>
                Proc. 31st Int. Conf. Mach. Learn.
               </i>
               Vol. 32 1314–1322 (2014)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24">
              <p class="c-article-references__text" id="ref-CR24">
               Rosin, C. D. Multi-armed bandits with episode context.
               <i>
                Ann. Math. Artif. Intell.
               </i>
               <b>
                61
               </b>
               , 203–230 (2011)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 24" data-doi="10.1007/s10472-011-9258-6" data-track="click" data-track-action="article reference" data-track-label="10.1007/s10472-011-9258-6" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs10472-011-9258-6" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 24" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2865077" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 24" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-armed%20bandits%20with%20episode%20context&amp;journal=Ann.%20Math.%20Artif.%20Intell.&amp;doi=10.1007%2Fs10472-011-9258-6&amp;volume=61&amp;pages=203-230&amp;publication_year=2011&amp;author=Rosin%2CCD" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25">
              <p class="c-article-references__text" id="ref-CR25">
               Coulom, R. Whole-history rating: a Bayesian rating system for players of time-varying strength. In
               <i>
                Int. Conf. Comput. Games
               </i>
               (eds van den Herik, H. J., Xu, X . Ma, Z . &amp; Winands, M. H. M. ) Vol. 5131 113–124 (Springer, 2008)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26">
              <p class="c-article-references__text" id="ref-CR26">
               Laurent, G. J., Matignon, L. &amp; Le Fort-Piat, N. The world of independent learners is not Markovian.
               <i>
                Int. J. Knowledge-Based Intelligent Engineering Systems
               </i>
               <b>
                15
               </b>
               , 55–64 (2011)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 26" data-doi="10.3233/KES-2010-0206" data-track="click" data-track-action="article reference" data-track-label="10.3233/KES-2010-0206" href="https://doi-org.proxy.lib.ohio-state.edu/10.3233%2FKES-2010-0206" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 26" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20world%20of%20independent%20learners%20is%20not%20Markovian&amp;journal=Int.%20J.%20Knowledge-Based%20Intelligent%20Engineering%20Systems&amp;doi=10.3233%2FKES-2010-0206&amp;volume=15&amp;pages=55-64&amp;publication_year=2011&amp;author=Laurent%2CGJ&amp;author=Matignon%2CL&amp;author=Le%20Fort-Piat%2CN" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27">
              <p class="c-article-references__text" id="ref-CR27">
               Foerster, J. N . et al. Stabilising experience replay for deep multi-agent reinforcement learning. In
               <i>
                Proc. 34th Int. Conf. Mach. Learn.
               </i>
               Vol. 70 1146–1155 (2017)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28">
              <p class="c-article-references__text" id="ref-CR28">
               Heinrich, J . &amp; Silver, D. Deep reinforcement learning from self-play in imperfect-information games. In
               <i>
                NIPS Deep Reinforcement Learning Workshop
               </i>
               (2016)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29">
              <p class="c-article-references__text" id="ref-CR29">
               Jouppi, N. P . et al. In-datacenter performance analysis of a Tensor Processing Unit.
               <i>
                Proc. 44th Annu. Int. Symp. Comp. Architecture
               </i>
               Vol. 17 1–12 (2017)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30">
              <p class="c-article-references__text" id="ref-CR30">
               Maddison, C. J., Huang, A., Sutskever, I . &amp; Silver, D. Move evaluation in Go using deep convolutional neural networks. In
               <i>
                3rd Int. Conf. Learn. Representations.
               </i>
               (2015)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31">
              <p class="c-article-references__text" id="ref-CR31">
               Clark, C . &amp; Storkey, A. J. Training deep convolutional neural networks to play Go. In
               <i>
                Proc. 32nd Int. Conf. Mach. Learn.
               </i>
               Vol. 37 1766–1774 (2015)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32">
              <p class="c-article-references__text" id="ref-CR32">
               Tian, Y. &amp; Zhu, Y. Better computer Go player with neural network and long-term prediction. In
               <i>
                4th Int. Conf. Learn. Representations
               </i>
               (2016)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33">
              <p class="c-article-references__text" id="ref-CR33">
               Cazenave, T. Residual networks for computer Go. IEEE Trans. Comput. Intell. AI Games
               <a data-track="click" data-track-action="external reference" data-track-label="10.1109/TCIAIG.2017.2681042" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042">
                https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042
               </a>
               (2017)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34">
              <p class="c-article-references__text" id="ref-CR34">
               Huang, A. AlphaGo master online series of games.
               <a data-track="click" data-track-action="external reference" data-track-label="https://deepmind.com/research/AlphaGo/match-archive/master" href="https://deepmind.com/research/AlphaGo/match-archive/master">
                https://deepmind.com/research/AlphaGo/match-archive/master
               </a>
               (2017)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35">
              <p class="c-article-references__text" id="ref-CR35">
               Barto, A. G. &amp; Duff, M. Monte Carlo matrix inversion and reinforcement learning.
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               <b>
                6
               </b>
               , 687–694 (1994)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 35" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Monte%20Carlo%20matrix%20inversion%20and%20reinforcement%20learning&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=6&amp;pages=687-694&amp;publication_year=1994&amp;author=Barto%2CAG&amp;author=Duff%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36">
              <p class="c-article-references__text" id="ref-CR36">
               Singh, S. P. &amp; Sutton, R. S. Reinforcement learning with replacing eligibility traces.
               <i>
                Mach. Learn.
               </i>
               <b>
                22
               </b>
               , 123–158 (1996)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="MATH reference 36" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1099.68700" rel="nofollow noopener">
                MATH
               </a>
               <a aria-label="Google Scholar reference 36" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20with%20replacing%20eligibility%20traces&amp;journal=Mach.%20Learn.&amp;volume=22&amp;pages=123-158&amp;publication_year=1996&amp;author=Singh%2CSP&amp;author=Sutton%2CRS" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37">
              <p class="c-article-references__text" id="ref-CR37">
               Lagoudakis, M. G. &amp; Parr, R. Reinforcement learning as classification: leveraging modern classifiers.
               <i>
                In Proc. 20th Int. Conf. Mach. Learn.
               </i>
               424–431 (2003)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38">
              <p class="c-article-references__text" id="ref-CR38">
               Scherrer, B., Ghavamzadeh, M., Gabillon, V., Lesner, B. &amp; Geist, M. Approximate modified policy iteration and its application to the game of Tetris.
               <i>
                J. Mach. Learn. Res.
               </i>
               <b>
                16
               </b>
               , 1629–1676 (2015)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="MathSciNet reference 38" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=3417794" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="MATH reference 38" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1351.90162" rel="nofollow noopener">
                MATH
               </a>
               <a aria-label="Google Scholar reference 38" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Approximate%20modified%20policy%20iteration%20and%20its%20application%20to%20the%20game%20of%20Tetris&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=16&amp;pages=1629-1676&amp;publication_year=2015&amp;author=Scherrer%2CB&amp;author=Ghavamzadeh%2CM&amp;author=Gabillon%2CV&amp;author=Lesner%2CB&amp;author=Geist%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39">
              <p class="c-article-references__text" id="ref-CR39">
               Littman, M. L. Markov games as a framework for multi-agent reinforcement learning.
               <i>
                In Proc. 11th Int. Conf. Mach. Learn.
               </i>
               157–163 (1994)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40">
              <p class="c-article-references__text" id="ref-CR40">
               Enzenberger, M. The integration of a priori knowledge into a Go playing neural network.
               <a data-track="click" data-track-action="external reference" data-track-label="http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html" href="http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html">
                http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html
               </a>
               (1996)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41">
              <p class="c-article-references__text" id="ref-CR41">
               Enzenberger, M. in
               <i>
                Advances in Computer Games
               </i>
               (eds Van Den Herik, H. J., Iida, H. &amp; Heinz, E. A. ) 97–108 (2003)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42">
              <p class="c-article-references__text" id="ref-CR42">
               Sutton, R. Learning to predict by the method of temporal differences.
               <i>
                Mach. Learn.
               </i>
               <b>
                3
               </b>
               , 9–44 (1988)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 42" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20to%20predict%20by%20the%20method%20of%20temporal%20differences&amp;journal=Mach.%20Learn.&amp;volume=3&amp;pages=9-44&amp;publication_year=1988&amp;author=Sutton%2CR" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43">
              <p class="c-article-references__text" id="ref-CR43">
               Schraudolph, N. N., Dayan, P. &amp; Sejnowski, T. J. Temporal difference learning of position evaluation in the game of Go.
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               <b>
                6
               </b>
               , 817–824 (1994)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 43" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20difference%20learning%20of%20position%20evaluation%20in%20the%20game%20of%20Go&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=6&amp;pages=817-824&amp;publication_year=1994&amp;author=Schraudolph%2CNN&amp;author=Dayan%2CP&amp;author=Sejnowski%2CTJ" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44">
              <p class="c-article-references__text" id="ref-CR44">
               Silver, D., Sutton, R. &amp; Müller, M. Temporal-difference search in computer Go.
               <i>
                Mach. Learn.
               </i>
               <b>
                87
               </b>
               , 183–219 (2012)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 44" data-doi="10.1007/s10994-012-5280-0" data-track="click" data-track-action="article reference" data-track-label="10.1007/s10994-012-5280-0" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs10994-012-5280-0" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 44" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2914011" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 44" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal-difference%20search%20in%20computer%20Go&amp;journal=Mach.%20Learn.&amp;doi=10.1007%2Fs10994-012-5280-0&amp;volume=87&amp;pages=183-219&amp;publication_year=2012&amp;author=Silver%2CD&amp;author=Sutton%2CR&amp;author=M%C3%BCller%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45">
              <p class="c-article-references__text" id="ref-CR45">
               Silver, D.
               <i>
                Reinforcement Learning and Simulation-Based Search in Computer Go
               </i>
               . PhD thesis, Univ. Alberta, Edmonton, Canada (2009)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46">
              <p class="c-article-references__text" id="ref-CR46">
               Gelly, S. &amp; Silver, D. Monte-Carlo tree search and rapid action value estimation in computer Go.
               <i>
                Artif. Intell.
               </i>
               <b>
                175
               </b>
               , 1856–1875 (2011)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 46" data-doi="10.1016/j.artint.2011.03.007" data-track="click" data-track-action="article reference" data-track-label="10.1016/j.artint.2011.03.007" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2Fj.artint.2011.03.007" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 46" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2847683" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 46" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Monte-Carlo%20tree%20search%20and%20rapid%20action%20value%20estimation%20in%20computer%20Go&amp;journal=Artif.%20Intell.&amp;doi=10.1016%2Fj.artint.2011.03.007&amp;volume=175&amp;pages=1856-1875&amp;publication_year=2011&amp;author=Gelly%2CS&amp;author=Silver%2CD" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47">
              <p class="c-article-references__text" id="ref-CR47">
               Coulom, R. Computing Elo ratings of move patterns in the game of Go.
               <i>
                Int. Comput. Games Assoc. J.
               </i>
               <b>
                30
               </b>
               , 198–208 (2007)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 47" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computing%20Elo%20ratings%20of%20move%20patterns%20in%20the%20game%20of%20Go&amp;journal=Int.%20Comput.%20Games%20Assoc.%20J.&amp;volume=30&amp;pages=198-208&amp;publication_year=2007&amp;author=Coulom%2CR" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48">
              <p class="c-article-references__text" id="ref-CR48">
               Gelly, S., Wang, Y., Munos, R. &amp; Teytaud, O. Modification of UCT with patterns in Monte-Carlo Go. Report No. 6062 (INRIA, 2006)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49">
              <p class="c-article-references__text" id="ref-CR49">
               Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences.
               <i>
                Mach. Learn.
               </i>
               <b>
                40
               </b>
               , 243–263 (2000)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 49" data-doi="10.1023/A:1007634325138" data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1007634325138" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1007634325138" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 49" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20to%20play%20chess%20using%20temporal%20differences&amp;journal=Mach.%20Learn.&amp;doi=10.1023%2FA%3A1007634325138&amp;volume=40&amp;pages=243-263&amp;publication_year=2000&amp;author=Baxter%2CJ&amp;author=Tridgell%2CA&amp;author=Weaver%2CL" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50">
              <p class="c-article-references__text" id="ref-CR50">
               Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               1937–1945 (2009)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51">
              <p class="c-article-references__text" id="ref-CR51">
               Lai, M.
               <i>
                Giraffe: Using Deep Reinforcement Learning to Play Chess
               </i>
               . MSc thesis, Imperial College London (2015)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52">
              <p class="c-article-references__text" id="ref-CR52">
               Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In
               <i>
                Proc. 17th Int. Jt Conf. Artif. Intell.
               </i>
               Vol. 1 529–534 (2001)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53">
              <p class="c-article-references__text" id="ref-CR53">
               Tesauro, G. TD-gammon, a self-teaching backgammon program, achieves master-level play.
               <i>
                Neural Comput.
               </i>
               <b>
                6
               </b>
               , 215–219 (1994)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 53" data-doi="10.1162/neco.1994.6.2.215" data-track="click" data-track-action="article reference" data-track-label="10.1162/neco.1994.6.2.215" href="https://doi-org.proxy.lib.ohio-state.edu/10.1162%2Fneco.1994.6.2.215" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 53" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=TD-gammon%2C%20a%20self-teaching%20backgammon%20program%2C%20achieves%20master-level%20play&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.1994.6.2.215&amp;volume=6&amp;pages=215-219&amp;publication_year=1994&amp;author=Tesauro%2CG" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54">
              <p class="c-article-references__text" id="ref-CR54">
               Buro, M. From simple features to sophisticated evaluation functions. In
               <i>
                Proc. 1st Int. Conf. Comput. Games
               </i>
               126–145 (1999)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55">
              <p class="c-article-references__text" id="ref-CR55">
               Sheppard, B. World-championship-caliber Scrabble.
               <i>
                Artif. Intell.
               </i>
               <b>
                134
               </b>
               , 241–275 (2002)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 55" data-doi="10.1016/S0004-3702(01)00166-7" data-track="click" data-track-action="article reference" data-track-label="10.1016/S0004-3702(01)00166-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0004-3702%2801%2900166-7" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 55" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=World-championship-caliber%20Scrabble&amp;journal=Artif.%20Intell.&amp;doi=10.1016%2FS0004-3702%2801%2900166-7&amp;volume=134&amp;pages=241-275&amp;publication_year=2002&amp;author=Sheppard%2CB" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56">
              <p class="c-article-references__text" id="ref-CR56">
               Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker.
               <i>
                Science
               </i>
               <b>
                356
               </b>
               , 508–513 (2017)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 56" data-doi="10.1126/science.aam6960" data-track="click" data-track-action="article reference" data-track-label="10.1126/science.aam6960" href="https://doi-org.proxy.lib.ohio-state.edu/10.1126%2Fscience.aam6960" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="ADS reference 56" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017Sci...356..508M" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="MathSciNet reference 56" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=3676953" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 56" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=DeepStack%3A%20expert-level%20artificial%20intelligence%20in%20heads-up%20no-limit%20poker&amp;journal=Science&amp;doi=10.1126%2Fscience.aam6960&amp;volume=356&amp;pages=508-513&amp;publication_year=2017&amp;author=Moravc%CB%87%C3%ADk%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57">
              <p class="c-article-references__text" id="ref-CR57">
               Tesauro, G &amp; Galperin, G. On-line policy improvement using Monte-Carlo search. In
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               1068–1074 (1996)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58">
              <p class="c-article-references__text" id="ref-CR58">
               Tesauro, G. Neurogammon: a neural-network backgammon program. In
               <i>
                Proc. Int. Jt Conf. Neural Netw.
               </i>
               Vol. 3, 33–39 (1990)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59">
              <p class="c-article-references__text" id="ref-CR59">
               Samuel, A. L. Some studies in machine learning using the game of checkers II - recent progress.
               <i>
                IBM J. Res. Develop.
               </i>
               <b>
                11
               </b>
               , 601–617 (1967)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 59" data-doi="10.1147/rd.116.0601" data-track="click" data-track-action="article reference" data-track-label="10.1147/rd.116.0601" href="https://doi-org.proxy.lib.ohio-state.edu/10.1147%2Frd.116.0601" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 59" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Some%20studies%20in%20machine%20learning%20using%20the%20game%20of%20checkers%20II%20-%20recent%20progress&amp;journal=IBM%20J.%20Res.%20Develop.&amp;doi=10.1147%2Frd.116.0601&amp;volume=11&amp;pages=601-617&amp;publication_year=1967&amp;author=Samuel%2CAL" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60">
              <p class="c-article-references__text" id="ref-CR60">
               Kober, J., Bagnell, J. A. &amp; Peters, J. Reinforcement learning in robotics: a survey.
               <i>
                Int. J. Robot. Res.
               </i>
               <b>
                32
               </b>
               , 1238–1274 (2013)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 60" data-doi="10.1177/0278364913495721" data-track="click" data-track-action="article reference" data-track-label="10.1177/0278364913495721" href="https://doi-org.proxy.lib.ohio-state.edu/10.1177%2F0278364913495721" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 60" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20in%20robotics%3A%20a%20survey&amp;journal=Int.%20J.%20Robot.%20Res.&amp;doi=10.1177%2F0278364913495721&amp;volume=32&amp;pages=1238-1274&amp;publication_year=2013&amp;author=Kober%2CJ&amp;author=Bagnell%2CJA&amp;author=Peters%2CJ" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61">
              <p class="c-article-references__text" id="ref-CR61">
               Zhang, W. &amp; Dietterich, T. G. A reinforcement learning approach to job-shop scheduling.
               <i>
                In Proc. 14th Int. Jt Conf. Artif. Intell.
               </i>
               1114–1120 (1995)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62">
              <p class="c-article-references__text" id="ref-CR62">
               Cazenave, T., Balbo, F. &amp; Pinson, S. Using a Monte-Carlo approach for bus regulation. In
               <i>
                Int. IEEE Conf. Intell. Transport. Syst.
               </i>
               1–6 (2009)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63">
              <p class="c-article-references__text" id="ref-CR63">
               Evans, R. &amp; Gao, J. Deepmind AI reduces Google data centre cooling bill by 40%.
               <a data-track="click" data-track-action="external reference" data-track-label="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/" href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/">
                https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/
               </a>
               (2016)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64">
              <p class="c-article-references__text" id="ref-CR64">
               Abe, N . et al. Empirical comparison of various reinforcement learning strategies for sequential targeted marketing. In
               <i>
                IEEE Int. Conf. Data Mining
               </i>
               3–10 (2002)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65">
              <p class="c-article-references__text" id="ref-CR65">
               Silver, D., Newnham, L., Barker, D., Weller, S. &amp; McFall, J. Concurrent reinforcement learning from customer interactions. In
               <i>
                Proc. 30th Int. Conf. Mach. Learn.
               </i>
               Vol. 28 924–932 (2013)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66">
              <p class="c-article-references__text" id="ref-CR66">
               Tromp, J. Tromp–Taylor rules.
               <a data-track="click" data-track-action="external reference" data-track-label="http://tromp.github.io/go.html" href="http://tromp.github.io/go.html">
                http://tromp.github.io/go.html
               </a>
               (1995)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67">
              <p class="c-article-references__text" id="ref-CR67">
               Müller, M. Computer Go.
               <i>
                Artif. Intell.
               </i>
               <b>
                134
               </b>
               , 145–179 (2002)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 67" data-doi="10.1016/S0004-3702(01)00121-7" data-track="click" data-track-action="article reference" data-track-label="10.1016/S0004-3702(01)00121-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0004-3702%2801%2900121-7" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 67" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer%20Go&amp;journal=Artif.%20Intell.&amp;doi=10.1016%2FS0004-3702%2801%2900121-7&amp;volume=134&amp;pages=145-179&amp;publication_year=2002&amp;author=M%C3%BCller%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68">
              <p class="c-article-references__text" id="ref-CR68">
               Shahriari, B., Swersky, K., Wang, Z., Adams, R. P. &amp; de Freitas, N. Taking the human out of the loop: a review of Bayesian optimization.
               <i>
                Proc. IEEE
               </i>
               <b>
                104
               </b>
               , 148–175 (2016)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 68" data-doi="10.1109/JPROC.2015.2494218" data-track="click" data-track-action="article reference" data-track-label="10.1109/JPROC.2015.2494218" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FJPROC.2015.2494218" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 68" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Taking%20the%20human%20out%20of%20the%20loop%3A%20a%20review%20of%20Bayesian%20optimization&amp;journal=Proc.%20IEEE&amp;doi=10.1109%2FJPROC.2015.2494218&amp;volume=104&amp;pages=148-175&amp;publication_year=2016&amp;author=Shahriari%2CB&amp;author=Swersky%2CK&amp;author=Wang%2CZ&amp;author=Adams%2CRP&amp;author=de%20Freitas%2CN" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="69">
              <p class="c-article-references__text" id="ref-CR69">
               Segal, R. B. On the scalability of parallel UCT.
               <i>
                Comput. Games
               </i>
               <b>
                6515
               </b>
               , 36–47 (2011)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 69" data-doi="10.1007/978-3-642-17928-0_4" data-track="click" data-track-action="article reference" data-track-label="10.1007/978-3-642-17928-0_4" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2F978-3-642-17928-0_4" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 69" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2803987" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 69" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20scalability%20of%20parallel%20UCT&amp;journal=Comput.%20Games&amp;doi=10.1007%2F978-3-642-17928-0_4&amp;volume=6515&amp;pages=36-47&amp;publication_year=2011&amp;author=Segal%2CRB" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
            </ol>
            <p class="c-article-references__download u-hide-print">
             <a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed-springer-com.proxy.lib.ohio-state.edu/v2/references/10.1038/nature24270?format=refman&amp;flavour=references" rel="nofollow">
              Download references
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-download" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </p>
           </div>
          </div>
         </div>
        </section>
       </div>
       <section data-title="Acknowledgements">
        <div class="c-article-section" id="Ack1-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">
          Acknowledgements
         </h2>
         <div class="c-article-section__content" id="Ack1-content">
          <p>
           We thank A. Cain for work on the visuals; A. Barreto, G. Ostrovski, T. Ewalds, T. Schaul, J. Oh and N. Heess for reviewing the paper; and the rest of the DeepMind team for their support.
          </p>
         </div>
        </div>
       </section>
       <section aria-labelledby="author-information" data-title="Author information">
        <div class="c-article-section" id="author-information-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">
          Author information
         </h2>
         <div class="c-article-section__content" id="author-information-content">
          <span class="c-article-author-information__subtitle u-visually-hidden" id="author-notes">
           Author notes
          </span>
          <ol class="c-article-author-information__list">
           <li class="c-article-author-information__item" id="na1">
            <p>
             David Silver, Julian Schrittwieser and Karen Simonyan: These authors contributed equally to this work.
            </p>
           </li>
          </ol>
          <h3 class="c-article__sub-heading" id="affiliations">
           Authors and Affiliations
          </h3>
          <ol class="c-article-author-affiliation__list">
           <li id="Aff1">
            <p class="c-article-author-affiliation__address">
             DeepMind, 5 New Street Square, London, EC4A 3TW, UK
            </p>
            <p class="c-article-author-affiliation__authors-list">
             David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel &amp; Demis Hassabis
            </p>
           </li>
          </ol>
          <div class="u-js-hide u-hide-print" data-test="author-info">
           <span class="c-article__sub-heading">
            Authors
           </span>
           <ol class="c-article-authors-search u-list-reset">
            <li id="auth-David-Silver-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              David Silver
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=David%20Silver" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=David%20Silver" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David%20Silver%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Julian-Schrittwieser-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Julian Schrittwieser
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Julian%20Schrittwieser" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Julian%20Schrittwieser" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Julian%20Schrittwieser%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Karen-Simonyan-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Karen Simonyan
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Karen%20Simonyan" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Karen%20Simonyan" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Karen%20Simonyan%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Ioannis-Antonoglou-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Ioannis Antonoglou
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Ioannis%20Antonoglou" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Ioannis%20Antonoglou" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ioannis%20Antonoglou%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Aja-Huang-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Aja Huang
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Aja%20Huang" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Aja%20Huang" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Aja%20Huang%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Arthur-Guez-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Arthur Guez
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Arthur%20Guez" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Arthur%20Guez" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Arthur%20Guez%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Thomas-Hubert-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Thomas Hubert
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Thomas%20Hubert" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Thomas%20Hubert" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thomas%20Hubert%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Lucas-Baker-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Lucas Baker
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Lucas%20Baker" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Lucas%20Baker" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lucas%20Baker%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Matthew-Lai-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Matthew Lai
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Matthew%20Lai" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Matthew%20Lai" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Matthew%20Lai%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Adrian-Bolton-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Adrian Bolton
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Adrian%20Bolton" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Adrian%20Bolton" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Adrian%20Bolton%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Yutian-Chen-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Yutian Chen
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Yutian%20Chen" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Yutian%20Chen" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yutian%20Chen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Timothy-Lillicrap-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Timothy Lillicrap
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Timothy%20Lillicrap" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Timothy%20Lillicrap" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Timothy%20Lillicrap%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Fan-Hui-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Fan Hui
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Fan%20Hui" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Fan%20Hui" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fan%20Hui%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Laurent-Sifre-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Laurent Sifre
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Laurent%20Sifre" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Laurent%20Sifre" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Laurent%20Sifre%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-George-van_den_Driessche-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              George van den Driessche
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=George%20van%20den%20Driessche" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=George%20van%20den%20Driessche" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22George%20van%20den%20Driessche%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Thore-Graepel-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Thore Graepel
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Thore%20Graepel" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Thore%20Graepel" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thore%20Graepel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Demis-Hassabis-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Demis Hassabis
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Demis%20Hassabis" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Demis%20Hassabis" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Demis%20Hassabis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
           </ol>
          </div>
          <h3 class="c-article__sub-heading" id="contributions">
           Contributions
          </h3>
          <p>
           D.S., J.S., K.S., I.A., A.G., L.S. and T.H. designed and implemented the reinforcement learning algorithm in AlphaGo Zero. A.H., J.S., M.L. and D.S. designed and implemented the search in AlphaGo Zero. L.B., J.S., A.H., F.H., T.H., Y.C. and D.S. designed and implemented the evaluation framework for AlphaGo Zero. D.S., A.B., F.H., A.G., T.L., T.G., L.S., G.v.d.D. and D.H. managed and advised on the project. D.S., T.G. and A.G. wrote the paper.
          </p>
          <h3 class="c-article__sub-heading" id="corresponding-author">
           Corresponding author
          </h3>
          <p id="corresponding-author-list">
           Correspondence to
           <a href="mailto:davidsilver@google.com" id="corresp-c1">
            David Silver
           </a>
           .
          </p>
         </div>
        </div>
       </section>
       <section data-title="Ethics declarations">
        <div class="c-article-section" id="ethics-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">
          Ethics declarations
         </h2>
         <div class="c-article-section__content" id="ethics-content">
          <h3 class="c-article__sub-heading">
           Competing interests
          </h3>
          <p>
           The authors declare no competing financial interests.
          </p>
         </div>
        </div>
       </section>
       <section data-title="Additional information">
        <div class="c-article-section" id="additional-information-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">
          Additional information
         </h2>
         <div class="c-article-section__content" id="additional-information-content">
          <p>
           <b>
            Reviewer Information
           </b>
           <i>
            Nature
           </i>
           thanks S. Singh and the other anonymous reviewer(s) for their contribution to the peer review of this work.
          </p>
          <p>
           Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
          </p>
         </div>
        </div>
       </section>
       <section data-title="Extended data figures and tables">
        <div class="c-article-section" id="Sec26-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec26">
          Extended data figures and tables
         </h2>
         <div class="c-article-section__content" id="Sec26-content">
          <div data-test="supplementary-info">
           <div class="c-article-figshare-container" data-test="figshare-container" id="figshareContainer">
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig7">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig7_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 1 tournament games between al" href="/articles/nature24270/figures/7">
              Extended Data Figure 1 Tournament games between AlphaGo Zero (20 blocks, 3 days) versus AlphaGo Lee using 2 h time controls.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              One hundred moves of the first 20 games are shown; full games are provided in the
              <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
               Supplementary Information
              </a>
              .
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig8">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig8_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 2 frequency of occurence over" href="/articles/nature24270/figures/8">
              Extended Data Figure 2 Frequency of occurence over time during training, for each
              <i>
               joseki
              </i>
              from Fig. 5a (corner sequences common in professional play that were discovered by AlphaGo Zero).
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              The corresponding
              <i>
               joseki
              </i>
              are shown on the right.
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig9">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig9_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 3 frequency of occurence over" href="/articles/nature24270/figures/9">
              Extended Data Figure 3 Frequency of occurence over time during training, for each
              <i>
               joseki
              </i>
              from Fig. 5b (corner sequences that AlphaGo Zero favoured for at least one iteration), and one additional variation.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              The corresponding
              <i>
               joseki
              </i>
              are shown on the right.
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig10">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig10_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 4 alphago zero (20 blocks) se" href="/articles/nature24270/figures/10">
              Extended Data Figure 4 AlphaGo Zero (20 blocks) self-play games.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              The 3-day training run was subdivided into 20 periods. The best player from each period (as selected by the evaluator) played a single game against itself, with 2 h time controls. One hundred moves are shown for each game; full games are provided in the
              <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
               Supplementary Information
              </a>
              .
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig11">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig11_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 5 alphago zero (40 blocks) se" href="/articles/nature24270/figures/11">
              Extended Data Figure 5 AlphaGo Zero (40 blocks) self-play games.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              The 40-day training run was subdivided into 20 periods. The best player from each period (as selected by the evaluator) played a single game against itself, with 2 h time controls. One hundred moves are shown for each game; full games are provided in the
              <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
               Supplementary Information
              </a>
              .
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig12">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig12_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 6 alphago zero (40 blocks, 40" href="/articles/nature24270/figures/12">
              Extended Data Figure 6 AlphaGo Zero (40 blocks, 40 days) versus AlphaGo Master tournament games using 2 h time controls.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              One hundred moves of the first 20 games are shown; full games are provided in the
              <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature24270#MOESM1">
               Supplementary Information
              </a>
              .
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-1">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab1">
                Extended Data Table 1 Move prediction accuracy
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 1" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature24270/tables/1" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-2">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab2">
                Extended Data Table 2 Game outcome prediction error
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 2" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature24270/tables/2" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-3">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab3">
                Extended Data Table 3 Learning rate schedule
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 3" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature24270/tables/3" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
          </div>
         </div>
        </div>
       </section>
       <section data-title="Supplementary information">
        <div class="c-article-section" id="Sec27-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec27">
          Supplementary information
         </h2>
         <div class="c-article-section__content" id="Sec27-content">
          <div data-test="supplementary-info">
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="reporting summary (pdf 67 kb)" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM1_ESM.pdf">
              Reporting Summary (PDF 67 kb)
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM2">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="supplementary data" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM2_ESM.zip">
              Supplementary Data
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              This zipped file contains the game records of self-play and tournament games played by AlphaGo Zero in .sgf format. (ZIP 82 kb)
             </p>
            </div>
           </div>
          </div>
         </div>
        </div>
       </section>
       <section data-title="PowerPoint slides">
        <div class="c-article-section" id="Sec28-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec28">
          PowerPoint slides
         </h2>
         <div class="c-article-section__content" id="Sec28-content">
          <div data-test="supplementary-info">
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM3">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 1" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM3_ESM.ppt">
              PowerPoint slide for Fig. 1
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM4">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 2" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM4_ESM.ppt">
              PowerPoint slide for Fig. 2
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM5">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 3" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM5_ESM.ppt">
              PowerPoint slide for Fig. 3
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM6">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 4" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM6_ESM.ppt">
              PowerPoint slide for Fig. 4
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM7">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 5" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM7_ESM.ppt">
              PowerPoint slide for Fig. 5
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM8">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 6" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_BFnature24270_MOESM8_ESM.ppt">
              PowerPoint slide for Fig. 6
             </a>
            </h3>
           </div>
          </div>
         </div>
        </div>
       </section>
       <section data-title="Rights and permissions">
        <div class="c-article-section" id="rightslink-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">
          Rights and permissions
         </h2>
         <div class="c-article-section__content" id="rightslink-content">
          <p class="c-article-rights">
           <a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Mastering%20the%20game%20of%20Go%20without%20human%20knowledge&amp;author=David%20Silver%20et%20al&amp;contentID=10.1038%2Fnature24270&amp;copyright=Macmillan%20Publishers%20Limited%2C%20part%20of%20Springer%20Nature.%20All%20rights%20reserved.&amp;publication=0028-0836&amp;publicationDate=2017-10-19&amp;publisherName=SpringerNature&amp;orderBeanReset=true">
            Reprints and Permissions
           </a>
          </p>
         </div>
        </div>
       </section>
       <section aria-labelledby="article-info" data-title="About this article">
        <div class="c-article-section" id="article-info-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">
          About this article
         </h2>
         <div class="c-article-section__content" id="article-info-content">
          <div class="c-bibliographic-information">
           <div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border">
            <a data-crossmark="10.1038/nature24270" data-test="crossmark" data-track="click" data-track-action="Click Crossmark" data-track-label="link" href="https://crossmark-crossref-org.proxy.lib.ohio-state.edu/dialog/?doi=10.1038/nature24270" rel="noopener" target="_blank">
             <img alt="Check for updates. Verify currency and authenticity via CrossMark" height="81" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" width="57"/>
            </a>
           </div>
           <div class="c-bibliographic-information__column">
            <h3 class="c-article__sub-heading" id="citeas">
             Cite this article
            </h3>
            <p class="c-bibliographic-information__citation">
             Silver, D., Schrittwieser, J., Simonyan, K.
             <i>
              et al.
             </i>
             Mastering the game of Go without human knowledge.
             <i>
              Nature
             </i>
             <b>
              550
             </b>
             , 354–359 (2017). https://doi-org.proxy.lib.ohio-state.edu/10.1038/nature24270
            </p>
            <p class="c-bibliographic-information__download-citation u-hide-print">
             <a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-external="" data-track-label="link" href="https://citation-needed-springer-com.proxy.lib.ohio-state.edu/v2/references/10.1038/nature24270?format=refman&amp;flavour=citation" rel="nofollow">
              Download citation
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-download" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </p>
            <ul class="c-bibliographic-information__list" data-test="publication-history">
             <li class="c-bibliographic-information__list-item">
              <p>
               Received
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2017-04-07">
                 07 April 2017
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item">
              <p>
               Accepted
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2017-09-13">
                 13 September 2017
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item">
              <p>
               Published
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2017-10-19">
                 19 October 2017
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item">
              <p>
               Issue Date
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2017-10-19">
                 19 October 2017
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width">
              <p>
               <abbr title="Digital Object Identifier">
                DOI
               </abbr>
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                https://doi-org.proxy.lib.ohio-state.edu/10.1038/nature24270
               </span>
              </p>
             </li>
            </ul>
            <div data-component="share-box">
             <div class="c-article-share-box u-display-block">
              <h3 class="c-article__sub-heading">
               Share this article
              </h3>
              <p class="c-article-share-box__description">
               Anyone you share the following link with will be able to read this content:
              </p>
              <button class="js-get-share-url c-article-share-box__button" data-track="click" data-track-action="get shareable link" data-track-external="" data-track-label="button" id="get-share-url" type="button">
               Get shareable link
              </button>
              <div class="js-no-share-url-container u-display-none" hidden="">
               <p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">
                Sorry, a shareable link is not currently available for this article.
               </p>
              </div>
              <div class="js-share-url-container u-display-none" hidden="">
               <p class="js-share-url c-article-share-box__only-read-input" data-track="click" data-track-action="select share url" data-track-label="button" id="share-url">
               </p>
               <button class="js-copy-share-url c-article-share-box__button--link-like" data-track="click" data-track-action="copy share url" data-track-external="" data-track-label="button" id="copy-share-url" type="button">
                Copy to clipboard
               </button>
              </div>
              <p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
               Provided by the Springer Nature SharedIt content-sharing initiative
              </p>
             </div>
            </div>
            <div data-component="article-info-list">
             <h3 class="c-article__sub-heading">
              Subjects
             </h3>
             <ul class="c-article-subject-list">
              <li class="c-article-subject-list__subject">
               <a data-track="click" data-track-action="view subject" data-track-label="link" href="/subjects/computational-science">
                Computational science
               </a>
              </li>
              <li class="c-article-subject-list__subject">
               <a data-track="click" data-track-action="view subject" data-track-label="link" href="/subjects/computer-science">
                Computer science
               </a>
              </li>
              <li class="c-article-subject-list__subject">
               <a data-track="click" data-track-action="view subject" data-track-label="link" href="/subjects/reward">
                Reward
               </a>
              </li>
             </ul>
            </div>
           </div>
          </div>
         </div>
        </div>
       </section>
      </div>
      <section>
       <div class="c-article-section js-article-section" id="further-reading-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">
         This article is cited by
        </h2>
        <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
         <ul class="c-article-further-reading__list" id="further-reading-list">
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Exploring the ability of machine learning-based virtual screening models to identify the functional groups responsible for binding" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s13321-023-00755-3">
             Exploring the ability of machine learning-based virtual screening models to identify the functional groups responsible for binding
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Thomas E. Hadfield
            </li>
            <li>
             Jack Scantlebury
            </li>
            <li>
             Charlotte M. Deane
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Cheminformatics
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Reliability-aware failure recovery for cloud computing based automatic train supervision systems in urban rail transit using deep reinforcement learning" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s13677-023-00502-x">
             Reliability-aware failure recovery for cloud computing based automatic train supervision systems in urban rail transit using deep reinforcement learning
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Li Zhu
            </li>
            <li>
             Qingheng Zhuang
            </li>
            <li>
             Wei Wang
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Cloud Computing
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Ethics and governance of trustworthy medical artificial intelligence" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s12911-023-02103-9">
             Ethics and governance of trustworthy medical artificial intelligence
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Jie Zhang
            </li>
            <li>
             Zong-ming Zhang
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             BMC Medical Informatics and Decision Making
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Informatics colourizes polymers" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41570-023-00484-z">
             Informatics colourizes polymers
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Xiaolin Liu
            </li>
            <li>
             Chunlei Zhu
            </li>
            <li>
             Ben Zhong Tang
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Nature Reviews Chemistry
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Champion-level drone racing using deep reinforcement learning" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41586-023-06419-4">
             Champion-level drone racing using deep reinforcement learning
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Elia Kaufmann
            </li>
            <li>
             Leonard Bauersfeld
            </li>
            <li>
             Davide Scaramuzza
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Nature
            </i>
            (2023)
           </p>
          </li>
         </ul>
        </div>
       </div>
      </section>
      <section data-title="Comments">
       <div class="c-article-section" id="article-comments-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-comments">
         Comments
        </h2>
        <div class="c-article-section__content" id="article-comments-content">
         <p>
          By submitting a comment you agree to abide by our
          <a href="/info/tandc.html">
           Terms
          </a>
          and
          <a href="/info/community-guidelines.html">
           Community Guidelines
          </a>
          . If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.
         </p>
        </div>
       </div>
      </section>
      <div id="inject-comments">
       <div class="placeholder" data-disqus-placeholder="/platform/disqus?doi=10.1038/nature24270 #article-comments-container" data-replace="true">
       </div>
      </div>
     </div>
    </article>
   </main>
   <aside aria-label="Article navigation" class="c-article-extras u-hide-print" data-component-reading-companion="" data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
     <noscript>
      <div class="c-nature-box c-nature-box--side" data-component="entitlement-box">
       <p class="c-nature-box__text js-text">
        You have full access to this article via your institution.
       </p>
       <div class="c-pdf-download u-clear-both js-pdf-download">
        <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature24270.pdf">
         <span class="c-pdf-download__text">
          Download PDF
         </span>
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
          <use xlink:href="#icon-download">
          </use>
         </svg>
        </a>
       </div>
      </div>
     </noscript>
     <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
      <div class="c-nature-box c-nature-box--side u-hide-print" data-component="entitlement-box" id="entitlement-box-right-column">
       <p class="c-nature-box__text js-text">
        You have full access to this article via
        <strong>
         Ohio State University Libraries
        </strong>
       </p>
       <div class="c-pdf-download u-clear-both js-pdf-download">
        <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature24270.pdf">
         <span class="c-pdf-download__text">
          Download PDF
         </span>
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
          <use xlink:href="#icon-download">
          </use>
         </svg>
        </a>
       </div>
      </div>
     </div>
    </div>
    <div class="c-article-editorial-summary__container u-mb-16" data-component-show-more="true" id="editorial-summary">
     <section>
      <h2 class="c-article-editorial-summary__title u-h3 u-mb-16">
       Editorial Summary
      </h2>
      <h3 class="c-article-editorial-summary__article-title u-mb-8">
       AlphaGo Zero goes solo
      </h3>
      <div class="c-article-editorial-summary__content c-article-editorial-summary__content--less">
       <p>
        To beat world champions at the game of Go, the computer program AlphaGo has relied largely on supervised learning from millions of human expert moves. David Silver and colleagues have now produced a system called AlphaGo Zero, which is based purely on reinforcement learning and learns solely from self-play. Starting from random moves, it can reach superhuman level in just a couple of days of training and five million games of self-play, and can now beat all previous versions of AlphaGo. Because the machine independently discovers the same fundamental principles of the game that took humans millennia to conceptualize, the work suggests that such principles have some universal character, beyond human bias.
       </p>
      </div>
      <button class="c-article-editorial-summary__button" data-track="click" data-track-action="editorial summary show less" data-track-label="button" id="show-button" type="button">
       show all
      </button>
     </section>
    </div>
    <div class="c-article-associated-content__container">
     <section>
      <h2 class="c-article-associated-content__title u-mb-24">
       Associated Content
      </h2>
      <div class="u-full-height u-mb-24">
       <article class="u-full-height c-card c-card--flush">
        <div class="c-card__layout u-full-height">
         <div class="c-card__body">
          <h3 class="c-card__title">
           <a class="c-card__link u-link-inherit" data-track="click" data-track-action="view article" data-track-category="associated content" data-track-label="news_and_views" href="/articles/550336a">
            Learning to play Go from scratch
           </a>
          </h3>
          <ul class="c-author-list c-author-list--compact" data-test="author-list">
           <li>
            Satinder Singh
           </li>
           <li>
            Andy Okun
           </li>
           <li>
            Andrew Jackson
           </li>
          </ul>
          <div class="c-card__section c-meta">
           <span class="c-meta__item">
            Nature
           </span>
           <span class="c-meta__item" data-test="article.type">
            <span class="c-meta__type">
             News &amp; Views
            </span>
           </span>
           <time class="c-meta__item" datetime="2017-10-19">
            19 Oct 2017
           </time>
          </div>
         </div>
        </div>
       </article>
      </div>
     </section>
    </div>
    <script>
     window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "news_and_views";
    </script>
    <div class="c-reading-companion">
     <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky" style="top: 40px;">
      <ul class="c-reading-companion__tabs" role="tablist">
       <li role="presentation">
        <button aria-controls="tabpanel-sections" aria-selected="true" class="c-reading-companion__tab c-reading-companion__tab--active" data-tab-target="sections" data-track="click" data-track-action="sections tab" data-track-label="tab" id="tab-sections" role="tab">
         Sections
        </button>
       </li>
       <li role="presentation">
        <button aria-controls="tabpanel-figures" aria-selected="false" class="c-reading-companion__tab" data-tab-target="figures" data-track="click" data-track-action="figures tab" data-track-label="tab" id="tab-figures" role="tab" tabindex="-1">
         Figures
        </button>
       </li>
       <li role="presentation">
        <button aria-controls="tabpanel-references" aria-selected="false" class="c-reading-companion__tab" data-tab-target="references" data-track="click" data-track-action="references tab" data-track-label="tab" id="tab-references" role="tab" tabindex="-1">
         References
        </button>
       </li>
      </ul>
      <div aria-labelledby="tab-sections" class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections" role="tabpanel">
       <div class="c-reading-companion__scroll-pane" style="max-height: none;">
        <ul class="c-reading-companion__sections-list">
         <li class="c-reading-companion__section-item" id="rc-sec-Abs1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Abstract" href="#Abs1">
           Abstract
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Main" href="#Sec1">
           Main
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec2">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Reinforcement learning in AlphaGo Zero" href="#Sec2">
           Reinforcement learning in AlphaGo Zero
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec3">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Empirical analysis of AlphaGo Zero training" href="#Sec3">
           Empirical analysis of AlphaGo Zero training
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec4">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Knowledge learned by AlphaGo Zero" href="#Sec4">
           Knowledge learned by AlphaGo Zero
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec5">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Final performance of AlphaGo Zero" href="#Sec5">
           Final performance of AlphaGo Zero
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec6">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Conclusion" href="#Sec6">
           Conclusion
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec7">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Methods" href="#Sec7">
           Methods
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Bib1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:References" href="#Bib1">
           References
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Ack1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Acknowledgements" href="#Ack1">
           Acknowledgements
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-author-information">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Author information" href="#author-information">
           Author information
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-ethics">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Ethics declarations" href="#ethics">
           Ethics declarations
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-additional-information">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Additional information" href="#additional-information">
           Additional information
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec26">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Extended data figures and tables" href="#Sec26">
           Extended data figures and tables
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec27">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Supplementary information" href="#Sec27">
           Supplementary information
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec28">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:PowerPoint slides" href="#Sec28">
           PowerPoint slides
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-rightslink">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Rights and permissions" href="#rightslink">
           Rights and permissions
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-article-info">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:About this article" href="#article-info">
           About this article
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-further-reading">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:This article is cited by" href="#further-reading">
           This article is cited by
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-article-comments">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Comments" href="#article-comments">
           Comments
          </a>
         </li>
        </ul>
       </div>
       <div class="u-lazy-ad-wrapper u-mt-16 u-show" data-component-mpu="">
        <div class="c-ad c-ad--300x250">
         <div class="c-ad__inner">
          <p class="c-ad__label">
           Advertisement
          </p>
          <div class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide" data-ad-type="right" data-gpt="" data-gpt-sizes="300x250" data-gpt-targeting="type=article;pos=right;artid=nature24270;doi=10.1038/nature24270;techmeta=129,139;subjmeta=1042,117,1788,378,631,639,705;kwrd=Computational+science,Computer+science,Reward" data-gpt-unitpath="/285/nature.com/article" data-pa11y-ignore="" data-test="right-ad" id="div-gpt-ad-right-2">
           <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=300x250&amp;c=1941157852&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnature24270%26doi%3D10.1038/nature24270%26techmeta%3D129,139%26subjmeta%3D1042,117,1788,378,631,639,705%26kwrd%3DComputational+science,Computer+science,Reward">
             <img alt="Advertisement" data-test="gpt-advert-fallback-img" height="250" src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=300x250&amp;c=1941157852&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnature24270%26doi%3D10.1038/nature24270%26techmeta%3D129,139%26subjmeta%3D1042,117,1788,378,631,639,705%26kwrd%3DComputational+science,Computer+science,Reward" width="300"/>
            </a>
           </noscript>
          </div>
         </div>
        </div>
       </div>
      </div>
      <div aria-labelledby="tab-figures" class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures" role="tabpanel">
       <div class="c-reading-companion__scroll-pane">
        <ul class="c-reading-companion__figures-list">
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig1">
             Figure 1: Self-play reinforcement learning in AlphaGo Zero.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg?"/>
            <img alt="figure 1" aria-describedby="rc-Fig1" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig1_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig1">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/1" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig2">
             Figure 2: MCTS in AlphaGo Zero.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig2_HTML.jpg?"/>
            <img alt="figure 2" aria-describedby="rc-Fig2" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig2_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig2">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/2" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig3">
             Figure 3: Empirical evaluation of AlphaGo Zero.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig3_HTML.jpg?"/>
            <img alt="figure 3" aria-describedby="rc-Fig3" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig3_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig3">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/3" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig4">
             Figure 4: Comparison of neural network architectures in AlphaGo Zero and AlphaGo Lee.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig4_HTML.jpg?"/>
            <img alt="figure 4" aria-describedby="rc-Fig4" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig4_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig4">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/4" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig5">
             Figure 5: Go knowledge learned by AlphaGo Zero.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig5_HTML.jpg?"/>
            <img alt="figure 5" aria-describedby="rc-Fig5" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig5_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig5">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/5" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig6">
             Figure 6: Performance of AlphaGo Zero.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig6_HTML.jpg?"/>
            <img alt="figure 6" aria-describedby="rc-Fig6" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig6_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig6">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/6" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig7">
             Extended Data Figure 1 Tournament games between AlphaGo Zero (20 blocks, 3 days) versus AlphaGo Lee using 2 h time controls.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig7_ESM.jpg?"/>
            <img alt="extended data figure 7" aria-describedby="rc-Fig7" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig7_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig7">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/7" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig8">
             Extended Data Figure 2 Frequency of occurence over time during training, for each
             <i>
              joseki
             </i>
             from Fig. 5a (corner sequences common in professional play that were discovered by AlphaGo Zero).
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig8_ESM.jpg?"/>
            <img alt="extended data figure 8" aria-describedby="rc-Fig8" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig8_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig8">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/8" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig9">
             Extended Data Figure 3 Frequency of occurence over time during training, for each
             <i>
              joseki
             </i>
             from Fig. 5b (corner sequences that AlphaGo Zero favoured for at least one iteration), and one additional variation.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig9_ESM.jpg?"/>
            <img alt="extended data figure 9" aria-describedby="rc-Fig9" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig9_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig9">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/9" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig10">
             Extended Data Figure 4 AlphaGo Zero (20 blocks) self-play games.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig10_ESM.jpg?"/>
            <img alt="extended data figure 10" aria-describedby="rc-Fig10" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig10_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig10">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/10" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig11">
             Extended Data Figure 5 AlphaGo Zero (40 blocks) self-play games.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig11_ESM.jpg?"/>
            <img alt="extended data figure 11" aria-describedby="rc-Fig11" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig11_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig11">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/11" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig12">
             Extended Data Figure 6 AlphaGo Zero (40 blocks, 40 days) versus AlphaGo Master tournament games using 2 h time controls.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig12_ESM.jpg?"/>
            <img alt="extended data figure 12" aria-describedby="rc-Fig12" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature24270/MediaObjects/41586_2017_Article_BFnature24270_Fig12_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig12">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature24270/figures/12" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
        </ul>
       </div>
      </div>
      <div aria-labelledby="tab-references" class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references" role="tabpanel">
       <div class="c-reading-companion__scroll-pane">
        <ol class="c-reading-companion__references-list c-reading-companion__references-list--numeric">
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR1">
           Friedman, J., Hastie, T. &amp; Tibshirani, R.
           <i>
            The Elements of Statistical Learning: Data Mining, Inference, and Prediction
           </i>
           (Springer, 2009)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR2">
           LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning.
           <i>
            Nature
           </i>
           <b>
            521
           </b>
           , 436–444 (2015)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nature14539" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature14539">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BC2MXht1WlurzP">
            CAS
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2015Natur.521..436L">
            ADS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning&amp;journal=Nature&amp;doi=10.1038%2Fnature14539&amp;volume=521&amp;pages=436-444&amp;publication_year=2015&amp;author=LeCun%2CY&amp;author=Bengio%2CY&amp;author=Hinton%2CG">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR3">
           Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. In
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           Vol. 25 (eds Pereira, F., Burges, C. J. C., Bottou, L. &amp; Weinberger, K. Q. ) 1097–1105 (2012)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR4">
           He, K., Zhang, X., Ren, S . &amp; Sun, J. Deep residual learning for image recognition. In
           <i>
            Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit.
           </i>
           770–778 (2016)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR5">
           Hayes-Roth, F., Waterman, D. &amp; Lenat, D.
           <i>
            Building Expert Systems
           </i>
           (Addison-Wesley, 1984)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR6">
           Mnih, V. et al. Human-level control through deep reinforcement learning.
           <i>
            Nature
           </i>
           <b>
            518
           </b>
           , 529–533 (2015)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nature14236" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature14236">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BC2MXjsVagur0%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2015Natur.518..529M">
            ADS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Human-level%20control%20through%20deep%20reinforcement%20learning&amp;journal=Nature&amp;doi=10.1038%2Fnature14236&amp;volume=518&amp;pages=529-533&amp;publication_year=2015&amp;author=Mnih%2CV">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR7">
           Guo, X., Singh, S. P., Lee, H., Lewis, R. L. &amp; Wang, X. Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning. In
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           Vol. 27 (eds Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. D. &amp; Weinberger, K. Q. ) 3338–3346 (2014)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR8">
           Mnih, V . et al. Asynchronous methods for deep reinforcement learning. In
           <i>
            Proc. 33rd Int. Conf. Mach. Learn.
           </i>
           Vol. 48 (eds Balcan, M. F. &amp; Weinberger, K. Q. ) 1928–1937 (2016)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR9">
           Jaderberg, M . et al. Reinforcement learning with unsupervised auxiliary tasks. In
           <i>
            5th Int. Conf. Learn. Representations
           </i>
           (2017)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR10">
           Dosovitskiy, A. &amp; Koltun, V. Learning to act by predicting the future. In
           <i>
            5th Int. Conf. Learn. Representations
           </i>
           (2017)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR11">
           Man´dziuk, J. in
           <i>
            Challenges for Computational Intelligence
           </i>
           ( Duch, W. &amp; Man´dziuk, J. ) 407–442 (Springer, 2007)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR12">
           Silver, D. et al. Mastering the game of Go with deep neural networks and tree search.
           <i>
            Nature
           </i>
           <b>
            529
           </b>
           , 484–489 (2016)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nature16961" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature16961">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12is7w%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016Natur.529..484S">
            ADS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Mastering%20the%20game%20of%20Go%20with%20deep%20neural%20networks%20and%20tree%20search&amp;journal=Nature&amp;doi=10.1038%2Fnature16961&amp;volume=529&amp;pages=484-489&amp;publication_year=2016&amp;author=Silver%2CD">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR13">
           Coulom, R. Efficient selectivity and backup operators in Monte-Carlo tree search. In
           <i>
            5th Int. Conf. Computers and Games
           </i>
           (eds Ciancarini, P. &amp; van den Herik, H. J. ) 72–83 (2006)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR14">
           Kocsis, L. &amp; Szepesvári, C. Bandit based Monte-Carlo planning. In
           <i>
            15th Eu. Conf. Mach. Learn.
           </i>
           282–293 (2006)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR15">
           Browne, C. et al. A survey of Monte Carlo tree search methods. IEEE Trans.
           <i>
            Comput. Intell. AI Games
           </i>
           <b>
            4
           </b>
           , 1–49 (2012)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1109/TCIAIG.2012.2186810" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTCIAIG.2012.2186810">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20of%20Monte%20Carlo%20tree%20search%20methods.%20IEEE%20Trans&amp;journal=Comput.%20Intell.%20AI%20Games&amp;doi=10.1109%2FTCIAIG.2012.2186810&amp;volume=4&amp;pages=1-49&amp;publication_year=2012&amp;author=Browne%2CC">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR16">
           Fukushima, K. Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.
           <i>
            Biol. Cybern.
           </i>
           <b>
            36
           </b>
           , 193–202 (1980)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/BF00344251" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2FBF00344251">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:STN:280:DyaL3c7nsFKntw%3D%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocognitron%3A%20a%20self%20organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern%20recognition%20unaffected%20by%20shift%20in%20position&amp;journal=Biol.%20Cybern.&amp;doi=10.1007%2FBF00344251&amp;volume=36&amp;pages=193-202&amp;publication_year=1980&amp;author=Fukushima%2CK">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR17">
           LeCun, Y. &amp; Bengio, Y. in
           <i>
            The Handbook of Brain Theory and Neural Networks
           </i>
           Ch. 3 (ed. Arbib, M. ) 276–278 (MIT Press, 1995)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR18">
           Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In
           <i>
            Proc. 32nd Int. Conf. Mach. Learn.
           </i>
           Vol. 37 448–456 (2015)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR19">
           Hahnloser, R. H. R., Sarpeshkar, R., Mahowald, M. A., Douglas, R. J. &amp; Seung, H. S. Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit.
           <i>
            Nature
           </i>
           <b>
            405
           </b>
           , 947–951 (2000)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/35016072" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F35016072">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BD3cXks1WltrY%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2000Natur.405..947H">
            ADS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Digital%20selection%20and%20analogue%20amplification%20coexist%20in%20a%20cortex-inspired%20silicon%20circuit&amp;journal=Nature&amp;doi=10.1038%2F35016072&amp;volume=405&amp;pages=947-951&amp;publication_year=2000&amp;author=Hahnloser%2CRHR&amp;author=Sarpeshkar%2CR&amp;author=Mahowald%2CMA&amp;author=Douglas%2CRJ&amp;author=Seung%2CHS">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR20">
           Howard, R.
           <i>
            Dynamic Programming and Markov Processes
           </i>
           (MIT Press, 1960)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR21">
           Sutton, R . &amp; Barto, A.
           <i>
            Reinforcement Learning: an Introduction
           </i>
           (MIT Press, 1998)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR22">
           Bertsekas, D. P. Approximate policy iteration: a survey and some new methods.
           <i>
            J. Control Theory Appl.
           </i>
           <b>
            9
           </b>
           , 310–335 (2011)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/s11768-011-1005-3" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs11768-011-1005-3">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2833999">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Approximate%20policy%20iteration%3A%20a%20survey%20and%20some%20new%20methods&amp;journal=J.%20Control%20Theory%20Appl.&amp;doi=10.1007%2Fs11768-011-1005-3&amp;volume=9&amp;pages=310-335&amp;publication_year=2011&amp;author=Bertsekas%2CDP">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR23">
           Scherrer, B. Approximate policy iteration schemes: a comparison. In
           <i>
            Proc. 31st Int. Conf. Mach. Learn.
           </i>
           Vol. 32 1314–1322 (2014)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR24">
           Rosin, C. D. Multi-armed bandits with episode context.
           <i>
            Ann. Math. Artif. Intell.
           </i>
           <b>
            61
           </b>
           , 203–230 (2011)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/s10472-011-9258-6" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs10472-011-9258-6">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2865077">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-armed%20bandits%20with%20episode%20context&amp;journal=Ann.%20Math.%20Artif.%20Intell.&amp;doi=10.1007%2Fs10472-011-9258-6&amp;volume=61&amp;pages=203-230&amp;publication_year=2011&amp;author=Rosin%2CCD">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR25">
           Coulom, R. Whole-history rating: a Bayesian rating system for players of time-varying strength. In
           <i>
            Int. Conf. Comput. Games
           </i>
           (eds van den Herik, H. J., Xu, X . Ma, Z . &amp; Winands, M. H. M. ) Vol. 5131 113–124 (Springer, 2008)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR26">
           Laurent, G. J., Matignon, L. &amp; Le Fort-Piat, N. The world of independent learners is not Markovian.
           <i>
            Int. J. Knowledge-Based Intelligent Engineering Systems
           </i>
           <b>
            15
           </b>
           , 55–64 (2011)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.3233/KES-2010-0206" href="https://doi-org.proxy.lib.ohio-state.edu/10.3233%2FKES-2010-0206">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20world%20of%20independent%20learners%20is%20not%20Markovian&amp;journal=Int.%20J.%20Knowledge-Based%20Intelligent%20Engineering%20Systems&amp;doi=10.3233%2FKES-2010-0206&amp;volume=15&amp;pages=55-64&amp;publication_year=2011&amp;author=Laurent%2CGJ&amp;author=Matignon%2CL&amp;author=Le%20Fort-Piat%2CN">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR27">
           Foerster, J. N . et al. Stabilising experience replay for deep multi-agent reinforcement learning. In
           <i>
            Proc. 34th Int. Conf. Mach. Learn.
           </i>
           Vol. 70 1146–1155 (2017)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR28">
           Heinrich, J . &amp; Silver, D. Deep reinforcement learning from self-play in imperfect-information games. In
           <i>
            NIPS Deep Reinforcement Learning Workshop
           </i>
           (2016)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR29">
           Jouppi, N. P . et al. In-datacenter performance analysis of a Tensor Processing Unit.
           <i>
            Proc. 44th Annu. Int. Symp. Comp. Architecture
           </i>
           Vol. 17 1–12 (2017)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR30">
           Maddison, C. J., Huang, A., Sutskever, I . &amp; Silver, D. Move evaluation in Go using deep convolutional neural networks. In
           <i>
            3rd Int. Conf. Learn. Representations.
           </i>
           (2015)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR31">
           Clark, C . &amp; Storkey, A. J. Training deep convolutional neural networks to play Go. In
           <i>
            Proc. 32nd Int. Conf. Mach. Learn.
           </i>
           Vol. 37 1766–1774 (2015)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR32">
           Tian, Y. &amp; Zhu, Y. Better computer Go player with neural network and long-term prediction. In
           <i>
            4th Int. Conf. Learn. Representations
           </i>
           (2016)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR33">
           Cazenave, T. Residual networks for computer Go. IEEE Trans. Comput. Intell. AI Games
           <a data-track="click" data-track-action="external reference" data-track-label="10.1109/TCIAIG.2017.2681042" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042">
            https://doi-org.proxy.lib.ohio-state.edu/10.1109/TCIAIG.2017.2681042
           </a>
           (2017)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR34">
           Huang, A. AlphaGo master online series of games.
           <a data-track="click" data-track-action="external reference" data-track-label="https://deepmind.com/research/AlphaGo/match-archive/master" href="https://deepmind.com/research/AlphaGo/match-archive/master">
            https://deepmind.com/research/AlphaGo/match-archive/master
           </a>
           (2017)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR35">
           Barto, A. G. &amp; Duff, M. Monte Carlo matrix inversion and reinforcement learning.
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           <b>
            6
           </b>
           , 687–694 (1994)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Monte%20Carlo%20matrix%20inversion%20and%20reinforcement%20learning&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=6&amp;pages=687-694&amp;publication_year=1994&amp;author=Barto%2CAG&amp;author=Duff%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR36">
           Singh, S. P. &amp; Sutton, R. S. Reinforcement learning with replacing eligibility traces.
           <i>
            Mach. Learn.
           </i>
           <b>
            22
           </b>
           , 123–158 (1996)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1099.68700">
            MATH
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20with%20replacing%20eligibility%20traces&amp;journal=Mach.%20Learn.&amp;volume=22&amp;pages=123-158&amp;publication_year=1996&amp;author=Singh%2CSP&amp;author=Sutton%2CRS">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR37">
           Lagoudakis, M. G. &amp; Parr, R. Reinforcement learning as classification: leveraging modern classifiers.
           <i>
            In Proc. 20th Int. Conf. Mach. Learn.
           </i>
           424–431 (2003)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR38">
           Scherrer, B., Ghavamzadeh, M., Gabillon, V., Lesner, B. &amp; Geist, M. Approximate modified policy iteration and its application to the game of Tetris.
           <i>
            J. Mach. Learn. Res.
           </i>
           <b>
            16
           </b>
           , 1629–1676 (2015)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=3417794">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1351.90162">
            MATH
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Approximate%20modified%20policy%20iteration%20and%20its%20application%20to%20the%20game%20of%20Tetris&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=16&amp;pages=1629-1676&amp;publication_year=2015&amp;author=Scherrer%2CB&amp;author=Ghavamzadeh%2CM&amp;author=Gabillon%2CV&amp;author=Lesner%2CB&amp;author=Geist%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR39">
           Littman, M. L. Markov games as a framework for multi-agent reinforcement learning.
           <i>
            In Proc. 11th Int. Conf. Mach. Learn.
           </i>
           157–163 (1994)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR40">
           Enzenberger, M. The integration of a priori knowledge into a Go playing neural network.
           <a data-track="click" data-track-action="external reference" data-track-label="http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html" href="http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html">
            http://www.cgl.ucsf.edu/go/Programs/neurogo-html/neurogo.html
           </a>
           (1996)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR41">
           Enzenberger, M. in
           <i>
            Advances in Computer Games
           </i>
           (eds Van Den Herik, H. J., Iida, H. &amp; Heinz, E. A. ) 97–108 (2003)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR42">
           Sutton, R. Learning to predict by the method of temporal differences.
           <i>
            Mach. Learn.
           </i>
           <b>
            3
           </b>
           , 9–44 (1988)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20to%20predict%20by%20the%20method%20of%20temporal%20differences&amp;journal=Mach.%20Learn.&amp;volume=3&amp;pages=9-44&amp;publication_year=1988&amp;author=Sutton%2CR">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR43">
           Schraudolph, N. N., Dayan, P. &amp; Sejnowski, T. J. Temporal difference learning of position evaluation in the game of Go.
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           <b>
            6
           </b>
           , 817–824 (1994)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20difference%20learning%20of%20position%20evaluation%20in%20the%20game%20of%20Go&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=6&amp;pages=817-824&amp;publication_year=1994&amp;author=Schraudolph%2CNN&amp;author=Dayan%2CP&amp;author=Sejnowski%2CTJ">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR44">
           Silver, D., Sutton, R. &amp; Müller, M. Temporal-difference search in computer Go.
           <i>
            Mach. Learn.
           </i>
           <b>
            87
           </b>
           , 183–219 (2012)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/s10994-012-5280-0" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs10994-012-5280-0">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2914011">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal-difference%20search%20in%20computer%20Go&amp;journal=Mach.%20Learn.&amp;doi=10.1007%2Fs10994-012-5280-0&amp;volume=87&amp;pages=183-219&amp;publication_year=2012&amp;author=Silver%2CD&amp;author=Sutton%2CR&amp;author=M%C3%BCller%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR45">
           Silver, D.
           <i>
            Reinforcement Learning and Simulation-Based Search in Computer Go
           </i>
           . PhD thesis, Univ. Alberta, Edmonton, Canada (2009)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR46">
           Gelly, S. &amp; Silver, D. Monte-Carlo tree search and rapid action value estimation in computer Go.
           <i>
            Artif. Intell.
           </i>
           <b>
            175
           </b>
           , 1856–1875 (2011)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1016/j.artint.2011.03.007" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2Fj.artint.2011.03.007">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2847683">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Monte-Carlo%20tree%20search%20and%20rapid%20action%20value%20estimation%20in%20computer%20Go&amp;journal=Artif.%20Intell.&amp;doi=10.1016%2Fj.artint.2011.03.007&amp;volume=175&amp;pages=1856-1875&amp;publication_year=2011&amp;author=Gelly%2CS&amp;author=Silver%2CD">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR47">
           Coulom, R. Computing Elo ratings of move patterns in the game of Go.
           <i>
            Int. Comput. Games Assoc. J.
           </i>
           <b>
            30
           </b>
           , 198–208 (2007)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computing%20Elo%20ratings%20of%20move%20patterns%20in%20the%20game%20of%20Go&amp;journal=Int.%20Comput.%20Games%20Assoc.%20J.&amp;volume=30&amp;pages=198-208&amp;publication_year=2007&amp;author=Coulom%2CR">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR48">
           Gelly, S., Wang, Y., Munos, R. &amp; Teytaud, O. Modification of UCT with patterns in Monte-Carlo Go. Report No. 6062 (INRIA, 2006)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR49">
           Baxter, J., Tridgell, A. &amp; Weaver, L. Learning to play chess using temporal differences.
           <i>
            Mach. Learn.
           </i>
           <b>
            40
           </b>
           , 243–263 (2000)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1007634325138" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1007634325138">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20to%20play%20chess%20using%20temporal%20differences&amp;journal=Mach.%20Learn.&amp;doi=10.1023%2FA%3A1007634325138&amp;volume=40&amp;pages=243-263&amp;publication_year=2000&amp;author=Baxter%2CJ&amp;author=Tridgell%2CA&amp;author=Weaver%2CL">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR50">
           Veness, J., Silver, D., Blair, A. &amp; Uther, W. Bootstrapping from game tree search. In
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           1937–1945 (2009)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR51">
           Lai, M.
           <i>
            Giraffe: Using Deep Reinforcement Learning to Play Chess
           </i>
           . MSc thesis, Imperial College London (2015)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR52">
           Schaeffer, J., Hlynka, M . &amp; Jussila, V. Temporal difference learning applied to a high-performance game-playing program. In
           <i>
            Proc. 17th Int. Jt Conf. Artif. Intell.
           </i>
           Vol. 1 529–534 (2001)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR53">
           Tesauro, G. TD-gammon, a self-teaching backgammon program, achieves master-level play.
           <i>
            Neural Comput.
           </i>
           <b>
            6
           </b>
           , 215–219 (1994)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1162/neco.1994.6.2.215" href="https://doi-org.proxy.lib.ohio-state.edu/10.1162%2Fneco.1994.6.2.215">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=TD-gammon%2C%20a%20self-teaching%20backgammon%20program%2C%20achieves%20master-level%20play&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.1994.6.2.215&amp;volume=6&amp;pages=215-219&amp;publication_year=1994&amp;author=Tesauro%2CG">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR54">
           Buro, M. From simple features to sophisticated evaluation functions. In
           <i>
            Proc. 1st Int. Conf. Comput. Games
           </i>
           126–145 (1999)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR55">
           Sheppard, B. World-championship-caliber Scrabble.
           <i>
            Artif. Intell.
           </i>
           <b>
            134
           </b>
           , 241–275 (2002)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1016/S0004-3702(01)00166-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0004-3702%2801%2900166-7">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=World-championship-caliber%20Scrabble&amp;journal=Artif.%20Intell.&amp;doi=10.1016%2FS0004-3702%2801%2900166-7&amp;volume=134&amp;pages=241-275&amp;publication_year=2002&amp;author=Sheppard%2CB">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR56">
           Moravcˇík, M. et al. DeepStack: expert-level artificial intelligence in heads-up no-limit poker.
           <i>
            Science
           </i>
           <b>
            356
           </b>
           , 508–513 (2017)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1126/science.aam6960" href="https://doi-org.proxy.lib.ohio-state.edu/10.1126%2Fscience.aam6960">
            Article
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2017Sci...356..508M">
            ADS
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=3676953">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=DeepStack%3A%20expert-level%20artificial%20intelligence%20in%20heads-up%20no-limit%20poker&amp;journal=Science&amp;doi=10.1126%2Fscience.aam6960&amp;volume=356&amp;pages=508-513&amp;publication_year=2017&amp;author=Moravc%CB%87%C3%ADk%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR57">
           Tesauro, G &amp; Galperin, G. On-line policy improvement using Monte-Carlo search. In
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           1068–1074 (1996)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR58">
           Tesauro, G. Neurogammon: a neural-network backgammon program. In
           <i>
            Proc. Int. Jt Conf. Neural Netw.
           </i>
           Vol. 3, 33–39 (1990)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR59">
           Samuel, A. L. Some studies in machine learning using the game of checkers II - recent progress.
           <i>
            IBM J. Res. Develop.
           </i>
           <b>
            11
           </b>
           , 601–617 (1967)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1147/rd.116.0601" href="https://doi-org.proxy.lib.ohio-state.edu/10.1147%2Frd.116.0601">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Some%20studies%20in%20machine%20learning%20using%20the%20game%20of%20checkers%20II%20-%20recent%20progress&amp;journal=IBM%20J.%20Res.%20Develop.&amp;doi=10.1147%2Frd.116.0601&amp;volume=11&amp;pages=601-617&amp;publication_year=1967&amp;author=Samuel%2CAL">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR60">
           Kober, J., Bagnell, J. A. &amp; Peters, J. Reinforcement learning in robotics: a survey.
           <i>
            Int. J. Robot. Res.
           </i>
           <b>
            32
           </b>
           , 1238–1274 (2013)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1177/0278364913495721" href="https://doi-org.proxy.lib.ohio-state.edu/10.1177%2F0278364913495721">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20in%20robotics%3A%20a%20survey&amp;journal=Int.%20J.%20Robot.%20Res.&amp;doi=10.1177%2F0278364913495721&amp;volume=32&amp;pages=1238-1274&amp;publication_year=2013&amp;author=Kober%2CJ&amp;author=Bagnell%2CJA&amp;author=Peters%2CJ">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR61">
           Zhang, W. &amp; Dietterich, T. G. A reinforcement learning approach to job-shop scheduling.
           <i>
            In Proc. 14th Int. Jt Conf. Artif. Intell.
           </i>
           1114–1120 (1995)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR62">
           Cazenave, T., Balbo, F. &amp; Pinson, S. Using a Monte-Carlo approach for bus regulation. In
           <i>
            Int. IEEE Conf. Intell. Transport. Syst.
           </i>
           1–6 (2009)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR63">
           Evans, R. &amp; Gao, J. Deepmind AI reduces Google data centre cooling bill by 40%.
           <a data-track="click" data-track-action="external reference" data-track-label="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/" href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/">
            https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/
           </a>
           (2016)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR64">
           Abe, N . et al. Empirical comparison of various reinforcement learning strategies for sequential targeted marketing. In
           <i>
            IEEE Int. Conf. Data Mining
           </i>
           3–10 (2002)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR65">
           Silver, D., Newnham, L., Barker, D., Weller, S. &amp; McFall, J. Concurrent reinforcement learning from customer interactions. In
           <i>
            Proc. 30th Int. Conf. Mach. Learn.
           </i>
           Vol. 28 924–932 (2013)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR66">
           Tromp, J. Tromp–Taylor rules.
           <a data-track="click" data-track-action="external reference" data-track-label="http://tromp.github.io/go.html" href="http://tromp.github.io/go.html">
            http://tromp.github.io/go.html
           </a>
           (1995)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR67">
           Müller, M. Computer Go.
           <i>
            Artif. Intell.
           </i>
           <b>
            134
           </b>
           , 145–179 (2002)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1016/S0004-3702(01)00121-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0004-3702%2801%2900121-7">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer%20Go&amp;journal=Artif.%20Intell.&amp;doi=10.1016%2FS0004-3702%2801%2900121-7&amp;volume=134&amp;pages=145-179&amp;publication_year=2002&amp;author=M%C3%BCller%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR68">
           Shahriari, B., Swersky, K., Wang, Z., Adams, R. P. &amp; de Freitas, N. Taking the human out of the loop: a review of Bayesian optimization.
           <i>
            Proc. IEEE
           </i>
           <b>
            104
           </b>
           , 148–175 (2016)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1109/JPROC.2015.2494218" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FJPROC.2015.2494218">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Taking%20the%20human%20out%20of%20the%20loop%3A%20a%20review%20of%20Bayesian%20optimization&amp;journal=Proc.%20IEEE&amp;doi=10.1109%2FJPROC.2015.2494218&amp;volume=104&amp;pages=148-175&amp;publication_year=2016&amp;author=Shahriari%2CB&amp;author=Swersky%2CK&amp;author=Wang%2CZ&amp;author=Adams%2CRP&amp;author=de%20Freitas%2CN">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR69">
           Segal, R. B. On the scalability of parallel UCT.
           <i>
            Comput. Games
           </i>
           <b>
            6515
           </b>
           , 36–47 (2011)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/978-3-642-17928-0_4" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2F978-3-642-17928-0_4">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2803987">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20scalability%20of%20parallel%20UCT&amp;journal=Comput.%20Games&amp;doi=10.1007%2F978-3-642-17928-0_4&amp;volume=6515&amp;pages=36-47&amp;publication_year=2011&amp;author=Segal%2CRB">
            Google Scholar
           </a>
          </p>
         </li>
        </ol>
       </div>
      </div>
     </div>
    </div>
   </aside>
  </div>
  <footer class="composite-layer" itemscope="" itemtype="http://schema.org/Periodical">
   <meta content="Springer Nature" itemprop="publisher"/>
   <div class="u-mt-16 u-mb-16">
    <div class="u-container">
     <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
      <p class="c-meta u-ma-0 u-flex-shrink">
       <span class="c-meta__item">
        Nature (
        <i>
         Nature
        </i>
        )
       </span>
       <span class="c-meta__item">
        <abbr title="International Standard Serial Number">
         ISSN
        </abbr>
        <span itemprop="onlineIssn">
         1476-4687
        </span>
        (online)
       </span>
       <span class="c-meta__item">
        <abbr title="International Standard Serial Number">
         ISSN
        </abbr>
        <span itemprop="printIssn">
         0028-0836
        </span>
        (print)
       </span>
      </p>
     </div>
    </div>
   </div>
   <div class="c-footer">
    <div class="u-hide-print" data-track-component="footer">
     <h2 class="u-visually-hidden">
      nature.com sitemap
     </h2>
     <div class="c-footer__container">
      <div class="c-footer__grid c-footer__group--separator">
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         About Nature Portfolio
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="about us" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/npg_/company_info/index.html">
           About us
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="press releases" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/npg_/press_room/press_releases.html">
           Press releases
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="press office" data-track-label="link" href="https://press-nature-com.proxy.lib.ohio-state.edu/">
           Press office
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="contact us" data-track-label="link" href="https://support-nature-com.proxy.lib.ohio-state.edu/support/home">
           Contact us
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Discover content
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="journals a-z" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/siteindex">
           Journals A-Z
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="article by subject" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/subjects/">
           Articles by subject
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nano" data-track-label="link" href="https://nano-nature-com.proxy.lib.ohio-state.edu/">
           Nano
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="protocol exchange" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/protocolexchange/">
           Protocol Exchange
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature index" data-track-label="link" href="https://www.natureindex.com/">
           Nature Index
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Publishing policies
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Nature portfolio policies" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/authors/editorial_policies/">
           Nature portfolio policies
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="open access" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nature-research/open-access">
           Open access
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Author &amp; Researcher services
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="reprints and permissions" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/reprints/">
           Reprints &amp; permissions
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="data research service" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/authors/research-data">
           Research data
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="language editing" data-track-label="link" href="https://authorservices-springernature-com.proxy.lib.ohio-state.edu/language-editing/">
           Language editing
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="scientific editing" data-track-label="link" href="https://authorservices-springernature-com.proxy.lib.ohio-state.edu/scientific-editing/">
           Scientific editing
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature masterclasses" data-track-label="link" href="https://masterclasses-nature-com.proxy.lib.ohio-state.edu/">
           Nature Masterclasses
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="live expert trainer-led workshops" data-track-label="link" href="https://masterclasses-nature-com.proxy.lib.ohio-state.edu/live-expert-trainer-led/23649702">
           Live Expert Trainer-led workshops
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="research solutions" data-track-label="link" href="https://solutions-springernature-com.proxy.lib.ohio-state.edu/">
           Research Solutions
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Libraries &amp; institutions
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="librarian service and tools" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians/tools-services">
           Librarian service &amp; tools
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="librarian portal" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians/manage-your-account/librarianportal">
           Librarian portal
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="open research" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/openresearch/about-open-access/information-for-institutions/">
           Open research
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Recommend to library" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians/recommend-to-your-library">
           Recommend to library
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Advertising &amp; partnerships
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="advertising" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/product/digital-advertising/">
           Advertising
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="partnerships and services" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/">
           Partnerships &amp; Services
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="media kits" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/media-kits/">
           Media kits
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track-action="branded content" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/product/branded-content-native-advertising/">
           Branded
                        content
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Career development
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature careers" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/naturecareers">
           Nature Careers
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature conferences" data-track-label="link" href="https://conferences-nature-com.proxy.lib.ohio-state.edu">
           Nature
           <span class="u-visually-hidden">
           </span>
           Conferences
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature events" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/natureevents/">
           Nature
           <span class="u-visually-hidden">
           </span>
           events
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Regional websites
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature africa" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/natafrica">
           Nature Africa
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature china" data-track-label="link" href="http://www.naturechina.com">
           Nature China
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature india" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nindia">
           Nature India
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature Italy" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/natitaly">
           Nature Italy
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature japan" data-track-label="link" href="https://www-natureasia-com.proxy.lib.ohio-state.edu/ja-jp/">
           Nature Japan
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature korea" data-track-label="link" href="https://www-natureasia-com.proxy.lib.ohio-state.edu/ko-kr/">
           Nature Korea
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature middle east" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nmiddleeast/">
           Nature Middle East
          </a>
         </li>
        </ul>
       </div>
      </div>
     </div>
     <div class="c-footer__container">
      <ul class="c-footer__links">
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="privacy policy" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/privacy">
         Privacy
                Policy
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="use of cookies" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/cookies">
         Use
                of cookies
        </a>
       </li>
       <li class="c-footer__item">
        <button class="optanon-toggle-display c-footer__link" data-cc-action="preferences" data-track="click" data-track-action="manage cookies" data-track-label="link" onclick="javascript:;">
         Your privacy choices/Manage cookies
        </button>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="legal notice" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/legal-notice">
         Legal
                notice
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="accessibility statement" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/accessibility-statement">
         Accessibility
                statement
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="terms and conditions" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/terms-and-conditions">
         Terms &amp; Conditions
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="california privacy statement" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/ccpa">
         Your US state privacy rights
        </a>
       </li>
      </ul>
     </div>
    </div>
    <div class="c-footer__container">
     <a class="c-footer__link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/">
      <img alt="Springer Nature" height="20" loading="lazy" src="/static/images/logos/sn-logo-white-ea63208b81.svg" width="200"/>
     </a>
     <p class="c-footer__legal" data-test="copyright">
      © 2023 Springer Nature Limited
     </p>
    </div>
   </div>
   <div aria-hidden="true" class="u-visually-hidden">
    <!--?xml version="1.0" encoding="UTF-8"?-->
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
     <defs>
      <path d="M0 .74h56.72v55.24H0z" id="a">
      </path>
     </defs>
     <symbol id="icon-access" viewbox="0 0 18 18">
      <path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-account" viewbox="0 0 18 18">
      <path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-alert" viewbox="0 0 18 18">
      <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-broad" viewbox="0 0 16 16">
      <path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)">
      </path>
     </symbol>
     <symbol id="icon-arrow-down" viewbox="0 0 16 16">
      <path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-left" viewbox="0 0 16 16">
      <path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-right" viewbox="0 0 16 16">
      <path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-sub" viewbox="0 0 16 16">
      <path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-up" viewbox="0 0 16 16">
      <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-article" viewbox="0 0 18 18">
      <path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-audio" viewbox="0 0 18 18">
      <path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-block" viewbox="0 0 24 24">
      <path d="m0 0h24v24h-24z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-book" viewbox="0 0 18 18">
      <path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-broad" viewbox="0 0 24 24">
      <path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)">
      </path>
     </symbol>
     <symbol id="icon-calendar" viewbox="0 0 18 18">
      <path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-cart" viewbox="0 0 18 18">
      <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z">
      </path>
     </symbol>
     <symbol id="icon-chevron-less" viewbox="0 0 10 10">
      <path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)">
      </path>
     </symbol>
     <symbol id="icon-chevron-more" viewbox="0 0 10 10">
      <path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)">
      </path>
     </symbol>
     <symbol id="icon-chevron-right" viewbox="0 0 10 10">
      <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
      </path>
     </symbol>
     <symbol id="icon-circle-fill" viewbox="0 0 16 16">
      <path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-circle" viewbox="0 0 16 16">
      <path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-citation" viewbox="0 0 18 18">
      <path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-close" viewbox="0 0 16 16">
      <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-collections" viewbox="0 0 18 18">
      <path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-compare" viewbox="0 0 18 18">
      <path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-download-file" viewbox="0 0 18 18">
      <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-download" viewbox="0 0 16 16">
      <path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-editors" viewbox="0 0 18 18">
      <path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-email" viewbox="0 0 18 18">
      <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-error" viewbox="0 0 18 18">
      <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-ethics" viewbox="0 0 18 18">
      <path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-expand">
      <path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-explore" viewbox="0 0 18 18">
      <path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-filter" viewbox="0 0 16 16">
      <path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z">
      </path>
     </symbol>
     <symbol id="icon-home" viewbox="0 0 18 18">
      <path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-image" viewbox="0 0 18 18">
      <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-info" viewbox="0 0 18 18">
      <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-institution" viewbox="0 0 18 18">
      <path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-location" viewbox="0 0 18 18">
      <path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-minus" viewbox="0 0 16 16">
      <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-newsletter" viewbox="0 0 18 18">
      <path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-orcid" viewbox="0 0 18 18">
      <path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-plus" viewbox="0 0 16 16">
      <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-print" viewbox="0 0 18 18">
      <path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-search" viewbox="0 0 22 22">
      <path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-social-facebook" viewbox="0 0 24 24">
      <path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-social-twitter" viewbox="0 0 24 24">
      <path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-social-youtube" viewbox="0 0 24 24">
      <path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-subject-medicine" viewbox="0 0 18 18">
      <path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-success" viewbox="0 0 18 18">
      <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-table" viewbox="0 0 18 18">
      <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-tick-circle" viewbox="0 0 24 24">
      <path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-tick" viewbox="0 0 16 16">
      <path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-update" viewbox="0 0 18 18">
      <path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-upload" viewbox="0 0 18 18">
      <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-video" viewbox="0 0 18 18">
      <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-warning" viewbox="0 0 18 18">
      <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-altmetric">
      <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm-1.886 9.684-1.101 1.845a1 1 0 0 1-.728.479l-.13.008H3.056a9.001 9.001 0 0 0 17.886 0l-4.564-.001-2.779 4.156c-.454.68-1.467.55-1.758-.179l-.038-.113-1.69-6.195ZM12 3a9.001 9.001 0 0 0-8.947 8.016h4.533l2.017-3.375c.452-.757 1.592-.6 1.824.25l1.73 6.345 1.858-2.777a1 1 0 0 1 .707-.436l.124-.008h5.1A9.001 9.001 0 0 0 12 3Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-checklist-banner" viewbox="0 0 56.69 56.69">
      <path d="M0 0h56.69v56.69H0z" style="fill:none">
      </path>
      <clippath id="b">
       <use style="overflow:visible" xlink:href="#a">
       </use>
      </clippath>
      <path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round">
      </path>
      <path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round">
      </path>
     </symbol>
     <symbol id="icon-chevron-down" viewbox="0 0 16 16">
      <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)">
      </path>
     </symbol>
     <symbol id="icon-citations">
      <path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM5.483 14.35c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Zm5 0c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-eds-checklist" viewbox="0 0 32 32">
      <path d="M19.2 1.333a3.468 3.468 0 0 1 3.381 2.699L24.667 4C26.515 4 28 5.52 28 7.38v19.906c0 1.86-1.485 3.38-3.333 3.38H7.333c-1.848 0-3.333-1.52-3.333-3.38V7.38C4 5.52 5.485 4 7.333 4h2.093A3.468 3.468 0 0 1 12.8 1.333h6.4ZM9.426 6.667H7.333c-.36 0-.666.312-.666.713v19.906c0 .401.305.714.666.714h17.334c.36 0 .666-.313.666-.714V7.38c0-.4-.305-.713-.646-.714l-2.121.033A3.468 3.468 0 0 1 19.2 9.333h-6.4a3.468 3.468 0 0 1-3.374-2.666Zm12.715 5.606c.586.446.7 1.283.253 1.868l-7.111 9.334a1.333 1.333 0 0 1-1.792.306l-3.556-2.333a1.333 1.333 0 1 1 1.463-2.23l2.517 1.651 6.358-8.344a1.333 1.333 0 0 1 1.868-.252ZM19.2 4h-6.4a.8.8 0 0 0-.8.8v1.067a.8.8 0 0 0 .8.8h6.4a.8.8 0 0 0 .8-.8V4.8a.8.8 0 0 0-.8-.8Z">
      </path>
     </symbol>
     <symbol id="icon-eds-i-external-link-medium" viewbox="0 0 24 24">
      <path d="M9 2a1 1 0 1 1 0 2H4.6c-.371 0-.6.209-.6.5v15c0 .291.229.5.6.5h14.8c.371 0 .6-.209.6-.5V15a1 1 0 0 1 2 0v4.5c0 1.438-1.162 2.5-2.6 2.5H4.6C3.162 22 2 20.938 2 19.5v-15C2 3.062 3.162 2 4.6 2H9Zm6 0h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L22 3v6a1 1 0 0 1-2 0V5.414l-6.693 6.693a1 1 0 0 1-1.414-1.414L18.584 4H15a1 1 0 0 1-.993-.883L14 3a1 1 0 0 1 1-1Z">
      </path>
     </symbol>
     <symbol id="icon-eds-i-info-filled-medium" viewbox="0 0 24 24">
      <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 9h-1.5a1 1 0 0 0-1 1l.007.117A1 1 0 0 0 10.5 12h.5v4H9.5a1 1 0 0 0 0 2h5a1 1 0 0 0 0-2H13v-5a1 1 0 0 0-1-1Zm0-4.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 5.5Z">
      </path>
     </symbol>
     <symbol id="icon-eds-menu" viewbox="0 0 24 24">
      <path d="M21.09 5c.503 0 .91.448.91 1s-.407 1-.91 1H2.91C2.406 7 2 6.552 2 6s.407-1 .91-1h18.18Zm-3.817 6c.401 0 .727.448.727 1s-.326 1-.727 1H2.727C2.326 13 2 12.552 2 12s.326-1 .727-1h14.546Zm3.818 6c.502 0 .909.448.909 1s-.407 1-.91 1H2.91c-.503 0-.91-.448-.91-1s.407-1 .91-1h18.18Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-eds-search" viewbox="0 0 24 24">
      <path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-eds-small-arrow-right" viewbox="0 0 16 16">
      <g fill-rule="evenodd" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
       <path d="M2 8.092h12M8 2l6 6.092M8 14.127l6-6.035">
       </path>
      </g>
     </symbol>
     <symbol id="icon-eds-user-single" viewbox="0 0 24 24">
      <path d="M12 12c5.498 0 10 4.001 10 9a1 1 0 0 1-2 0c0-3.838-3.557-7-8-7s-8 3.162-8 7a1 1 0 0 1-2 0c0-4.999 4.502-9 10-9Zm0-11a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm0 2a3 3 0 1 1 0 6 3 3 0 0 1 0-6Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-email-new" viewbox="0 0 24 24">
      <path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z">
      </path>
     </symbol>
     <symbol id="icon-expand-image" viewbox="0 0 18 18">
      <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-github" viewbox="0 0 100 100">
      <path clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-mentions">
      <g fill-rule="evenodd" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
       <path d="M22 15.255A9.373 9.373 0 0 1 8.745 2L22 15.255ZM15.477 8.523l4.215-4.215">
       </path>
       <path d="m7 13-5 9h10l-1-5">
       </path>
      </g>
     </symbol>
     <symbol id="icon-metrics-accesses">
      <path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM7.708 13.308c2.004 0 3.969 1.198 5.802 2.995l.23.23a2.285 2.285 0 0 1 .009 3.233C11.853 21.693 9.799 23 7.707 23c-2.091 0-4.14-1.305-6.033-3.226a2.285 2.285 0 0 1-.007-3.233c1.9-1.93 3.949-3.233 6.04-3.233Zm0 2c-1.396 0-3.064 1.062-4.623 2.644a.285.285 0 0 0 .007.41C4.642 19.938 6.311 21 7.707 21c1.397 0 3.069-1.065 4.623-2.644a.285.285 0 0 0 0-.404l-.23-.229c-1.487-1.451-3.064-2.415-4.393-2.415Zm-.036 1.077a1.77 1.77 0 1 1 .126 3.537 1.77 1.77 0 0 1-.126-3.537Zm.072 1.538a.23.23 0 1 0-.017.461.23.23 0 0 0 .017-.46Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-metrics">
      <path d="M3 22a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v7h4V8a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v13a1 1 0 0 1-.883.993L21 22H3Zm17-2V9h-4v11h4Zm-6-8h-4v8h4v-8ZM8 4H4v16h4V4Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-springer-arrow-left">
      <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z">
      </path>
     </symbol>
     <symbol id="icon-springer-arrow-right">
      <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z">
      </path>
     </symbol>
     <symbol id="icon-submit-open" viewbox="0 0 16 17">
      <path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero">
      </path>
     </symbol>
    </svg>
   </div>
  </footer>
  <div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif" data-component-expirydays="30" data-component-id="nature-briefing-banner" data-component-trigger-scroll-percentage="15" data-track="in-view" data-track-action="in-view" data-track-category="nature briefing" data-track-label="Briefing banner visible: Flagship">
   <div class="c-site-messages__banner-large">
    <div class="c-site-messages__close-container">
     <button class="c-site-messages__close" data-track="click" data-track-category="nature briefing" data-track-label="Briefing banner dismiss: Flagship">
      <svg aria-hidden="true" focusable="false" height="25px" version="1.1" viewbox="0 0 25 25" width="25px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
       <title>
        Close banner
       </title>
       <defs>
       </defs>
       <g fill="none" fill-rule="evenodd" stroke="none" stroke-width="1">
        <rect height="25" opacity="0" width="25" x="0" y="0">
        </rect>
        <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff">
        </path>
       </g>
      </svg>
      <span class="visually-hidden">
       Close
      </span>
     </button>
    </div>
    <div class="c-site-messages__form-container">
     <div class="grid grid-12 last">
      <div class="grid grid-4">
       <img alt="Nature Briefing" height="40" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250"/>
       <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">
        Sign up for the
        <em>
         Nature Briefing
        </em>
        newsletter — what matters in science, free to your inbox daily.
       </p>
      </div>
      <div class="grid grid-8 last">
       <form action="https://briefer.public.springernature.app/" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship" method="post">
        <input id="briefing-banner-signup-form-input-track-originReferralPoint" name="track_originReferralPoint" type="hidden" value="MainBriefingBanner"/>
        <input id="briefing-banner-signup-form-input-track-formType" name="track_formType" type="hidden" value="DirectEmailBanner"/>
        <input id="gdpr_tick" name="gdpr_tick" type="hidden" value="false"/>
        <input id="marketing" name="marketing" type="hidden" value="false"/>
        <input id="marketing_tick" name="marketing_tick" type="hidden" value="false"/>
        <input id="brieferEntryPoint" name="brieferEntryPoint" type="hidden" value="MainBriefingBanner"/>
        <label class="nature-briefing-banner__email-label" for="emailAddress">
         Email address
        </label>
        <div class="nature-briefing-banner__email-wrapper">
         <input class="nature-briefing-banner__email-input box-sizing text14" data-test-element="briefing-emailbanner-email-input" id="emailAddress" name="emailAddress" placeholder="e.g. jo.smith@university.ac.uk" required="" type="email" value=""/>
         <input id="defaultNewsletter" name="N:nature_briefing_daily" type="hidden" value="true"/>
         <button class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button" type="submit">
          Sign up
         </button>
        </div>
        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
         <input class="nature-briefing-banner__checkbox-checkbox" data-test-element="briefing-emailbanner-gdpr-checkbox" id="gdpr-briefing-banner-checkbox" name="gdpr" required="" type="checkbox" value="true"/>
         <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">
          I agree my information will be processed in accordance with the
          <em>
           Nature
          </em>
          and Springer Nature Limited
          <a href="https://www-nature-com.proxy.lib.ohio-state.edu/info/privacy">
           Privacy Policy
          </a>
          .
         </label>
        </div>
       </form>
      </div>
     </div>
    </div>
   </div>
   <div class="c-site-messages__banner-small">
    <div class="c-site-messages__close-container">
     <button class="c-site-messages__close" data-track="click" data-track-category="nature briefing" data-track-label="Briefing banner dismiss: Flagship">
      <svg aria-hidden="true" focusable="false" height="25px" version="1.1" viewbox="0 0 25 25" width="25px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
       <title>
        Close banner
       </title>
       <defs>
       </defs>
       <g fill="none" fill-rule="evenodd" stroke="none" stroke-width="1">
        <rect height="25" opacity="0" width="25" x="0" y="0">
        </rect>
        <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff">
        </path>
       </g>
      </svg>
      <span class="visually-hidden">
       Close
      </span>
     </button>
    </div>
    <div class="c-site-messages__content text14">
     <span class="c-site-messages--nature-briefing__strapline strong">
      Get the most important science stories of the day, free in your inbox.
     </span>
     <a class="nature-briefing__link text14 sans-serif" data-test-element="briefing-banner-link" data-track="click" data-track-category="nature briefing" data-track-label="Small-screen banner CTA to site" href="https://www-nature-com.proxy.lib.ohio-state.edu/briefing/signup/?brieferEntryPoint=MainBriefingBanner" rel="noreferrer noopener" target="_blank">
      Sign up for Nature Briefing
     </a>
    </div>
   </div>
  </div>
  <noscript>
   <img alt="" height="0" hidden="" src="https://verify-nature-com.proxy.lib.ohio-state.edu/verify/nature.png" style="display: none" width="0"/>
  </noscript>
  <script async="" src="//content.readcube.com/ping?doi=10.1038/nature24270&amp;format=js&amp;last_modified=2017-10-19">
  </script>
  <img alt="" class="u-visually-hidden" height="1" src="/o8u0xtsy/article/nature24270" width="1"/>
  <div class="c-cookie-banner">
   <div class="c-cookie-banner__container">
    <p>
     This website sets only cookies which are necessary for it to function. They are used to enable core functionality such as security, network management and accessibility. These cookies cannot be switched off in our systems. You may disable these by changing your browser settings, but this may affect how the website functions. Please view our privacy policy for further details on how we process your information.
     <button class="c-cookie-banner__dismiss">
      Dismiss
     </button>
    </p>
   </div>
  </div>
  <script src="https://verify-nature-com.proxy.lib.ohio-state.edu/verify/nature.min.js">
  </script>
 </body>
</html>
