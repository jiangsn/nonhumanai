<html class="js" lang="en">
 <head>
  <link as="font" crossorigin="" href="/static/fonts/HardingText-Regular-Web-cecd90984f.woff2" rel="preload" type="font/woff2"/>
  <title>
   Human-level control through deep reinforcement learning | Nature
  </title>
  <script id="save-data-connection-testing">
   function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
  </script>
  <script data-consent="www-nature-com.proxy.lib.ohio-state.edu" src="/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js">
  </script>
  <link crossorigin="" href="https://push-content.springernature.io" rel="preconnect"/>
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="pc,mobile" name="applicable-device"/>
  <meta content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes" name="viewport"/>
  <meta content="5a2dc4ab3fcb9b0393241ffbbb490480" name="360-site-verification"/>
  <script data-test="dataLayer">
   window.dataLayer = [{"content":{"category":{"contentType":"letter","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"computer-science","webtrendsContentCategory":null,"webtrendsContentCollection":"The multidisciplinary nature of machine intelligence","webtrendsContentGroup":"Nature","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Letter"}},"article":{"doi":"10.1038/nature14236"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Volodymyr Mnih","Koray Kavukcuoglu","David Silver","Andrei A. Rusu","Joel Veness","Marc G. Bellemare","Alex Graves","Martin Riedmiller","Andreas K. Fidjeland","Georg Ostrovski","Stig Petersen","Charles Beattie","Amir Sadik","Ioannis Antonoglou","Helen King","Dharshan Kumaran","Daan Wierstra","Shane Legg","Demis Hassabis"],"publishedAt":1424822400,"publishedAtString":"2015-02-25","title":"Human-level control through deep reinforcement learning","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"nature","title":"nature","volume":"518","issue":"7540"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":{"id":"csgqqsrfxh"}},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        ga4ServerUrl: 'https://collect-nature-com.proxy.lib.ohio-state.edu',
        imprint: 'nature'
    });
  </script>
  <script>
   (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
  </script>
  <style>
   @media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-editorial-summary__container .c-article-editorial-summary__button:focus{outline:3px solid #fece3e;will-change:transform}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:16px}.c-recommendations-title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.24;margin:0;padding-bottom:16px}.c-recommendations-close{background-color:transparent;border:0;cursor:pointer;height:2em;margin-right:-10px;margin-top:-5px;width:2em}.c-recommendations-authors{line-height:1.24;margin:0}.c-recommendations-list-container{position:relative}.c-recommendations-list{display:flex;flex-wrap:nowrap;justify-content:space-between;margin:0 auto;overflow-x:hidden;padding:0 0 16px;scroll-behavior:smooth;scroll-snap-type:x mandatory;width:calc(100% - 128px)}@media only screen and (max-width:539px){.c-recommendations-list{display:block;height:40vh;overflow-y:auto;width:100%}}.c-recommendations-list__item{display:flex;flex:0 0 calc(33.3333% - 24px);margin:0 24px 0 0;scroll-snap-align:center}@media only screen and (max-width:539px){.c-recommendations-list__item{margin:0;padding:0 0 16px}}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 16px 0 0;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #d5d5d5;height:auto;min-height:0;position:relative;transform:translateY(0)}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:#069;text-decoration:none}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}@media only screen and (max-width:539px){.c-recommendations-column-switch{display:flex;flex-direction:column-reverse}}.js-greyout-page-background{background-color:rgba(34,34,34,.75);bottom:0;left:0;position:fixed;right:0;top:0}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a{color:inherit}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px;padding:0}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:540px){.u-hide-at-sm{display:none;visibility:hidden}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-display-flex{display:flex;width:100%}.u-flex-direction-column{flex-direction:column}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px} }
  </style>
  <link data-inline-css-source="critical-css" data-test="critical-css-handler" href="/static/css/enhanced-article-nature-branded-30b9d5ba44.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null" rel="stylesheet"/>
  <noscript>
   <link href="/static/css/enhanced-article-nature-branded-30b9d5ba44.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)" rel="stylesheet" type="text/css"/>
  </noscript>
  <link href="/static/css/article-print-122346e276.css" media="print" rel="stylesheet" type="text/css"/>
  <link href="/static/images/favicons/nature/apple-touch-icon-f39cb19454.png" rel="apple-touch-icon" sizes="180x180"/>
  <link href="/static/images/favicons/nature/favicon-32x32-3fe59ece92.png" rel="icon" sizes="32x32" type="image/png"/>
  <link href="/static/images/favicons/nature/favicon-16x16-951651ab72.png" rel="icon" sizes="16x16" type="image/png"/>
  <link crossorigin="use-credentials" href="/static/manifest.json" rel="manifest"/>
  <link color="#000000" href="/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg" rel="mask-icon"/>
  <link href="/static/images/favicons/nature/favicon.ico" rel="shortcut icon"/>
  <meta content="#000000" name="msapplication-TileColor"/>
  <meta content="/static/browserconfig.xml" name="msapplication-config"/>
  <meta content="#000000" name="theme-color"/>
  <meta content="Nature" name="application-name"/>
  <script>
   (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
  </script>
  <!-- Google Tag Manager -->
  <script data-test="gtm-head">
   window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
  </script>
  <!-- End Google Tag Manager -->
  <script>
   (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp-static-nature-com.proxy.lib.ohio-state.edu/production_live/consent-bundle-8-23.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp-static-nature-com.proxy.lib.ohio-state.edu/production_live/consent-bundle-8-23.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
  </script>
  <script id="js-position0">
   (function(w, d) {
        w.idpVerifyPrefix = 'https://verify-nature-com.proxy.lib.ohio-state.edu';
        w.ra21Host = 'https://wayf-springernature-com.proxy.lib.ohio-state.edu';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        var polyfillsUrl = function() {
            var features = {
                'IntersectionObserver': window.IntersectionObserver,
                'Promise': window.Promise,
                'URLSearchParams': window.URLSearchParams,
                'Symbol.iterator': window.Symbol && Symbol.iterator,
                'Array.from': Array.from,
                'Array.prototype.includes': Array.prototype.includes,
                'Array.prototype.find': Array.prototype.find,
                'Array.prototype.forEach': Array.prototype.forEach,
                'NodeList.prototype.forEach': NodeList.prototype.forEach,
                'Element.prototype.closest': Element.prototype.closest,
                'Element.prototype.prepend': Element.prototype.prepend,
                'Element.prototype.remove': Element.prototype.remove,
                'Object.assign': Object.assign
            };
            var req = [];
            for (var feature in features) {
                if (Object.prototype.hasOwnProperty.call(features, feature) && !features[feature]) {
                    req.push(feature);
                }
            }
            if (req.length) {
                return 'https://polyfill.io/v3/polyfill.min.js?features=' + req.join('%2C') + '&flags=always';
            }
            return null;
        };

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    {src: polyfillsUrl(), test: 'polyfills-js', noinit: true},
                    
                        {src: '/static/js/global-article-es6-bundle-62a1428781.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-ca6a20c074.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-7850fbb459.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-bd334e676d.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-c634a291c7.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        
                            var conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-2626f1bdf8.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-bd14bd0747.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2d5c465efd.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
  </script>
  <script data-test="global-article-js" defer="" id="js-position1" src="/static/js/global-article-es6-bundle-62a1428781.js">
  </script>
  <script data-test="shared-js" defer="" id="js-position2" src="/static/js/shared-es6-bundle-7850fbb459.js">
  </script>
  <script data-test="header-150-js" defer="" id="js-position3" src="/static/js/header-150-es6-bundle-5bb959eaa1.js">
  </script>
  <meta content="noarchive" name="robots"/>
  <meta content="Yes" name="access"/>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/search" rel="search"/>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/opensearch/opensearch.xml" rel="search" title="nature.com" type="application/opensearchdescription+xml"/>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/opensearch/request" rel="search" title="nature.com" type="application/sru+xml"/>
  <script type="application/ld+json">
   {"mainEntity":{"headline":"Human-level control through deep reinforcement learning","description":"An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action. For an artificial agent to be considered truly intelligent it needs to excel at a variety of tasks considered challenging for humans. To date, it has only been possible to create individual algorithms able to master a single discipline — for example, IBM's Deep Blue beat the human world champion at chess but was not able to do anything else. Now a team working at Google's DeepMind subsidiary has developed an artificial agent — dubbed a deep Q-network — that learns to play 49 classic Atari 2600 'arcade' games directly from sensory experience, achieving performance on a par with that of an expert human player. By combining reinforcement learning (selecting actions that maximize reward — in this case the game score) with deep learning (multilayered feature extraction from high-dimensional data — in this case the pixels), the game-playing agent takes artificial intelligence a step nearer the goal of systems capable of learning a diversity of challenging tasks from scratch. The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4,5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6,7,8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9,10,11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.","datePublished":"2015-02-25","dateModified":"2015-02-25","pageStart":"529","pageEnd":"533","sameAs":"https://doi-org.proxy.lib.ohio-state.edu/10.1038/nature14236","keywords":"Computer science,Science,Humanities and Social Sciences,multidisciplinary","image":"https://static-content.springer.com/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg","isPartOf":{"name":"Nature","issn":["1476-4687","0028-0836"],"volumeNumber":"518","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www-springernature-com.proxy.lib.ohio-state.edu/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Volodymyr Mnih","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Koray Kavukcuoglu","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"email":"korayk@google.com","@type":"Person"},{"name":"David Silver","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Andrei A. Rusu","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Joel Veness","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Marc G. Bellemare","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Alex Graves","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Martin Riedmiller","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Andreas K. Fidjeland","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Georg Ostrovski","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Stig Petersen","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Charles Beattie","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Amir Sadik","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Ioannis Antonoglou","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Helen King","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Dharshan Kumaran","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Daan Wierstra","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Shane Legg","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Demis Hassabis","affiliation":[{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK","address":{"name":"Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, \n                  ","@type":"PostalAddress"},"@type":"Organization"}],"email":"demishassabis@google.com","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}
  </script>
  <link href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236" rel="canonical"/>
  <meta content="41586" name="journal_id"/>
  <meta content="Human-level control through deep reinforcement learning" name="dc.title"/>
  <meta content="Nature 2015 518:7540" name="dc.source"/>
  <meta content="text/html" name="dc.format"/>
  <meta content="Nature Publishing Group" name="dc.publisher"/>
  <meta content="2015-02-25" name="dc.date"/>
  <meta content="OriginalPaper" name="dc.type"/>
  <meta content="En" name="dc.language"/>
  <meta content="2015 Springer Nature Limited" name="dc.copyright"/>
  <meta content="2015 Springer Nature Limited" name="dc.rights"/>
  <meta content="journalpermissions@springernature.com" name="dc.rightsAgent"/>
  <meta content="An artificial agent is developed that learns to play&amp;nbsp;a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a&amp;nbsp;performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action. For an artificial agent to be considered truly intelligent it needs to excel at a variety of tasks considered challenging for humans. To date, it has only been possible to create individual algorithms able to master a single discipline — for example, IBM's Deep Blue beat the human world champion at chess but was not able to do anything else. Now a team working at Google's DeepMind subsidiary has developed an artificial agent — dubbed a deep Q-network — that learns to play 49 classic Atari 2600 'arcade' games directly from sensory experience, achieving performance on a par with that of an expert human player. By combining reinforcement learning (selecting actions that maximize reward — in this case the game score) with deep learning (multilayered feature extraction from high-dimensional data — in this case the pixels), the game-playing agent takes artificial intelligence a step nearer the goal of systems capable of learning a diversity of challenging tasks from scratch. The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4,5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6,7,8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9,10,11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks." name="dc.description"/>
  <meta content="1476-4687" name="prism.issn"/>
  <meta content="Nature" name="prism.publicationName"/>
  <meta content="2015-02-25" name="prism.publicationDate"/>
  <meta content="518" name="prism.volume"/>
  <meta content="7540" name="prism.number"/>
  <meta content="OriginalPaper" name="prism.section"/>
  <meta content="529" name="prism.startingPage"/>
  <meta content="533" name="prism.endingPage"/>
  <meta content="2015 Springer Nature Limited" name="prism.copyright"/>
  <meta content="journalpermissions@springernature.com" name="prism.rightsAgent"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236" name="prism.url"/>
  <meta content="doi:10.1038/nature14236" name="prism.doi"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236.pdf" name="citation_pdf_url"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236" name="citation_fulltext_html_url"/>
  <meta content="Nature" name="citation_journal_title"/>
  <meta content="Nature" name="citation_journal_abbrev"/>
  <meta content="Nature Publishing Group" name="citation_publisher"/>
  <meta content="1476-4687" name="citation_issn"/>
  <meta content="Human-level control through deep reinforcement learning" name="citation_title"/>
  <meta content="518" name="citation_volume"/>
  <meta content="7540" name="citation_issue"/>
  <meta content="2015/02" name="citation_publication_date"/>
  <meta content="2015/02/25" name="citation_online_date"/>
  <meta content="529" name="citation_firstpage"/>
  <meta content="533" name="citation_lastpage"/>
  <meta content="Article" name="citation_article_type"/>
  <meta content="en" name="citation_language"/>
  <meta content="doi:10.1038/nature14236" name="dc.identifier"/>
  <meta content="10.1038/nature14236" name="DOI"/>
  <meta content="145098" name="size"/>
  <meta content="10.1038/nature14236" name="citation_doi"/>
  <meta content="http://api.springer-com.proxy.lib.ohio-state.edu/xmldata/jats?q=doi:10.1038/nature14236&amp;api_key=" name="citation_springer_api_url"/>
  <meta content="An artificial agent is developed that learns to play&amp;nbsp;a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a&amp;nbsp;performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action. For an artificial agent to be considered truly intelligent it needs to excel at a variety of tasks considered challenging for humans. To date, it has only been possible to create individual algorithms able to master a single discipline — for example, IBM's Deep Blue beat the human world champion at chess but was not able to do anything else. Now a team working at Google's DeepMind subsidiary has developed an artificial agent — dubbed a deep Q-network — that learns to play 49 classic Atari 2600 'arcade' games directly from sensory experience, achieving performance on a par with that of an expert human player. By combining reinforcement learning (selecting actions that maximize reward — in this case the game score) with deep learning (multilayered feature extraction from high-dimensional data — in this case the pixels), the game-playing agent takes artificial intelligence a step nearer the goal of systems capable of learning a diversity of challenging tasks from scratch. The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4,5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6,7,8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9,10,11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks." name="description"/>
  <meta content="Mnih, Volodymyr" name="dc.creator"/>
  <meta content="Kavukcuoglu, Koray" name="dc.creator"/>
  <meta content="Silver, David" name="dc.creator"/>
  <meta content="Rusu, Andrei A." name="dc.creator"/>
  <meta content="Veness, Joel" name="dc.creator"/>
  <meta content="Bellemare, Marc G." name="dc.creator"/>
  <meta content="Graves, Alex" name="dc.creator"/>
  <meta content="Riedmiller, Martin" name="dc.creator"/>
  <meta content="Fidjeland, Andreas K." name="dc.creator"/>
  <meta content="Ostrovski, Georg" name="dc.creator"/>
  <meta content="Petersen, Stig" name="dc.creator"/>
  <meta content="Beattie, Charles" name="dc.creator"/>
  <meta content="Sadik, Amir" name="dc.creator"/>
  <meta content="Antonoglou, Ioannis" name="dc.creator"/>
  <meta content="King, Helen" name="dc.creator"/>
  <meta content="Kumaran, Dharshan" name="dc.creator"/>
  <meta content="Wierstra, Daan" name="dc.creator"/>
  <meta content="Legg, Shane" name="dc.creator"/>
  <meta content="Hassabis, Demis" name="dc.creator"/>
  <meta content="Computer science" name="dc.subject"/>
  <meta content="citation_title=Reinforcement Learning: An Introduction; citation_publication_date=1998; citation_id=CR1; citation_author=R Sutton; citation_author=A Barto" name="citation_reference"/>
  <meta content="citation_title=Animal Intelligence: Experimental studies; citation_publication_date=1911; citation_id=CR2; citation_author=EL Thorndike" name="citation_reference"/>
  <meta content="citation_journal_title=Science; citation_title=A neural substrate of prediction and reward; citation_author=W Schultz, P Dayan, PR Montague; citation_volume=275; citation_publication_date=1997; citation_pages=1593-1599; citation_doi=10.1126/science.275.5306.1593; citation_id=CR3" name="citation_reference"/>
  <meta content="citation_title=Object recognition with features inspired by visual cortex; citation_inbook_title=Proc. IEEE. Comput. Soc. Conf. Comput. Vis. Pattern. Recognit.; citation_publication_date=2005; citation_pages=994-1000; citation_id=CR4; citation_author=T Serre; citation_author=L Wolf; citation_author=T Poggio" name="citation_reference"/>
  <meta content="citation_journal_title=Biol. Cybern.; citation_title=Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position; citation_author=K Fukushima; citation_volume=36; citation_publication_date=1980; citation_pages=193-202; citation_doi=10.1007/BF00344251; citation_id=CR5" name="citation_reference"/>
  <meta content="citation_journal_title=Commun. ACM; citation_title=Temporal difference learning and TD-Gammon; citation_author=G Tesauro; citation_volume=38; citation_publication_date=1995; citation_pages=58-68; citation_doi=10.1145/203330.203343; citation_id=CR6" name="citation_reference"/>
  <meta content="citation_journal_title=Auton. Robots; citation_title=Reinforcement learning for robot soccer; citation_author=M Riedmiller, T Gabel, R Hafner, S Lange; citation_volume=27; citation_publication_date=2009; citation_pages=55-73; citation_doi=10.1007/s10514-009-9120-4; citation_id=CR7" name="citation_reference"/>
  <meta content="citation_title=An object-oriented representation for efficient reinforcement learning; citation_inbook_title=Proc. Int. Conf. Mach. Learn.; citation_publication_date=2008; citation_pages=240-247; citation_id=CR8; citation_author=C Diuk; citation_author=A Cohen; citation_author=ML Littman" name="citation_reference"/>
  <meta content="citation_journal_title=Foundations and Trends in Machine Learning; citation_title=Learning deep architectures for AI; citation_author=Y Bengio; citation_volume=2; citation_publication_date=2009; citation_pages=1-127; citation_doi=10.1561/2200000006; citation_id=CR9" name="citation_reference"/>
  <meta content="citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=ImageNet classification with deep convolutional neural networks; citation_author=A Krizhevsky, I Sutskever, G Hinton; citation_volume=25; citation_publication_date=2012; citation_pages=1106-1114; citation_id=CR10" name="citation_reference"/>
  <meta content="citation_journal_title=Science; citation_title=Reducing the dimensionality of data with neural networks; citation_author=GE Hinton, RR Salakhutdinov; citation_volume=313; citation_publication_date=2006; citation_pages=504-507; citation_doi=10.1126/science.1127647; citation_id=CR11" name="citation_reference"/>
  <meta content="citation_journal_title=J. Artif. Intell. Res.; citation_title=The arcade learning environment: An evaluation platform for general agents; citation_author=MG Bellemare, Y Naddaf, J Veness, M Bowling; citation_volume=47; citation_publication_date=2013; citation_pages=253-279; citation_doi=10.1613/jair.3912; citation_id=CR12" name="citation_reference"/>
  <meta content="citation_journal_title=Minds Mach.; citation_title=Universal Intelligence: a definition of machine intelligence; citation_author=S Legg, M Hutter; citation_volume=17; citation_publication_date=2007; citation_pages=391-444; citation_doi=10.1007/s11023-007-9079-x; citation_id=CR13" name="citation_reference"/>
  <meta content="citation_journal_title=AI Mag.; citation_title=General game playing: overview of the AAAI competition; citation_author=M Genesereth, N Love, B Pell; citation_volume=26; citation_publication_date=2005; citation_pages=62-72; citation_id=CR14" name="citation_reference"/>
  <meta content="citation_title=Investigating contingency awareness using Atari 2600 games; citation_inbook_title=Proc. Conf. AAAI. Artif. Intell.; citation_publication_date=2012; citation_pages=864-871; citation_id=CR15; citation_author=MG Bellemare; citation_author=J Veness; citation_author=M Bowling" name="citation_reference"/>
  <meta content="citation_title=Parallel Distributed Processing: Explorations in the Microstructure of Cognition; citation_publication_date=1986; citation_id=CR16; citation_author=JL McClelland; citation_author=DE Rumelhart; citation_author=TPR Group" name="citation_reference"/>
  <meta content="citation_journal_title=Proc. IEEE; citation_title=Gradient-based learning applied to document recognition; citation_author=Y LeCun, L Bottou, Y Bengio, P Haffner; citation_volume=86; citation_publication_date=1998; citation_pages=2278-2324; citation_doi=10.1109/5.726791; citation_id=CR17" name="citation_reference"/>
  <meta content="citation_journal_title=J. Physiol.; citation_title=Shape and arrangement of columns in cat’s striate cortex; citation_author=DH Hubel, TN Wiesel; citation_volume=165; citation_publication_date=1963; citation_pages=559-568; citation_doi=10.1113/jphysiol.1963.sp007079; citation_id=CR18" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.; citation_title=Q-learning; citation_author=CJ Watkins, P Dayan; citation_volume=8; citation_publication_date=1992; citation_pages=279-292; citation_id=CR19" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Trans. Automat. Contr.; citation_title=An analysis of temporal-difference learning with function approximation; citation_author=J Tsitsiklis, BV Roy; citation_volume=42; citation_publication_date=1997; citation_pages=674-690; citation_doi=10.1109/9.580874; citation_id=CR20" name="citation_reference"/>
  <meta content="citation_journal_title=Psychol. Rev.; citation_title=Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory; citation_author=JL McClelland, BL McNaughton, RC O’Reilly; citation_volume=102; citation_publication_date=1995; citation_pages=419-457; citation_doi=10.1037/0033-295X.102.3.419; citation_id=CR21" name="citation_reference"/>
  <meta content="citation_journal_title=Trends Neurosci.; citation_title=Play it again: reactivation of waking experience and memory; citation_author=J O’Neill, B Pleydell-Bouverie, D Dupret, J Csicsvari; citation_volume=33; citation_publication_date=2010; citation_pages=220-229; citation_doi=10.1016/j.tins.2010.01.006; citation_id=CR22" name="citation_reference"/>
  <meta content="Lin, L.-J. Reinforcement learning for robots using neural networks. Technical Report, DTIC Document. (1993)" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.: ECML; citation_title=Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method; citation_author=M Riedmiller; citation_volume=3720; citation_publication_date=2005; citation_pages=317-328; citation_id=CR24" name="citation_reference"/>
  <meta content="citation_journal_title=J. Mach. Learn. Res.; citation_title=Visualizing high-dimensional data using t-SNE; citation_author=LJP Van der Maaten, GE Hinton; citation_volume=9; citation_publication_date=2008; citation_pages=2579-2605; citation_id=CR25" name="citation_reference"/>
  <meta content="citation_title=Deep auto-encoder neural networks in reinforcement learning; citation_inbook_title=Proc. Int. Jt. Conf. Neural. Netw.; citation_publication_date=2010; citation_pages=1-8; citation_id=CR26; citation_author=S Lange; citation_author=M Riedmiller" name="citation_reference"/>
  <meta content="citation_journal_title=Nature Neurosci.; citation_title=Reinforcement learning can account for associative and perceptual learning on a visual decision task; citation_author=C-T Law, JI Gold; citation_volume=12; citation_publication_date=2009; citation_pages=655; citation_doi=10.1038/nn.2304; citation_id=CR27" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Visual categorization shapes feature selectivity in the primate temporal cortex; citation_author=N Sigala, NK Logothetis; citation_volume=415; citation_publication_date=2002; citation_pages=318-320; citation_doi=10.1038/415318a; citation_id=CR28" name="citation_reference"/>
  <meta content="citation_journal_title=Nature Neurosci.; citation_title=Biasing the content of hippocampal replay during sleep; citation_author=D Bendor, MA Wilson; citation_volume=15; citation_publication_date=2012; citation_pages=1439-1444; citation_doi=10.1038/nn.3203; citation_id=CR29" name="citation_reference"/>
  <meta content="citation_journal_title=Mach. Learn.; citation_title=Prioritized sweeping: reinforcement learning with less data and less real time; citation_author=A Moore, C Atkeson; citation_volume=13; citation_publication_date=1993; citation_pages=103-130; citation_id=CR30" name="citation_reference"/>
  <meta content="citation_title=What is the best multi-stage architecture for object recognition; citation_inbook_title=Proc. IEEE. Int. Conf. Comput. Vis.; citation_publication_date=2009; citation_pages=2146-2153; citation_id=CR31; citation_author=K Jarrett; citation_author=K Kavukcuoglu; citation_author=MA Ranzato; citation_author=Y LeCun" name="citation_reference"/>
  <meta content="Nair, V. &amp; Hinton, G. E. Rectified linear units improve restricted Boltzmann machines. Proc. Int. Conf. Mach. Learn. 807–814 (2010)" name="citation_reference"/>
  <meta content="citation_journal_title=Artificial Intelligence; citation_title=Planning and acting in partially observable stochastic domains; citation_author=LP Kaelbling, ML Littman, AR Cassandra; citation_volume=101; citation_publication_date=1994; citation_pages=99-134; citation_doi=10.1016/S0004-3702(98)00023-X; citation_id=CR33" name="citation_reference"/>
  <meta content="Mnih, Volodymyr" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Kavukcuoglu, Koray" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Silver, David" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Rusu, Andrei A." name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Veness, Joel" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Bellemare, Marc G." name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Graves, Alex" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Riedmiller, Martin" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Fidjeland, Andreas K." name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Ostrovski, Georg" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Petersen, Stig" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Beattie, Charles" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Sadik, Amir" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Antonoglou, Ioannis" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="King, Helen" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Kumaran, Dharshan" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Wierstra, Daan" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Legg, Shane" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="Hassabis, Demis" name="citation_author"/>
  <meta content="Google DeepMind, 5 New Street Square, London EC4A 3TW, UK, 
                  " name="citation_author_institution"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/platform/readcube-access" name="access_endpoint"/>
  <meta content="@nature" name="twitter:site"/>
  <meta content="summary_large_image" name="twitter:card"/>
  <meta content="Content cover image" name="twitter:image:alt"/>
  <meta content="Human-level control through deep reinforcement learning" name="twitter:title"/>
  <meta content="Nature - For an artificial agent to be considered truly intelligent it needs to excel at a variety of tasks considered challenging for humans. To date, it has only been possible to create..." name="twitter:description"/>
  <meta content="https://media-springernature-com.proxy.lib.ohio-state.edu/full/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg" name="twitter:image"/>
  <meta content="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236" property="og:url"/>
  <meta content="article" property="og:type"/>
  <meta content="Nature" property="og:site_name"/>
  <meta content="Human-level control through deep reinforcement learning - Nature" property="og:title"/>
  <meta content="An artificial agent is developed that learns to play&amp;nbsp;a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a&amp;nbsp;performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action." property="og:description"/>
  <meta content="https://media-springernature-com.proxy.lib.ohio-state.edu/m685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg" property="og:image"/>
  <script>
   window.eligibleForRa21 = 'true';
  </script>
  <script async="" src="https://injections.readcube.com/nature/inject.ef8e25d3.js" type="text/javascript">
  </script>
  <style type="text/css">
   .c-cookie-banner {
			background-color: #01324b;
			color: white;
			font-size: 1rem;
			position: fixed;
			bottom: 0;
			left: 0;
			right: 0;
			padding: 16px 0;
			font-family: sans-serif;
			z-index: 100002;
			text-align: center;
		}
		.c-cookie-banner__container {
			margin: 0 auto;
			max-width: 1280px;
			padding: 0 16px;
		}
		.c-cookie-banner p {
			margin-bottom: 8px;
		}
		.c-cookie-banner p:last-child {
			margin-bottom: 0;
		}	
		.c-cookie-banner__dismiss {
			background-color: transparent;
			border: 0;
			padding: 0;
			margin-left: 4px;
			color: inherit;
			text-decoration: underline;
			font-size: inherit;
		}
		.c-cookie-banner__dismiss:hover {
			text-decoration: none;
		}
  </style>
  <link href="https://injections.readcube.com/styles/nature_checkout.7bec98da.css" rel="stylesheet" type="text/css"/>
  <script>
   window.dataLayer = window.dataLayer || [];
            window.dataLayer.push({
                recommendations: {
                    recommender: 'topic',
                    model: 'visits_v2',
                    policy_id: 'speedy-BootstrappedUCB',
                    timestamp: 1698031850,
                    embedded_user: 'null'
                }
            });
  </script>
 </head>
 <body class="article-page">
  <noscript>
   <iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ" style="display:none;visibility:hidden" width="0">
   </iframe>
  </noscript>
  <div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
   <a class="c-skip-link" href="#content">
    Skip to main content
   </a>
   <div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
     <p>
      Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.
     </p>
    </div>
   </div>
   <div class="u-lazy-ad-wrapper u-mbs-0">
    <div class="deferred-placeholder" data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container" data-replace="true">
    </div>
    <aside class="c-ad c-ad--728x90">
     <div class="c-ad__inner" data-container-type="banner-advert">
      <p class="c-ad__label">
       Advertisement
      </p>
      <div class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide" data-ad-type="top" data-gpt="" data-gpt-sizes="728x90" data-gpt-targeting="type=article;pos=top;artid=nature14236;doi=10.1038/nature14236;techmeta=119,129;subjmeta=117,639,705;kwrd=Computer+science" data-gpt-unitpath="/285/nature.com/article" data-pa11y-ignore="" data-test="top-ad" id="div-gpt-ad-top-1">
       <noscript>
        <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=728x90&amp;c=1119316271&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnature14236%26doi%3D10.1038/nature14236%26techmeta%3D119,129%26subjmeta%3D117,639,705%26kwrd%3DComputer+science">
         <img alt="Advertisement" data-test="gpt-advert-fallback-img" height="90" src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=728x90&amp;c=1119316271&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnature14236%26doi%3D10.1038/nature14236%26techmeta%3D119,129%26subjmeta%3D117,639,705%26kwrd%3DComputer+science" width="728"/>
        </a>
       </noscript>
      </div>
     </div>
    </aside>
   </div>
   <header class="c-header" data-header="" data-track-component="nature-150-split-header" id="header" style="border-color:#000">
    <div class="c-header__row">
     <div class="c-header__container">
      <div class="c-header__split">
       <div class="c-header__logo-container">
        <a data-track="click" data-track-action="home" data-track-label="image" href="/">
         <picture class="c-header__logo">
          <source media="(min-width: 875px)" srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/full/nature-cms/uploads/product/nature/header-86f1267ea01eccd46b530284be10585e.svg"/>
          <img alt="Nature" height="32" src="https://media-springernature-com.proxy.lib.ohio-state.edu/full/nature-cms/uploads/product/nature/header-86f1267ea01eccd46b530284be10585e.svg"/>
         </picture>
        </a>
       </div>
       <ul class="c-header__menu c-header__menu--global">
        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
         <a class="c-header__link" data-test="siteindex-link" data-track="click" data-track-action="open nature research index" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/siteindex">
          <span>
           View all journals
          </span>
         </a>
        </li>
        <li class="c-header__item c-header__item--padding c-header__item--pipe">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button" href="javascript:;" role="button">
          <span>
           Search
          </span>
          <svg aria-hidden="true" focusable="false" height="22" role="img" viewbox="0 0 18 18" width="22" xmlns="http://www.w3.org/2000/svg">
           <path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z">
           </path>
          </svg>
         </a>
         <div class="c-header__dropdown c-header__dropdown--full-width has-tethered u-js-hide" data-track-component="nature-150-split-header" hidden="" id="search-menu">
          <div class="c-header__container">
           <h2 class="c-header__visually-hidden">
            Search
           </h2>
           <form action="/search" autocomplete="off" class="c-header__search-form" data-test="inline-search" method="get" role="search">
            <label class="c-header__heading" for="keywords">
             Search articles by subject, keyword or author
            </label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
             <div>
              <input class="c-header__input" id="keywords" name="q" required="" type="text" value=""/>
             </div>
             <div class="c-header__search-layout">
              <div>
               <label class="c-header__visually-hidden" for="results-from">
                Show results from
               </label>
               <select class="c-header__select" id="results-from" name="journal">
                <option selected="" value="">
                 All journals
                </option>
                <option value="nature">
                 This journal
                </option>
               </select>
              </div>
              <div>
               <button class="c-header__search-button" type="submit">
                Search
               </button>
              </div>
             </div>
            </div>
           </form>
           <div class="c-header__flush">
            <a class="c-header__link" data-track="click" data-track-action="advanced search" data-track-label="link" href="/search/advanced">
             Advanced search
            </a>
           </div>
           <h3 class="c-header__heading c-header__heading--keyline">
            Quick links
           </h3>
           <ul class="c-header__list">
            <li>
             <a class="c-header__link" data-track="click" data-track-action="explore articles by subject" data-track-label="link" href="/subjects">
              Explore articles by subject
             </a>
            </li>
            <li>
             <a class="c-header__link" data-track="click" data-track-action="find a job" data-track-label="link" href="/naturecareers">
              Find a job
             </a>
            </li>
            <li>
             <a class="c-header__link" data-track="click" data-track-action="guide to authors" data-track-label="link" href="/authors/index.html">
              Guide to authors
             </a>
            </li>
            <li>
             <a class="c-header__link" data-track="click" data-track-action="editorial policies" data-track-label="link" href="/authors/editorial_policies/">
              Editorial policies
             </a>
            </li>
           </ul>
          </div>
         </div>
        </li>
        <li class="c-header__item c-header__item--padding">
         <a class="c-header__link eds-c-header__link" href="https://idp-nature-com.proxy.lib.ohio-state.edu/auth/personal/springernature?redirect_uri=https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236" id="identity-account-widget">
          Log in
         </a>
        </li>
       </ul>
      </div>
     </div>
    </div>
    <div class="c-header__row">
     <div class="c-header__container" data-test="navigation-row">
      <div class="c-header__split">
       <ul class="c-header__menu c-header__menu--journal">
        <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" data-test="menu-button--explore" data-track="click" data-track-action="open explore expander" data-track-label="button" href="javascript:;" role="button">
          <span>
           <span class="c-header__show-text">
            Explore
           </span>
           content
          </span>
          <svg aria-hidden="true" focusable="false" height="16" role="img" viewbox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg">
           <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)">
           </path>
          </svg>
         </a>
         <nav aria-labelledby="Explore-content" class="c-header__dropdown has-tethered u-js-hide" data-test="Explore-content" data-track-component="nature-150-split-header" hidden="" id="explore">
          <div class="c-header__container">
           <h2 class="c-header__heading c-header__heading--js-hide" id="Explore-content">
            Explore content
           </h2>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="research articles" data-track-label="link" href="/nature/research-articles">
              Research articles
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="news" data-track-label="link" href="/news">
              News
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="opinion" data-track-label="link" href="/opinion">
              Opinion
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="research analysis" data-track-label="link" href="/research-analysis">
              Research Analysis
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="careers" data-track-label="link" href="/careers">
              Careers
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="books &amp; culture" data-track-label="link" href="/books-culture">
              Books &amp; Culture
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="podcasts" data-track-label="link" href="/nature/podcasts">
              Podcasts
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="videos" data-track-label="link" href="/nature/videos">
              Videos
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="current issue" data-track-label="link" href="/nature/current-issue">
              Current issue
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="browse issues" data-track-label="link" href="/nature/browse-issues">
              Browse issues
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="collections" data-track-label="link" href="/nature/collections">
              Collections
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="explore-nav-item" data-track="click" data-track-action="subjects" data-track-label="link" href="/nature/browse-subjects">
              Subjects
             </a>
            </li>
           </ul>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="facebook" data-track-label="link" href="https://www.facebook.com/Nature">
              Follow us on Facebook
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="twitter" data-track-label="link" href="https://twitter.com/nature">
              Follow us on Twitter
             </a>
            </li>
            <li class="c-header__item c-header__item--hide-lg">
             <a class="c-header__link" data-track="click" data-track-action="Sign up for alerts" data-track-external="" data-track-label="link (mobile dropdown)" href="https://www-nature-com.proxy.lib.ohio-state.edu/my-account/alerts/subscribe-journal?list-id=1" rel="nofollow">
              Sign up for alerts
              <svg aria-hidden="true" focusable="false" height="18" role="img" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg">
               <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff">
               </path>
              </svg>
             </a>
            </li>
            <li class="c-header__item c-header__item--hide-lg">
             <a class="c-header__link" data-track="click" data-track-action="rss feed" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nature.rss">
              <span>
               RSS feed
              </span>
             </a>
            </li>
           </ul>
          </div>
         </nav>
        </li>
        <li class="c-header__item c-header__item--dropdown-menu">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" data-test="menu-button--about-the-journal" data-track="click" data-track-action="open about the journal expander" data-track-label="button" href="javascript:;" role="button">
          <span>
           About
           <span class="c-header__show-text">
            the journal
           </span>
          </span>
          <svg aria-hidden="true" focusable="false" height="16" role="img" viewbox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg">
           <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)">
           </path>
          </svg>
         </a>
         <nav aria-labelledby="About-the-journal" class="c-header__dropdown has-tethered u-js-hide" data-test="about-the-journal" data-track-component="nature-150-split-header" hidden="" id="about-the-journal">
          <div class="c-header__container">
           <h2 class="c-header__heading c-header__heading--js-hide" id="About-the-journal">
            About the journal
           </h2>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="journal staff" data-track-label="link" href="/nature/journal-staff">
              Journal Staff
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="about the editors" data-track-label="link" href="/nature/editors">
              About the Editors
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="journal information" data-track-label="link" href="/nature/journal-information">
              Journal Information
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="our publishing models" data-track-label="link" href="/nature/our-publishing-models">
              Our publishing models
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="editorial values statement" data-track-label="link" href="/nature/editorial-values-statement">
              Editorial Values Statement
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="journal metrics" data-track-label="link" href="/nature/journal-impact">
              Journal Metrics
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="awards" data-track-label="link" href="/nature/awards">
              Awards
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="contact" data-track-label="link" href="/nature/contact">
              Contact
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="editorial policies" data-track-label="link" href="/nature/editorial-policies">
              Editorial policies
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="history of nature" data-track-label="link" href="/nature/history-of-nature">
              History of Nature
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="send a news tip" data-track-label="link" href="/nature/send-a-news-tip">
              Send a news tip
             </a>
            </li>
           </ul>
          </div>
         </nav>
        </li>
        <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
         <a aria-expanded="false" aria-haspopup="true" class="c-header__link c-header__link--dropdown-menu" data-header-expander="" data-test="menu-button--publish" data-track="click" data-track-action="open publish with us expander" data-track-label="button" href="javascript:;" role="button">
          <span>
           Publish
           <span class="c-header__show-text">
            with us
           </span>
          </span>
          <svg aria-hidden="true" focusable="false" height="16" role="img" viewbox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg">
           <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)">
           </path>
          </svg>
         </a>
         <nav aria-labelledby="Publish-with-us-label" class="c-header__dropdown has-tethered u-js-hide" data-test="publish-with-us" data-track-component="nature-150-split-header" hidden="" id="publish-with-us">
          <div class="c-header__container">
           <h2 class="c-header__heading c-header__heading--js-hide" id="Publish-with-us-label">
            Publish with us
           </h2>
           <ul class="c-header__list c-header__list--js-stack">
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="for authors" data-track-label="link" href="/nature/for-authors">
              For Authors
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-track="click" data-track-action="for referees" data-track-label="link" href="/nature/for-referees">
              For Referees
             </a>
            </li>
            <li class="c-header__item">
             <a class="c-header__link" data-test="nature-author-services" data-track="click" data-track-action="manuscript author services" data-track-label="link manuscript author services" href="https://authorservices-springernature-com.proxy.lib.ohio-state.edu/go/sn/?utm_source=For+Authors&amp;utm_medium=Website_Nature&amp;utm_campaign=Platform+Experimentation+2022&amp;utm_id=PE2022">
              Language editing services
             </a>
            </li>
            <li class="c-header__item c-header__item--keyline">
             <a class="c-header__link" data-track="click" data-track-action="submit manuscript" data-track-external="" data-track-label="link (publish with us dropdown menu)" href="https://mts-nature-nature-com.proxy.lib.ohio-state.edu/">
              Submit manuscript
              <svg aria-hidden="true" focusable="false" height="18" role="img" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg">
               <path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff">
               </path>
              </svg>
             </a>
            </li>
           </ul>
          </div>
         </nav>
        </li>
       </ul>
       <ul class="c-header__menu c-header__menu--hide-lg-max">
        <li class="c-header__item">
         <a class="c-header__link" data-track="click" data-track-action="Sign up for alerts" data-track-external="" data-track-label="link (desktop site header)" href="https://www-nature-com.proxy.lib.ohio-state.edu/my-account/alerts/subscribe-journal?list-id=1" rel="nofollow">
          <span>
           Sign up for alerts
          </span>
          <svg aria-hidden="true" focusable="false" height="18" role="img" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg">
           <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222">
           </path>
          </svg>
         </a>
        </li>
        <li class="c-header__item c-header__item--pipe">
         <a class="c-header__link" data-track="click" data-track-action="rss feed" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nature.rss">
          <span>
           RSS feed
          </span>
         </a>
        </li>
       </ul>
      </div>
     </div>
    </div>
   </header>
   <nav aria-label="breadcrumbs" class="u-mb-16">
    <div class="u-container">
     <ol class="c-breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList">
      <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
       <a class="c-breadcrumbs__link" data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature" href="/" itemprop="item">
        <span itemprop="name">
         nature
        </span>
       </a>
       <meta content="1" itemprop="position"/>
       <svg aria-hidden="true" class="c-breadcrumbs__chevron" focusable="false" height="10" role="img" viewbox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
        </path>
       </svg>
      </li>
      <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
       <a class="c-breadcrumbs__link" data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:letters" href="/nature/articles?type=letter" itemprop="item">
        <span itemprop="name">
         letters
        </span>
       </a>
       <meta content="2" itemprop="position"/>
       <svg aria-hidden="true" class="c-breadcrumbs__chevron" focusable="false" height="10" role="img" viewbox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
        </path>
       </svg>
      </li>
      <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
       <span itemprop="name">
        article
       </span>
       <meta content="3" itemprop="position"/>
      </li>
     </ol>
    </div>
   </nav>
  </div>
  <div class="u-container u-mt-32 u-mb-32 u-clearfix" data-component="article-container" data-container-type="article" id="content">
   <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
    <div aria-hidden="true" class="c-context-bar u-hide" data-context-bar="" data-context-bar-with-recommendations="" data-test="context-bar">
     <div class="c-context-bar__container u-container">
      <div class="c-context-bar__title">
       Human-level control through deep reinforcement learning
      </div>
      <div class="c-pdf-download u-clear-both js-pdf-download">
       <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature14236.pdf">
        <span class="c-pdf-download__text">
         Download PDF
        </span>
        <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
         <use xlink:href="#icon-download">
         </use>
        </svg>
       </a>
      </div>
     </div>
     <div id="recommendations">
      <div class="c-recommendations__container u-container u-display-none" data-component-recommendations="">
       <aside class="c-status-message c-status-message--success u-display-none" data-component-status-msg="">
        <svg aria-label="success:" class="c-status-message__icon" focusable="false" height="24" role="img" width="24">
         <use xlink:href="#icon-success">
         </use>
        </svg>
        <div class="c-status-message__message" id="success-message" tabindex="-1">
         Your content has downloaded
        </div>
       </aside>
       <div class="c-recommendations-header u-display-flex u-justify-content-space-between">
        <h2 class="c-recommendations-title" id="recommendation-heading">
         Similar content being viewed by others
        </h2>
        <button aria-label="Close" class="c-recommendations-close u-flex-static" data-track="click" data-track-action="close recommendations" type="button">
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
          <use xlink:href="#icon-close">
          </use>
         </svg>
        </button>
       </div>
       <section aria-labelledby="recommendation-heading" aria-roledescription="carousel">
        <p class="u-visually-hidden">
         Slider with three content items shown per slide. Use the Previous and Next buttons to navigate the slides or the slide controller buttons at the end to navigate through each slide.
        </p>
        <div class="c-recommendations-list-container">
         <div class="c-recommendations-list">
          <div aria-label="Recommendation 1 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41586-023-06574-8/MediaObjects/41586_2023_6574_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 1" data-track-label="10.1038/s41586-023-06574-8" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41586-023-06574-8" itemprop="url">
                 State estimation of a physical system with unknown governing equations
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 11 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Kevin Course &amp; Prasanth B. Nair
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 2 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs44159-023-00241-5/MediaObjects/44159_2023_241_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 2" data-track-label="10.1038/s44159-023-00241-5" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s44159-023-00241-5" itemprop="url">
                 Using large language models in psychology
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 13 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Dorottya Demszky, Diyi Yang, … James W. Pennebaker
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 3 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41593-023-01444-y/MediaObjects/41593_2023_1444_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 3" data-track-label="10.1038/s41593-023-01444-y" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41593-023-01444-y" itemprop="url">
                 Studying the neural representations of uncertainty
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 09 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Edgar Y. Walker, Stephan Pohl, … Florent Meyniel
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 4 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41583-023-00740-7/MediaObjects/41583_2023_740_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 4" data-track-label="10.1038/s41583-023-00740-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41583-023-00740-7" itemprop="url">
                 Reconstructing computational system dynamics from neural data with recurrent neural networks
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 04 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Daniel Durstewitz, Georgia Koppe &amp; Max Ingo Thurm
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 5 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41467-023-41664-1/MediaObjects/41467_2023_41664_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 5" data-track-label="10.1038/s41467-023-41664-1" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41467-023-41664-1" itemprop="url">
                 Accurate prediction of protein folding mechanisms by simple structure-based statistical mechanical models
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 19 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Koji Ooka &amp; Munehito Arai
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 6 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41593-023-01460-y/MediaObjects/41593_2023_1460_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 6" data-track-label="10.1038/s41593-023-01460-y" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41593-023-01460-y" itemprop="url">
                 The combination of Hebbian and predictive plasticity learns invariant object representations in deep sensory networks
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 12 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Manu Srinath Halvagal &amp; Friedemann Zenke
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 7 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs43588-023-00527-x/MediaObjects/43588_2023_527_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 7" data-track-label="10.1038/s43588-023-00527-x" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s43588-023-00527-x" itemprop="url">
                 Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 05 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Thilo Hagendorff, Sarah Fabi &amp; Michal Kosinski
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 8 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs42256-023-00735-0/MediaObjects/42256_2023_735_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 8" data-track-label="10.1038/s42256-023-00735-0" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s42256-023-00735-0" itemprop="url">
                 Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 16 October 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Mario Krenn, Lorenzo Buffoni, … Michael Kopp
              </p>
             </div>
            </div>
           </article>
          </div>
          <div aria-label="Recommendation 9 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
           <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
            <div class="c-card__layout u-full-height">
             <div class="c-card__image">
              <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1038%2Fs41586-023-06415-8/MediaObjects/41586_2023_6415_Fig1_HTML.png"/>
             </div>
             <div class="c-card__body u-display-flex u-flex-direction-column">
              <div class="c-recommendations-column-switch">
               <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                <a class="c-card__link" data-track="click" data-track-action="click recommendations - 9" data-track-label="10.1038/s41586-023-06415-8" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038/s41586-023-06415-8" itemprop="url">
                 De novo design of protein structure and function with RFdiffusion
                </a>
               </h3>
               <div class="c-card__section c-meta">
                <span class="c-meta__item u-sans-serif">
                 Article
                </span>
                <span class="c-meta__item u-sans-serif">
                 11 July 2023
                </span>
               </div>
              </div>
              <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
               Joseph L. Watson, David Juergens, … David Baker
              </p>
             </div>
            </div>
           </article>
          </div>
         </div>
        </div>
       </section>
      </div>
      <div class="js-greyout-page-background" data-component-grey-background="" style="display:none">
      </div>
     </div>
    </div>
    <article lang="en">
     <div class="c-article-header">
      <header>
       <ul class="c-article-identifiers" data-test="article-identifier">
        <li class="c-article-identifiers__item">
         <a data-track="click" data-track-action="publication date" data-track-label="link" href="#article-info">
          Published:
          <time datetime="2015-02-25">
           25 February 2015
          </time>
         </a>
        </li>
       </ul>
       <h1 class="c-article-title" data-article-title="" data-test="article-title">
        Human-level control through deep reinforcement learning
       </h1>
       <ul class="c-article-author-list c-article-author-list--short js-no-scroll" data-component-authors-activator="authors-list" data-test="authors-list">
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Volodymyr-Mnih-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Volodymyr-Mnih-Aff1">
          Volodymyr Mnih
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         <sup class="u-js-hide">
          <a href="#na1" tabindex="-1">
           na1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Koray-Kavukcuoglu-Aff1" data-corresp-id="c1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Koray-Kavukcuoglu-Aff1">
          Koray Kavukcuoglu
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
           <use xlink:href="#icon-email-new" xmlns:xlink="http://www.w3.org/1999/xlink">
           </use>
          </svg>
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         <sup class="u-js-hide">
          <a href="#na1" tabindex="-1">
           na1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-David-Silver-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David-Silver-Aff1">
          David Silver
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         <sup class="u-js-hide">
          <a href="#na1" tabindex="-1">
           na1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Andrei_A_-Rusu-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Andrei_A_-Rusu-Aff1">
          Andrei A. Rusu
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Joel-Veness-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Joel-Veness-Aff1">
          Joel Veness
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Marc_G_-Bellemare-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Marc_G_-Bellemare-Aff1">
          Marc G. Bellemare
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Alex-Graves-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alex-Graves-Aff1">
          Alex Graves
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Martin-Riedmiller-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Martin-Riedmiller-Aff1">
          Martin Riedmiller
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Andreas_K_-Fidjeland-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Andreas_K_-Fidjeland-Aff1">
          Andreas K. Fidjeland
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Georg-Ostrovski-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Georg-Ostrovski-Aff1">
          Georg Ostrovski
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Stig-Petersen-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Stig-Petersen-Aff1">
          Stig Petersen
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Charles-Beattie-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Charles-Beattie-Aff1">
          Charles Beattie
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Amir-Sadik-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Amir-Sadik-Aff1">
          Amir Sadik
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Ioannis-Antonoglou-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ioannis-Antonoglou-Aff1">
          Ioannis Antonoglou
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Helen-King-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Helen-King-Aff1">
          Helen King
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Dharshan-Kumaran-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Dharshan-Kumaran-Aff1">
          Dharshan Kumaran
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Daan-Wierstra-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Daan-Wierstra-Aff1">
          Daan Wierstra
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item c-article-author-list__item--hide-small-screen">
         <a data-author-popup="auth-Shane-Legg-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Shane-Legg-Aff1">
          Shane Legg
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         &amp;
        </li>
        <li aria-label="Show all 19 authors for this article" class="c-article-author-list__show-more" title="Show all 19 authors for this article">
         …
        </li>
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Demis-Hassabis-Aff1" data-corresp-id="c2" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Demis-Hassabis-Aff1">
          Demis Hassabis
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
           <use xlink:href="#icon-email-new" xmlns:xlink="http://www.w3.org/1999/xlink">
           </use>
          </svg>
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
        </li>
       </ul>
       <button aria-expanded="false" class="c-article-author-list__button">
        <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
         <use xlink:href="#icon-plus" xmlns:xlink="http://www.w3.org/1999/xlink">
         </use>
        </svg>
        <span>
         Show authors
        </span>
       </button>
       <p class="c-article-info-details" data-container-section="info">
        <a data-test="journal-link" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link" href="/">
         <i data-test="journal-title">
          Nature
         </i>
        </a>
        <b data-test="journal-volume">
         <span class="u-visually-hidden">
          volume
         </span>
         518
        </b>
        ,
        <span class="u-visually-hidden">
         pages
        </span>
        529–533 (
        <span data-test="article-publication-year">
         2015
        </span>
        )
        <a class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link" href="#citeas">
         Cite this article
        </a>
       </p>
       <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__count">
           481k
           <span class="c-article-metrics-bar__label">
            Accesses
           </span>
          </p>
         </li>
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__count">
           12k
           <span class="c-article-metrics-bar__label">
            Citations
           </span>
          </p>
         </li>
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__count">
           1543
           <span class="c-article-metrics-bar__label">
            Altmetric
           </span>
          </p>
         </li>
         <li class="c-article-metrics-bar__item">
          <p class="c-article-metrics-bar__details">
           <a data-track="click" data-track-action="view metrics" data-track-label="link" href="/articles/nature14236/metrics" rel="nofollow">
            Metrics
            <span class="u-visually-hidden">
             details
            </span>
           </a>
          </p>
         </li>
        </ul>
       </div>
      </header>
     </div>
     <div class="c-article-body">
      <section aria-labelledby="Abs3" data-title="Abstract" lang="en">
       <div class="c-article-section" id="Abs3-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs3">
         Abstract
        </h2>
        <div class="c-article-section__content" id="Abs3-content">
         <p>
          The theory of reinforcement learning provides a normative account
          <sup>
           <a aria-label="Reference 1" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR1" id="ref-link-section-d27533759e524" title="Sutton, R. &amp; Barto, A. Reinforcement Learning: An Introduction (MIT Press, 1998)">
            1
           </a>
          </sup>
          , deeply rooted in psychological
          <sup>
           <a aria-label="Reference 2" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR2" id="ref-link-section-d27533759e528" title="Thorndike, E. L. Animal Intelligence: Experimental studies (Macmillan, 1911)">
            2
           </a>
          </sup>
          and neuroscientific
          <sup>
           <a aria-label="Reference 3" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR3" id="ref-link-section-d27533759e532" title="Schultz, W., Dayan, P. &amp; Montague, P. R. A neural substrate of prediction and reward. Science 275, 1593–1599 (1997)">
            3
           </a>
          </sup>
          perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems
          <sup>
           <a aria-label="Reference 4" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR4" id="ref-link-section-d27533759e536" title="Serre, T., Wolf, L. &amp; Poggio, T. Object recognition with features inspired by visual cortex. Proc. IEEE. Comput. Soc. Conf. Comput. Vis. Pattern. Recognit. 994–1000 (2005)">
            4
           </a>
           ,
           <a aria-label="Reference 5" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR5" id="ref-link-section-d27533759e539" title="Fukushima, K. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biol. Cybern. 36, 193–202 (1980)">
            5
           </a>
          </sup>
          , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms
          <sup>
           <a aria-label="Reference 3" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR3" id="ref-link-section-d27533759e543" title="Schultz, W., Dayan, P. &amp; Montague, P. R. A neural substrate of prediction and reward. Science 275, 1593–1599 (1997)">
            3
           </a>
          </sup>
          . While reinforcement learning agents have achieved some successes in a variety of domains
          <sup>
           <a aria-label="Reference 6" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR6" id="ref-link-section-d27533759e548" title="Tesauro, G. Temporal difference learning and TD-Gammon. Commun. ACM 38, 58–68 (1995)">
            6
           </a>
           ,
           <a aria-label="Reference 7" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR7" id="ref-link-section-d27533759e551" title="Riedmiller, M., Gabel, T., Hafner, R. &amp; Lange, S. Reinforcement learning for robot soccer. Auton. Robots 27, 55–73 (2009)">
            7
           </a>
           ,
           <a aria-label="Reference 8" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR8" id="ref-link-section-d27533759e554" title="Diuk, C., Cohen, A. &amp; Littman, M. L. An object-oriented representation for efficient reinforcement learning. Proc. Int. Conf. Mach. Learn. 240–247 (2008)">
            8
           </a>
          </sup>
          , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks
          <sup>
           <a aria-label="Reference 9" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR9" id="ref-link-section-d27533759e558" title="Bengio, Y. Learning deep architectures for AI. Foundations and Trends in Machine Learning 2, 1–127 (2009)">
            9
           </a>
           ,
           <a aria-label="Reference 10" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR10" id="ref-link-section-d27533759e561" title="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. Adv. Neural Inf. Process. Syst. 25, 1106–1114 (2012)">
            10
           </a>
           ,
           <a aria-label="Reference 11" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR11" id="ref-link-section-d27533759e564" title="Hinton, G. E. &amp; Salakhutdinov, R. R. Reducing the dimensionality of data with neural networks. Science 313, 504–507 (2006)">
            11
           </a>
          </sup>
          to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games
          <sup>
           <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR12" id="ref-link-section-d27533759e568" title="Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents. J. Artif. Intell. Res. 47, 253–279 (2013)">
            12
           </a>
          </sup>
          . We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.
         </p>
        </div>
       </div>
      </section>
      <noscript>
       <div class="c-nature-box c-nature-box--side" data-component="entitlement-box">
        <p class="c-nature-box__text js-text">
         You have full access to this article via your institution.
        </p>
        <div class="c-pdf-download u-clear-both js-pdf-download">
         <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature14236.pdf">
          <span class="c-pdf-download__text">
           Download PDF
          </span>
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
           <use xlink:href="#icon-download">
           </use>
          </svg>
         </a>
        </div>
       </div>
      </noscript>
      <div class="js-context-bar-sticky-point-mobile">
       <div aria-hidden="true" class="c-nature-box c-nature-box--side u-display-none u-hide-print" data-component="entitlement-box" id="entitlement-box-entitled-mobile">
        <p aria-hidden="true" class="c-nature-box__text js-text u-display-none">
         You have full access to this article via
         <strong>
          Ohio State University Libraries
         </strong>
        </p>
        <div class="c-pdf-download u-clear-both js-pdf-download">
         <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature14236.pdf">
          <span class="c-pdf-download__text">
           Download PDF
          </span>
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
           <use xlink:href="#icon-download">
           </use>
          </svg>
         </a>
        </div>
       </div>
      </div>
      <div class="main-content">
       <section data-title="Main">
        <div class="c-article-section" id="Sec1-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">
          Main
         </h2>
         <div class="c-article-section__content" id="Sec1-content">
          <p>
           We set out to create a single algorithm that would be able to develop a wide range of competencies on a varied range of challenging tasks—a central goal of general artificial intelligence
           <sup>
            <a aria-label="Reference 13" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR13" id="ref-link-section-d27533759e604" title="Legg, S. &amp; Hutter, M. Universal Intelligence: a definition of machine intelligence. Minds Mach. 17, 391–444 (2007)">
             13
            </a>
           </sup>
           that has eluded previous efforts
           <sup>
            <a aria-label="Reference 8" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR8" id="ref-link-section-d27533759e608" title="Diuk, C., Cohen, A. &amp; Littman, M. L. An object-oriented representation for efficient reinforcement learning. Proc. Int. Conf. Mach. Learn. 240–247 (2008)">
             8
            </a>
            ,
            <a aria-label="Reference 14" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR14" id="ref-link-section-d27533759e611" title="Genesereth, M., Love, N. &amp; Pell, B. General game playing: overview of the AAAI competition. AI Mag. 26, 62–72 (2005)">
             14
            </a>
            ,
            <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e614" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
             15
            </a>
           </sup>
           . To achieve this, we developed a novel agent, a deep Q-network (DQN), which is able to combine reinforcement learning with a class of artificial neural network
           <sup>
            <a aria-label="Reference 16" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR16" id="ref-link-section-d27533759e618" title="McClelland, J. L., Rumelhart, D. E. &amp; Group, T. P. R. Parallel Distributed Processing: Explorations in the Microstructure of Cognition (MIT Press, 1986)">
             16
            </a>
           </sup>
           known as deep neural networks. Notably, recent advances in deep neural networks
           <sup>
            <a aria-label="Reference 9" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR9" id="ref-link-section-d27533759e622" title="Bengio, Y. Learning deep architectures for AI. Foundations and Trends in Machine Learning 2, 1–127 (2009)">
             9
            </a>
            ,
            <a aria-label="Reference 10" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR10" id="ref-link-section-d27533759e625" title="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks. Adv. Neural Inf. Process. Syst. 25, 1106–1114 (2012)">
             10
            </a>
            ,
            <a aria-label="Reference 11" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR11" id="ref-link-section-d27533759e628" title="Hinton, G. E. &amp; Salakhutdinov, R. R. Reducing the dimensionality of data with neural networks. Science 313, 504–507 (2006)">
             11
            </a>
           </sup>
           , in which several layers of nodes are used to build up progressively more abstract representations of the data, have made it possible for artificial neural networks to learn concepts such as object categories directly from raw sensory data. We use one particularly successful architecture, the deep convolutional network
           <sup>
            <a aria-label="Reference 17" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR17" id="ref-link-section-d27533759e632" title="LeCun, Y., Bottou, L., Bengio, Y. &amp; Haffner, P. Gradient-based learning applied to document recognition. Proc. IEEE 86, 2278–2324 (1998)">
             17
            </a>
           </sup>
           , which uses hierarchical layers of tiled convolutional filters to mimic the effects of receptive fields—inspired by Hubel and Wiesel’s seminal work on feedforward processing in early visual cortex
           <sup>
            <a aria-label="Reference 18" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR18" id="ref-link-section-d27533759e637" title="Hubel, D. H. &amp; Wiesel, T. N. Shape and arrangement of columns in cat’s striate cortex. J. Physiol. 165, 559–568 (1963)">
             18
            </a>
           </sup>
           —thereby exploiting the local spatial correlations present in images, and building in robustness to natural transformations such as changes of viewpoint or scale.
          </p>
          <p>
           We consider tasks in which the agent interacts with an environment through a sequence of observations, actions and rewards. The goal of the agent is to select actions in a fashion that maximizes cumulative future reward. More formally, we use a deep convolutional neural network to approximate the optimal action-value function
          </p>
          <div class="c-article-equation" id="Equ1">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw365/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Equ1_HTML.jpg"/>
           </div>
          </div>
          <p>
           which is the maximum sum of rewards
           <i>
            r
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           discounted by
           <i>
            γ
           </i>
           at each time-step
           <i>
            t
           </i>
           , achievable by a behaviour policy
           <i>
            π = P
           </i>
           (
           <i>
            a|s
           </i>
           ), after making an observation (
           <i>
            s
           </i>
           ) and taking an action (
           <i>
            a
           </i>
           ) (see Methods)
           <sup>
            <a aria-label="Reference 19" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR19" id="ref-link-section-d27533759e677" title="Watkins, C. J. &amp; Dayan, P. Q-learning. Mach. Learn. 8, 279–292 (1992)">
             19
            </a>
           </sup>
           .
          </p>
          <p>
           Reinforcement learning is known to be unstable or even to diverge when a nonlinear function approximator such as a neural network is used to represent the action-value (also known as
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw13/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq1_HTML.jpg" style="width:13px;max-width:none;"/>
           ) function
           <sup>
            <a aria-label="Reference 20" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR20" id="ref-link-section-d27533759e692" title="Tsitsiklis, J. &amp; Roy, B. V. An analysis of temporal-difference learning with function approximation. IEEE Trans. Automat. Contr. 42, 674–690 (1997)">
             20
            </a>
           </sup>
           . This instability has several causes: the correlations present in the sequence of observations, the fact that small updates to
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw12/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq2_HTML.jpg" style="width:12px;max-width:none;"/>
           may significantly change the policy and therefore change the data distribution, and the correlations between the action-values (
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw13/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq3_HTML.jpg" style="width:13px;max-width:none;"/>
           ) and the target values
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw129/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq4_HTML.jpg" style="width:129px;max-width:none;"/>
           . We address these instabilities with a novel variant of Q-learning, which uses two key ideas. First, we used a biologically inspired mechanism termed experience replay
           <sup>
            <a aria-label="Reference 21" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR21" id="ref-link-section-d27533759e721" title="McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychol. Rev. 102, 419–457 (1995)">
             21
            </a>
            ,
            <a aria-label="Reference 22" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR22" id="ref-link-section-d27533759e724" title="O’Neill, J., Pleydell-Bouverie, B., Dupret, D. &amp; Csicsvari, J. Play it again: reactivation of waking experience and memory. Trends Neurosci. 33, 220–229 (2010)">
             22
            </a>
            ,
            <a aria-label="Reference 23" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR23" id="ref-link-section-d27533759e727" title="Lin, L.-J. Reinforcement learning for robots using neural networks. Technical Report, DTIC Document. (1993)">
             23
            </a>
           </sup>
           that randomizes over the data, thereby removing correlations in the observation sequence and smoothing over changes in the data distribution (see below for details). Second, we used an iterative update that adjusts the action-values (
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw13/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq5_HTML.jpg" style="width:13px;max-width:none;"/>
           ) towards target values that are only periodically updated, thereby reducing correlations with the target.
          </p>
          <p>
           While other stable methods exist for training neural networks in the reinforcement learning setting, such as neural fitted Q-iteration
           <sup>
            <a aria-label="Reference 24" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR24" id="ref-link-section-d27533759e742" title="Riedmiller, M. Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method. Mach. Learn.: ECML 3720, 317–328 (Springer, 2005)">
             24
            </a>
           </sup>
           , these methods involve the repeated training of networks
           <i>
            de novo
           </i>
           on hundreds of iterations. Consequently, these methods, unlike our algorithm, are too inefficient to be used successfully with large neural networks. We parameterize an approximate value function
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw60/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq6_HTML.jpg" style="width:60px;max-width:none;"/>
           using the deep convolutional neural network shown in
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig1">
            Fig. 1
           </a>
           , in which
           <i>
            θ
           </i>
           <sub>
            i
           </sub>
           are the parameters (that is, weights) of the Q-network at iteration
           <i>
            i
           </i>
           . To perform experience replay we store the agent’s experiences
           <i>
            e
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           = (
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            r
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           <sub>
            + 1
           </sub>
           ) at each time-step
           <i>
            t
           </i>
           in a data set
           <i>
            D
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           = {
           <i>
            e
           </i>
           <sub>
            1
           </sub>
           ,…,
           <i>
            e
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           }. During learning, we apply Q-learning updates, on samples (or minibatches) of experience (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ,
           <i>
            r
           </i>
           ,
           <i>
            s′
           </i>
           )
           <span class="stix">
            ∼
           </span>
           <i>
            U
           </i>
           (
           <i>
            D
           </i>
           ), drawn uniformly at random from the pool of stored samples. The Q-learning update at iteration
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw5/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq7_HTML.jpg" style="width:5px;max-width:none;"/>
           uses the following loss function:
          </p>
          <div class="c-article-equation" id="Equ2">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw382/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Equ2_HTML.jpg"/>
           </div>
          </div>
          <p>
           in which
           <i>
            γ
           </i>
           is the discount factor determining the agent’s horizon,
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           are the parameters of the Q-network at iteration
           <i>
            i
           </i>
           and
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq8_HTML.jpg" style="width:19px;max-width:none;"/>
           are the network parameters used to compute the target at iteration
           <i>
            i
           </i>
           . The target network parameters
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw19/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq9_HTML.jpg" style="width:19px;max-width:none;"/>
           are only updated with the Q-network parameters (
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           ) every
           <i>
            C
           </i>
           steps and are held fixed between individual updates (see Methods).
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Schematic illustration of the convolutional neural network." id="figure-1">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig1">
              Figure 1: Schematic illustration of the convolutional neural network.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature14236/figures/1" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 1" aria-describedby="Fig1" height="392" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc">
              <p>
               The details of the architecture are explained in the Methods. The input to the neural network consists of an 84 × 84 × 4 image produced by the preprocessing map
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw8/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq55_HTML.jpg" style="width:8px;max-width:none;"/>
               , followed by three convolutional layers (note: snaking blue line symbolizes sliding of each filter across input image) and two fully connected layers with a single output for each valid action. Each hidden layer is followed by a rectifier nonlinearity (that is,
               <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw58/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq56_HTML.jpg" style="width:58px;max-width:none;"/>
               ).
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature14236#MOESM118">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 1" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure1 Full size image" data-track-label="button" href="/articles/nature14236/figures/1" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           To evaluate our DQN agent, we took advantage of the Atari 2600 platform, which offers a diverse array of tasks (
           <i>
            n
           </i>
           = 49) designed to be difficult and engaging for human players. We used the same network architecture, hyperparameter values (see
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab1">
            Extended Data Table 1
           </a>
           ) and learning procedure throughout—taking high-dimensional data (
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw67/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq10_HTML.jpg" style="width:67px;max-width:none;"/>
           colour video at 60 Hz) as input—to demonstrate that our approach robustly learns successful policies over a variety of games based solely on sensory inputs with only very minimal prior knowledge (that is, merely the input data were visual images, and the number of actions available in each game, but not their correspondences; see Methods). Notably, our method was able to train large neural networks using a reinforcement learning signal and stochastic gradient descent in a stable manner— illustrated by the temporal evolution of two indices of learning (the agent’s average score-per-episode and average predicted Q-values; see
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig2">
            Fig. 2
           </a>
           and Supplementary Discussion for details).
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Training curves tracking the agent’s average score and average predicted action-value." id="figure-2">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig2">
              Figure 2: Training curves tracking the agent’s average score and average predicted action-value.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature14236/figures/2" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig2_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 2" aria-describedby="Fig2" height="492" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig2_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc">
              <p>
               <b>
                a
               </b>
               , Each point is the average score achieved per episode after the agent is run with
               <i>
                ε
               </i>
               -greedy policy (
               <i>
                ε
               </i>
               = 0.05) for 520 k frames on Space Invaders.
               <b>
                b
               </b>
               , Average score achieved per episode for Seaquest.
               <b>
                c
               </b>
               , Average predicted action-value on a held-out set of states on Space Invaders. Each point on the curve is the average of the action-value Q computed over the held-out set of states. Note that Q-values are scaled due to clipping of rewards (see Methods).
               <b>
                d
               </b>
               , Average predicted action-value on Seaquest. See Supplementary Discussion for details.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature14236#MOESM119">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 2" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure2 Full size image" data-track-label="button" href="/articles/nature14236/figures/2" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           We compared DQN with the best performing methods from the reinforcement learning literature on the 49 games where results were available
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR12" id="ref-link-section-d27533759e1006" title="Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents. J. Artif. Intell. Res. 47, 253–279 (2013)">
             12
            </a>
            ,
            <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e1009" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
             15
            </a>
           </sup>
           . In addition to the learned agents, we also report scores for a professional human games tester playing under controlled conditions and a policy that selects actions uniformly at random (
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab2">
            Extended Data Table 2
           </a>
           and
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig3">
            Fig. 3
           </a>
           , denoted by 100% (human) and 0% (random) on
           <i>
            y
           </i>
           axis; see Methods). Our DQN method outperforms the best existing reinforcement learning methods on 43 of the games without incorporating any of the additional prior knowledge about Atari 2600 games used by other approaches (for example, refs
           <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR12" id="ref-link-section-d27533759e1021" title="Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents. J. Artif. Intell. Res. 47, 253–279 (2013)">
            12
           </a>
           ,
           <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e1025" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
            15
           </a>
           ). Furthermore, our DQN agent performed at a level that was comparable to that of a professional human games tester across the set of 49 games, achieving more than 75% of the human score on more than half of the games (29 games; see
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig3">
            Fig. 3
           </a>
           , Supplementary Discussion and
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab2">
            Extended Data Table 2
           </a>
           ). In additional simulations (see Supplementary Discussion and
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab3">
            Extended Data Tables 3
           </a>
           and
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab4">
            4
           </a>
           ), we demonstrate the importance of the individual core components of the DQN agent—the replay memory, separate target Q-network and deep convolutional network architecture—by disabling them and demonstrating the detrimental effects on performance.
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Comparison of the DQN agent with the best reinforcement learning methods15 in the literature." id="figure-3">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig3">
              Figure 3: Comparison of the DQN agent with the best reinforcement learning methods
              <sup>
               <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e1051" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
                15
               </a>
              </sup>
              in the literature.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature14236/figures/3" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig3_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 3" aria-describedby="Fig3" height="860" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig3_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc">
              <p>
               The performance of DQN is normalized with respect to a professional human games tester (that is, 100% level) and random play (that is, 0% level). Note that the normalized performance of DQN, expressed as a percentage, is calculated as: 100 × (DQN score − random play score)/(human score − random play score). It can be seen that DQN outperforms competing methods (also see
               <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab2">
                Extended Data Table 2
               </a>
               ) in almost all the games, and performs at a level that is broadly comparable with or superior to a professional human games tester (that is, operationalized as a level of 75% or above) in the majority of games. Audio output was disabled for both human players and agents. Error bars indicate s.d. across the 30 evaluation episodes, starting with different initial conditions.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature14236#MOESM120">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 3" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure3 Full size image" data-track-label="button" href="/articles/nature14236/figures/3" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           We next examined the representations learned by DQN that underpinned the successful performance of the agent in the context of the game Space Invaders (see
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature14236#MOESM123">
            Supplementary Video 1
           </a>
           for a demonstration of the performance of DQN), by using a technique developed for the visualization of high-dimensional data called ‘t-SNE’
           <sup>
            <a aria-label="Reference 25" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR25" id="ref-link-section-d27533759e1081" title="Van der Maaten, L. J. P. &amp; Hinton, G. E. Visualizing high-dimensional data using t-SNE. J. Mach. Learn. Res. 9, 2579–2605 (2008)">
             25
            </a>
           </sup>
           (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig4">
            Fig. 4
           </a>
           ). As expected, the t-SNE algorithm tends to map the DQN representation of perceptually similar states to nearby points. Interestingly, we also found instances in which the t-SNE algorithm generated similar embeddings for DQN representations of states that are close in terms of expected reward but perceptually dissimilar (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig4">
            Fig. 4
           </a>
           , bottom right, top left and middle), consistent with the notion that the network is able to learn representations that support adaptive behaviour from high-dimensional sensory inputs. Furthermore, we also show that the representations learned by DQN are able to generalize to data generated from policies other than its own—in simulations where we presented as input to the network game states experienced during human and agent play, recorded the representations of the last hidden layer, and visualized the embeddings generated by the t-SNE algorithm (
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig5">
            Extended Data Fig. 1
           </a>
           and Supplementary Discussion).
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig6">
            Extended Data Fig. 2
           </a>
           provides an additional illustration of how the representations learned by DQN allow it to accurately predict state and action values.
          </p>
          <div class="c-article-section__figure js-c-reading-companion-figures-item" data-container-section="figure" data-test="figure" data-title="Two-dimensional t-SNE embedding of the representations in the last hidden layer assigned by DQN to game states experienced while playing Space Invaders." id="figure-4">
           <figure>
            <figcaption>
             <b class="c-article-section__figure-caption" data-test="figure-caption-text" id="Fig4">
              Figure 4: Two-dimensional t-SNE embedding of the representations in the last hidden layer assigned by DQN to game states experienced while playing Space Invaders.
             </b>
            </figcaption>
            <div class="c-article-section__figure-content">
             <div class="c-article-section__figure-item">
              <a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-action="view figure" data-track-label="image" href="/articles/nature14236/figures/4" rel="nofollow">
               <picture>
                <source srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig4_HTML.jpg?as=webp" type="image/webp"/>
                <img alt="figure 4" aria-describedby="Fig4" height="569" loading="lazy" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig4_HTML.jpg" width="685"/>
               </picture>
              </a>
             </div>
             <div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc">
              <p>
               The plot was generated by letting the DQN agent play for 2 h of real game time and running the t-SNE algorithm
               <sup>
                <a aria-label="Reference 25" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR25" id="ref-link-section-d27533759e1110" title="Van der Maaten, L. J. P. &amp; Hinton, G. E. Visualizing high-dimensional data using t-SNE. J. Mach. Learn. Res. 9, 2579–2605 (2008)">
                 25
                </a>
               </sup>
               on the last hidden layer representations assigned by DQN to each experienced game state. The points are coloured according to the state values (
               <i>
                V
               </i>
               , maximum expected reward of a state) predicted by DQN for the corresponding game states (ranging from dark red (highest
               <i>
                V
               </i>
               ) to dark blue (lowest
               <i>
                V
               </i>
               )). The screenshots corresponding to a selected number of points are shown. The DQN agent predicts high state values for both full (top right screenshots) and nearly complete screens (bottom left screenshots) because it has learned that completing a screen leads to a new screen full of enemy ships. Partially completed screens (bottom screenshots) are assigned lower state values because less immediate reward is available. The screens shown on the bottom right and top left and middle are less perceptually similar than the other examples but are still mapped to nearby representations and similar values because the orange bunkers do not carry great significance near the end of a level. With permission from Square Enix Limited.
              </p>
              <p>
               <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature14236#MOESM121">
                PowerPoint slide
               </a>
              </p>
             </div>
            </div>
            <div class="u-text-right u-hide-print">
             <a aria-label="Full size image figure 4" class="c-article__pill-button" data-test="article-link" data-track="click" data-track-action="view figure" data-track-dest="link:Figure4 Full size image" data-track-label="button" href="/articles/nature14236/figures/4" rel="nofollow">
              <span>
               Full size image
              </span>
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </div>
           </figure>
          </div>
          <p>
           It is worth noting that the games in which DQN excels are extremely varied in their nature, from side-scrolling shooters (River Raid) to boxing games (Boxing) and three-dimensional car-racing games (Enduro). Indeed, in certain games DQN is able to discover a relatively long-term strategy (for example, Breakout: the agent learns the optimal strategy, which is to first dig a tunnel around the side of the wall allowing the ball to be sent around the back to destroy a large number of blocks; see
           <a data-track="click" data-track-action="supplementary material anchor" data-track-label="link" href="/articles/nature14236#MOESM124">
            Supplementary Video 2
           </a>
           for illustration of development of DQN’s performance over the course of training). Nevertheless, games demanding more temporally extended planning strategies still constitute a major challenge for all existing agents including DQN (for example, Montezuma’s Revenge).
          </p>
          <p>
           In this work, we demonstrate that a single architecture can successfully learn control policies in a range of different environments with only very minimal prior knowledge, receiving only the pixels and the game score as inputs, and using the same algorithm, network architecture and hyperparameters on each game, privy only to the inputs a human player would have. In contrast to previous work
           <sup>
            <a aria-label="Reference 24" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR24" id="ref-link-section-d27533759e1146" title="Riedmiller, M. Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method. Mach. Learn.: ECML 3720, 317–328 (Springer, 2005)">
             24
            </a>
            ,
            <a aria-label="Reference 26" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR26" id="ref-link-section-d27533759e1149" title="Lange, S. &amp; Riedmiller, M. Deep auto-encoder neural networks in reinforcement learning. Proc. Int. Jt. Conf. Neural. Netw. 1–8 (2010)">
             26
            </a>
           </sup>
           , our approach incorporates ‘end-to-end’ reinforcement learning that uses reward to continuously shape representations within the convolutional network towards salient features of the environment that facilitate value estimation. This principle draws on neurobiological evidence that reward signals during perceptual learning may influence the characteristics of representations within primate visual cortex
           <sup>
            <a aria-label="Reference 27" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR27" id="ref-link-section-d27533759e1153" title="Law, C.-T. &amp; Gold, J. I. Reinforcement learning can account for associative and perceptual learning on a visual decision task. Nature Neurosci. 12, 655 (2009)">
             27
            </a>
            ,
            <a aria-label="Reference 28" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR28" id="ref-link-section-d27533759e1156" title="Sigala, N. &amp; Logothetis, N. K. Visual categorization shapes feature selectivity in the primate temporal cortex. Nature 415, 318–320 (2002)">
             28
            </a>
           </sup>
           . Notably, the successful integration of reinforcement learning with deep network architectures was critically dependent on our incorporation of a replay algorithm
           <sup>
            <a aria-label="Reference 21" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR21" id="ref-link-section-d27533759e1160" title="McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychol. Rev. 102, 419–457 (1995)">
             21
            </a>
            ,
            <a aria-label="Reference 22" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR22" id="ref-link-section-d27533759e1163" title="O’Neill, J., Pleydell-Bouverie, B., Dupret, D. &amp; Csicsvari, J. Play it again: reactivation of waking experience and memory. Trends Neurosci. 33, 220–229 (2010)">
             22
            </a>
            ,
            <a aria-label="Reference 23" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR23" id="ref-link-section-d27533759e1166" title="Lin, L.-J. Reinforcement learning for robots using neural networks. Technical Report, DTIC Document. (1993)">
             23
            </a>
           </sup>
           involving the storage and representation of recently experienced transitions. Convergent evidence suggests that the hippocampus may support the physical realization of such a process in the mammalian brain, with the time-compressed reactivation of recently experienced trajectories during offline periods
           <sup>
            <a aria-label="Reference 21" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR21" id="ref-link-section-d27533759e1170" title="McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychol. Rev. 102, 419–457 (1995)">
             21
            </a>
            ,
            <a aria-label="Reference 22" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR22" id="ref-link-section-d27533759e1173" title="O’Neill, J., Pleydell-Bouverie, B., Dupret, D. &amp; Csicsvari, J. Play it again: reactivation of waking experience and memory. Trends Neurosci. 33, 220–229 (2010)">
             22
            </a>
           </sup>
           (for example, waking rest) providing a putative mechanism by which value functions may be efficiently updated through interactions with the basal ganglia
           <sup>
            <a aria-label="Reference 22" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR22" id="ref-link-section-d27533759e1177" title="O’Neill, J., Pleydell-Bouverie, B., Dupret, D. &amp; Csicsvari, J. Play it again: reactivation of waking experience and memory. Trends Neurosci. 33, 220–229 (2010)">
             22
            </a>
           </sup>
           . In the future, it will be important to explore the potential use of biasing the content of experience replay towards salient events, a phenomenon that characterizes empirically observed hippocampal replay
           <sup>
            <a aria-label="Reference 29" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR29" id="ref-link-section-d27533759e1182" title="Bendor, D. &amp; Wilson, M. A. Biasing the content of hippocampal replay during sleep. Nature Neurosci. 15, 1439–1444 (2012)">
             29
            </a>
           </sup>
           , and relates to the notion of ‘prioritized sweeping’
           <sup>
            <a aria-label="Reference 30" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR30" id="ref-link-section-d27533759e1186" title="Moore, A. &amp; Atkeson, C. Prioritized sweeping: reinforcement learning with less data and less real time. Mach. Learn. 13, 103–130 (1993)">
             30
            </a>
           </sup>
           in reinforcement learning. Taken together, our work illustrates the power of harnessing state-of-the-art machine learning techniques with biologically inspired mechanisms to create agents that are capable of learning to master a diverse array of challenging tasks.
          </p>
         </div>
        </div>
       </section>
       <section data-title="Methods">
        <div class="c-article-section" id="Sec2-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">
          Methods
         </h2>
         <div class="c-article-section__content" id="Sec2-content">
          <h3 class="c-article__sub-heading" id="Sec3">
           Preprocessing
          </h3>
          <p>
           Working directly with raw Atari 2600 frames, which are 210 × 160 pixel images with a 128-colour palette, can be demanding in terms of computation and memory requirements. We apply a basic preprocessing step aimed at reducing the input dimensionality and dealing with some artefacts of the Atari 2600 emulator. First, to encode a single frame we take the maximum value for each pixel colour value over the frame being encoded and the previous frame. This was necessary to remove flickering that is present in games where some objects appear only in even frames while other objects appear only in odd frames, an artefact caused by the limited number of sprites Atari 2600 can display at once. Second, we then extract the Y channel, also known as luminance, from the RGB frame and rescale it to 84 × 84. The function
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw8/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq11_HTML.jpg" style="width:8px;max-width:none;"/>
           from algorithm 1 described below applies this preprocessing to the
           <i>
            m
           </i>
           most recent frames and stacks them to produce the input to the Q-function, in which
           <i>
            m
           </i>
           = 4, although the algorithm is robust to different values of
           <i>
            m
           </i>
           (for example, 3 or 5).
          </p>
          <h3 class="c-article__sub-heading" id="Sec4">
           Code availability
          </h3>
          <p>
           The source code can be accessed at
           <a href="https://sites-google-com.proxy.lib.ohio-state.edu/a/deepmind.com/dqn">
            https://sites-google-com.proxy.lib.ohio-state.edu/a/deepmind.com/dqn
           </a>
           for non-commercial uses only.
          </p>
          <h3 class="c-article__sub-heading" id="Sec5">
           Model architecture
          </h3>
          <p>
           There are several possible ways of parameterizing Q using a neural network. Because Q maps history–action pairs to scalar estimates of their Q-value, the history and the action have been used as inputs to the neural network by some previous approaches
           <sup>
            <a aria-label="Reference 24" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR24" id="ref-link-section-d27533759e1242" title="Riedmiller, M. Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method. Mach. Learn.: ECML 3720, 317–328 (Springer, 2005)">
             24
            </a>
            ,
            <a aria-label="Reference 26" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR26" id="ref-link-section-d27533759e1245" title="Lange, S. &amp; Riedmiller, M. Deep auto-encoder neural networks in reinforcement learning. Proc. Int. Jt. Conf. Neural. Netw. 1–8 (2010)">
             26
            </a>
           </sup>
           . The main drawback of this type of architecture is that a separate forward pass is required to compute the Q-value of each action, resulting in a cost that scales linearly with the number of actions. We instead use an architecture in which there is a separate output unit for each possible action, and only the state representation is an input to the neural network. The outputs correspond to the predicted Q-values of the individual actions for the input state. The main advantage of this type of architecture is the ability to compute Q-values for all possible actions in a given state with only a single forward pass through the network.
          </p>
          <p>
           The exact architecture, shown schematically in
           <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="/articles/nature14236#Fig1">
            Fig. 1
           </a>
           , is as follows. The input to the neural network consists of an 84 × 84 × 4 image produced by the preprocessing map
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw8/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq12_HTML.jpg" style="width:8px;max-width:none;"/>
           . The first hidden layer convolves 32 filters of 8 × 8 with stride 4 with the input image and applies a rectifier nonlinearity
           <sup>
            <a aria-label="Reference 31" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR31" id="ref-link-section-d27533759e1263" title="Jarrett, K., Kavukcuoglu, K., Ranzato, M. A. &amp; LeCun, Y. What is the best multi-stage architecture for object recognition? Proc. IEEE. Int. Conf. Comput. Vis. 2146–2153 (2009)">
             31
            </a>
            ,
            <a aria-label="Reference 32" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR32" id="ref-link-section-d27533759e1266" title="Nair, V. &amp; Hinton, G. E. Rectified linear units improve restricted Boltzmann machines. Proc. Int. Conf. Mach. Learn. 807–814 (2010)">
             32
            </a>
           </sup>
           . The second hidden layer convolves 64 filters of 4 × 4 with stride 2, again followed by a rectifier nonlinearity. This is followed by a third convolutional layer that convolves 64 filters of 3 × 3 with stride 1 followed by a rectifier. The final hidden layer is fully-connected and consists of 512 rectifier units. The output layer is a fully-connected linear layer with a single output for each valid action. The number of valid actions varied between 4 and 18 on the games we considered.
          </p>
          <h3 class="c-article__sub-heading" id="Sec6">
           Training details
          </h3>
          <p>
           We performed experiments on 49 Atari 2600 games where results were available for all other comparable methods
           <sup>
            <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR12" id="ref-link-section-d27533759e1278" title="Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents. J. Artif. Intell. Res. 47, 253–279 (2013)">
             12
            </a>
            ,
            <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e1281" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
             15
            </a>
           </sup>
           . A different network was trained on each game: the same network architecture, learning algorithm and hyperparameter settings (see
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab1">
            Extended Data Table 1
           </a>
           ) were used across all games, showing that our approach is robust enough to work on a variety of games while incorporating only minimal prior knowledge (see below). While we evaluated our agents on unmodified games, we made one change to the reward structure of the games during training only. As the scale of scores varies greatly from game to game, we clipped all positive rewards at 1 and all negative rewards at −1, leaving 0 rewards unchanged. Clipping the rewards in this manner limits the scale of the error derivatives and makes it easier to use the same learning rate across multiple games. At the same time, it could affect the performance of our agent since it cannot differentiate between rewards of different magnitude. For games where there is a life counter, the Atari 2600 emulator also sends the number of lives left in the game, which is then used to mark the end of an episode during training.
          </p>
          <p>
           In these experiments, we used the RMSProp (see
           <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">
            http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf
           </a>
           ) algorithm with minibatches of size 32. The behaviour policy during training was
           <i>
            ε
           </i>
           -greedy with
           <i>
            ε
           </i>
           annealed linearly from 1.0 to 0.1 over the first million frames, and fixed at 0.1 thereafter. We trained for a total of 50 million frames (that is, around 38 days of game experience in total) and used a replay memory of 1 million most recent frames.
          </p>
          <p>
           Following previous approaches to playing Atari 2600 games, we also use a simple frame-skipping technique
           <sup>
            <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e1307" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
             15
            </a>
           </sup>
           . More precisely, the agent sees and selects actions on every
           <i>
            k
           </i>
           th frame instead of every frame, and its last action is repeated on skipped frames. Because running the emulator forward for one step requires much less computation than having the agent select an action, this technique allows the agent to play roughly
           <i>
            k
           </i>
           times more games without significantly increasing the runtime. We use
           <i>
            k
           </i>
           = 4 for all games.
          </p>
          <p>
           The values of all the hyperparameters and optimization parameters were selected by performing an informal search on the games Pong, Breakout, Seaquest, Space Invaders and Beam Rider. We did not perform a systematic grid search owing to the high computational cost. These parameters were then held fixed across all other games. The values and descriptions of all hyperparameters are provided in
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab1">
            Extended Data Table 1
           </a>
           .
          </p>
          <p>
           Our experimental setup amounts to using the following minimal prior knowledge: that the input data consisted of visual images (motivating our use of a convolutional deep network), the game-specific score (with no modification), number of actions, although not their correspondences (for example, specification of the up ‘button’) and the life count.
          </p>
          <h3 class="c-article__sub-heading" id="Sec7">
           Evaluation procedure
          </h3>
          <p>
           The trained agents were evaluated by playing each game 30 times for up to 5 min each time with different initial random conditions (‘no-op’; see
           <a data-track="click" data-track-action="table anchor" data-track-label="link" href="/articles/nature14236#Tab1">
            Extended Data Table 1
           </a>
           ) and an
           <i>
            ε
           </i>
           -greedy policy with
           <i>
            ε
           </i>
           = 0.05. This procedure is adopted to minimize the possibility of overfitting during evaluation. The random agent served as a baseline comparison and chose a random action at 10 Hz which is every sixth frame, repeating its last action on intervening frames. 10 Hz is about the fastest that a human player can select the ‘fire’ button, and setting the random agent to this frequency avoids spurious baseline scores in a handful of the games. We did also assess the performance of a random agent that selected an action at 60 Hz (that is, every frame). This had a minimal effect: changing the normalized DQN performance by more than 5% in only six games (Boxing, Breakout, Crazy Climber, Demon Attack, Krull and Robotank), and in all these games DQN outperformed the expert human by a considerable margin.
          </p>
          <p>
           The professional human tester used the same emulator engine as the agents, and played under controlled conditions. The human tester was not allowed to pause, save or reload games. As in the original Atari 2600 environment, the emulator was run at 60 Hz and the audio output was disabled: as such, the sensory input was equated between human player and agents. The human performance is the average reward achieved from around 20 episodes of each game lasting a maximum of 5 min each, following around 2 h of practice playing each game.
          </p>
          <h3 class="c-article__sub-heading" id="Sec8">
           Algorithm
          </h3>
          <p>
           We consider tasks in which an agent interacts with an environment, in this case the Atari emulator, in a sequence of actions, observations and rewards. At each time-step the agent selects an action
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw12/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq13_HTML.jpg" style="width:12px;max-width:none;"/>
           from the set of legal game actions,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw92/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq14_HTML.jpg" style="width:92px;max-width:none;"/>
           . The action is passed to the emulator and modifies its internal state and the game score. In general the environment may be stochastic. The emulator’s internal state is not observed by the agent; instead the agent observes an image
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw37/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq15_HTML.jpg" style="width:37px;max-width:none;"/>
           from the emulator, which is a vector of pixel values representing the current screen. In addition it receives a reward
           <i>
            r
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           representing the change in game score. Note that in general the game score may depend on the whole previous sequence of actions and observations; feedback about an action may only be received after many thousands of time-steps have elapsed.
          </p>
          <p>
           Because the agent only observes the current screen, the task is partially observed
           <sup>
            <a aria-label="Reference 33" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR33" id="ref-link-section-d27533759e1390" title="Kaelbling, L. P., Littman, M. L. &amp; Cassandra, A. R. Planning and acting in partially observable stochastic domains. Artificial Intelligence 101, 99–134 (1994)">
             33
            </a>
           </sup>
           and many emulator states are perceptually aliased (that is, it is impossible to fully understand the current situation from only the current screen
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw12/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq16_HTML.jpg" style="width:12px;max-width:none;"/>
           ). Therefore, sequences of actions and observations,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw139/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq17_HTML.jpg" style="width:139px;max-width:none;"/>
           , are input to the algorithm, which then learns game strategies depending upon these sequences. All sequences in the emulator are assumed to terminate in a finite number of time-steps. This formalism gives rise to a large but finite Markov decision process (MDP) in which each sequence is a distinct state. As a result, we can apply standard reinforcement learning methods for MDPs, simply by using the complete sequence
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           as the state representation at time
           <i>
            t
           </i>
           .
          </p>
          <p>
           The goal of the agent is to interact with the emulator by selecting actions in a way that maximizes future rewards. We make the standard assumption that future rewards are discounted by a factor of
           <i>
            γ
           </i>
           per time-step (
           <i>
            γ
           </i>
           was set to 0.99 throughout), and define the future discounted return at time
           <i>
            t
           </i>
           as
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw97/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq18_HTML.jpg" style="width:97px;max-width:none;"/>
           , in which
           <i>
            T
           </i>
           is the time-step at which the game terminates. We define the optimal action-value function
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw45/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq19_HTML.jpg" style="width:45px;max-width:none;"/>
           as the maximum expected return achievable by following any policy, after seeing some sequence
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw6/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq20_HTML.jpg" style="width:6px;max-width:none;"/>
           and then taking some action
           <i>
            a
           </i>
           ,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw183/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq21_HTML.jpg" style="width:183px;max-width:none;"/>
           in which
           <i>
            π
           </i>
           is a policy mapping sequences to actions (or distributions over actions).
          </p>
          <p>
           The optimal action-value function obeys an important identity known as the Bellman equation. This is based on the following intuition: if the optimal value
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw53/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq22_HTML.jpg" style="width:53px;max-width:none;"/>
           of the sequence
           <i>
            s′
           </i>
           at the next time-step was known for all possible actions
           <i>
            a′
           </i>
           , then the optimal strategy is to select the action
           <i>
            a′
           </i>
           maximizing the expected value of
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw82/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq23_HTML.jpg" style="width:82px;max-width:none;"/>
           :
          </p>
          <div class="c-article-equation" id="Equ3">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw209/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Equ3_HTML.jpg"/>
           </div>
          </div>
          <p>
           The basic idea behind many reinforcement learning algorithms is to estimate the action-value function by using the Bellman equation as an iterative update,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw209/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq24_HTML.jpg" style="width:209px;max-width:none;"/>
           . Such value iteration algorithms converge to the optimal action-value function,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw47/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq25_HTML.jpg" style="width:47px;max-width:none;"/>
           as
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw33/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq26_HTML.jpg" style="width:33px;max-width:none;"/>
           . In practice, this basic approach is impractical, because the action-value function is estimated separately for each sequence, without any generalization. Instead, it is common to use a function approximator to estimate the action-value function,
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw113/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq27_HTML.jpg" style="width:113px;max-width:none;"/>
           . In the reinforcement learning community this is typically a linear function approximator, but sometimes a nonlinear function approximator is used instead, such as a neural network. We refer to a neural network function approximator with weights
           <i>
            θ
           </i>
           as a Q-network. A Q-network can be trained by adjusting the parameters
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           at iteration
           <i>
            i
           </i>
           to reduce the mean-squared error in the Bellman equation, where the optimal target values
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw125/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq28_HTML.jpg" style="width:125px;max-width:none;"/>
           are substituted with approximate target values
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw144/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq29_HTML.jpg" style="width:144px;max-width:none;"/>
           , using parameters
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw16/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq30_HTML.jpg" style="width:16px;max-width:none;"/>
           from some previous iteration. This leads to a sequence of loss functions
           <i>
            L
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           (
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           ) that changes at each iteration
           <i>
            i
           </i>
           ,
          </p>
          <div class="c-article-equation" id="Equ4">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw253/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Equ4_HTML.jpg"/>
           </div>
          </div>
          <p>
           Note that the targets depend on the network weights; this is in contrast with the targets used for supervised learning, which are fixed before learning begins. At each stage of optimization, we hold the parameters from the previous iteration
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           <sup>
            −
           </sup>
           fixed when optimizing the
           <i>
            i
           </i>
           th loss function
           <i>
            L
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           (
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           ), resulting in a sequence of well-defined optimization problems. The final term is the variance of the targets, which does not depend on the parameters
           <i>
            θ
           </i>
           <sub>
            <i>
             i
            </i>
           </sub>
           that we are currently optimizing, and may therefore be ignored. Differentiating the loss function with respect to the weights we arrive at the following gradient:
          </p>
          <div class="c-article-equation" id="Equ5">
           <div class="c-article-equation__content">
            <img alt="" class="u-display-block" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw391/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Equ5_HTML.jpg"/>
           </div>
          </div>
          <p>
           Rather than computing the full expectations in the above gradient, it is often computationally expedient to optimize the loss function by stochastic gradient descent. The familiar Q-learning algorithm
           <sup>
            <a aria-label="Reference 19" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR19" id="ref-link-section-d27533759e1647" title="Watkins, C. J. &amp; Dayan, P. Q-learning. Mach. Learn. 8, 279–292 (1992)">
             19
            </a>
           </sup>
           can be recovered in this framework by updating the weights after every time step, replacing the expectations using single samples, and setting
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw60/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq31_HTML.jpg" style="width:60px;max-width:none;"/>
           .
          </p>
          <p>
           Note that this algorithm is model-free: it solves the reinforcement learning task directly using samples from the emulator, without explicitly estimating the reward and transition dynamics
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw59/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq32_HTML.jpg" style="width:59px;max-width:none;"/>
           . It is also off-policy: it learns about the greedy policy
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw135/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq33_HTML.jpg" style="width:135px;max-width:none;"/>
           , while following a behaviour distribution that ensures adequate exploration of the state space. In practice, the behaviour distribution is often selected by an
           <i>
            ε
           </i>
           -greedy policy that follows the greedy policy with probability 1 −
           <i>
            ε
           </i>
           and selects a random action with probability
           <i>
            ε
           </i>
           .
          </p>
          <h3 class="c-article__sub-heading" id="Sec9">
           Training algorithm for deep Q-networks
          </h3>
          <p>
           The full algorithm for training deep Q-networks is presented in Algorithm 1. The agent selects and executes actions according to an
           <i>
            ε
           </i>
           -greedy policy based on
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq34_HTML.jpg" style="width:11px;max-width:none;"/>
           . Because using histories of arbitrary length as inputs to a neural network can be difficult, our Q-function instead works on a fixed length representation of histories produced by the function
           <i>
            ϕ
           </i>
           described above. The algorithm modifies standard online Q-learning in two ways to make it suitable for training large neural networks without diverging.
          </p>
          <p>
           First, we use a technique known as experience replay
           <sup>
            <a aria-label="Reference 23" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR23" id="ref-link-section-d27533759e1712" title="Lin, L.-J. Reinforcement learning for robots using neural networks. Technical Report, DTIC Document. (1993)">
             23
            </a>
           </sup>
           in which we store the agent’s experiences at each time-step,
           <i>
            e
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           = (
           <i>
            s
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            a
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            r
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           ,
           <i>
            s
           </i>
           <sub>
            <i>
             t +
            </i>
           </sub>
           <sub>
            1
           </sub>
           ), in a data set
           <i>
            D
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           = {
           <i>
            e
           </i>
           <sub>
            1
           </sub>
           ,…,
           <i>
            e
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           }, pooled over many episodes (where the end of an episode occurs when a terminal state is reached) into a replay memory. During the inner loop of the algorithm, we apply Q-learning updates, or minibatch updates, to samples of experience, (
           <i>
            s
           </i>
           ,
           <i>
            a
           </i>
           ,
           <i>
            r
           </i>
           ,
           <i>
            s
           </i>
           ′)
           <span class="stix">
            ∼
           </span>
           <i>
            U
           </i>
           (
           <i>
            D
           </i>
           ), drawn at random from the pool of stored samples. This approach has several advantages over standard online Q-learning. First, each step of experience is potentially used in many weight updates, which allows for greater data efficiency. Second, learning directly from consecutive samples is inefficient, owing to the strong correlations between the samples; randomizing the samples breaks these correlations and therefore reduces the variance of the updates. Third, when learning on-policy the current parameters determine the next data sample that the parameters are trained on. For example, if the maximizing action is to move left then the training samples will be dominated by samples from the left-hand side; if the maximizing action then switches to the right then the training distribution will also switch. It is easy to see how unwanted feedback loops may arise and the parameters could get stuck in a poor local minimum, or even diverge catastrophically
           <sup>
            <a aria-label="Reference 20" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR20" id="ref-link-section-d27533759e1784" title="Tsitsiklis, J. &amp; Roy, B. V. An analysis of temporal-difference learning with function approximation. IEEE Trans. Automat. Contr. 42, 674–690 (1997)">
             20
            </a>
           </sup>
           . By using experience replay the behaviour distribution is averaged over many of its previous states, smoothing out learning and avoiding oscillations or divergence in the parameters. Note that when learning by experience replay, it is necessary to learn off-policy (because our current parameters are different to those used to generate the sample), which motivates the choice of Q-learning.
          </p>
          <p>
           In practice, our algorithm only stores the last
           <i>
            N
           </i>
           experience tuples in the replay memory, and samples uniformly at random from
           <i>
            D
           </i>
           when performing updates. This approach is in some respects limited because the memory buffer does not differentiate important transitions and always overwrites with recent transitions owing to the finite memory size
           <i>
            N
           </i>
           . Similarly, the uniform sampling gives equal importance to all transitions in the replay memory. A more sophisticated sampling strategy might emphasize transitions from which we can learn the most, similar to prioritized sweeping
           <sup>
            <a aria-label="Reference 30" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR30" id="ref-link-section-d27533759e1800" title="Moore, A. &amp; Atkeson, C. Prioritized sweeping: reinforcement learning with less data and less real time. Mach. Learn. 13, 103–130 (1993)">
             30
            </a>
           </sup>
           .
          </p>
          <p>
           The second modification to online Q-learning aimed at further improving the stability of our method with neural networks is to use a separate network for generating the targets
           <i>
            y
           </i>
           <sub>
            <i>
             j
            </i>
           </sub>
           in the Q-learning update. More precisely, every
           <i>
            C
           </i>
           updates we clone the network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq35_HTML.jpg" style="width:11px;max-width:none;"/>
           to obtain a target network
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq36_HTML.jpg" style="width:11px;max-width:none;"/>
           and use
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq37_HTML.jpg" style="width:11px;max-width:none;"/>
           for generating the Q-learning targets
           <i>
            y
           </i>
           <sub>
            <i>
             j
            </i>
           </sub>
           for the following
           <i>
            C
           </i>
           updates to
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq38_HTML.jpg" style="width:11px;max-width:none;"/>
           . This modification makes the algorithm more stable compared to standard online Q-learning, where an update that increases
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw43/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq39_HTML.jpg" style="width:43px;max-width:none;"/>
           often also increases
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw58/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq40_HTML.jpg" style="width:58px;max-width:none;"/>
           for all
           <i>
            a
           </i>
           and hence also increases the target
           <i>
            y
           </i>
           <sub>
            <i>
             j
            </i>
           </sub>
           , possibly leading to oscillations or divergence of the policy. Generating the targets using an older set of parameters adds a delay between the time an update to
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq41_HTML.jpg" style="width:11px;max-width:none;"/>
           is made and the time the update affects the targets
           <i>
            y
           </i>
           <sub>
            <i>
             j
            </i>
           </sub>
           , making divergence or oscillations much more unlikely.
          </p>
          <p>
           We also found it helpful to clip the error term from the update
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw189/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq42_HTML.jpg" style="width:189px;max-width:none;"/>
           to be between −1 and 1. Because the absolute value loss function |
           <i>
            x
           </i>
           | has a derivative of −1 for all negative values of
           <i>
            x
           </i>
           and a derivative of 1 for all positive values of
           <i>
            x
           </i>
           , clipping the squared error to be between −1 and 1 corresponds to using an absolute value loss function for errors outside of the (−1,1) interval. This form of error clipping further improved the stability of the algorithm.
          </p>
          <h3 class="c-article__sub-heading" id="Sec10">
           Algorithm 1: deep Q-learning with experience replay
          </h3>
          <p>
           Initialize replay memory
           <i>
            D
           </i>
           to capacity
           <i>
            N
           </i>
          </p>
          <p>
           Initialize action-value function
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq43_HTML.jpg" style="width:11px;max-width:none;"/>
           with random weights
           <i>
            θ
           </i>
          </p>
          <p>
           Initialize target action-value function
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw11/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq44_HTML.jpg" style="width:11px;max-width:none;"/>
           with weights
           <i>
            θ
           </i>
           <sup>
            −
           </sup>
           <i>
            = θ
           </i>
          </p>
          <p>
           <b>
            For
           </b>
           episode = 1,
           <i>
            M
           </i>
           <b>
            do
           </b>
          </p>
          <p>
           Initialize sequence
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw55/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq45_HTML.jpg" style="width:55px;max-width:none;"/>
           and preprocessed sequence
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw61/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq46_HTML.jpg" style="width:61px;max-width:none;"/>
          </p>
          <p>
           <b>
            For
           </b>
           <i>
            t
           </i>
           = 1,T
           <b>
            do
           </b>
          </p>
          <p>
           With probability
           <i>
            ε
           </i>
           select a random action
           <i>
            a
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
          </p>
          <p>
           otherwise select
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw136/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq47_HTML.jpg" style="width:136px;max-width:none;"/>
          </p>
          <p>
           Execute action
           <i>
            a
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           in emulator and observe reward
           <i>
            r
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           and image
           <i>
            x
           </i>
           <sub>
            <i>
             t
            </i>
           </sub>
           <sub>
            + 1
           </sub>
          </p>
          <p>
           Set
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw98/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq48_HTML.jpg" style="width:98px;max-width:none;"/>
           and preprocess
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw90/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq49_HTML.jpg" style="width:90px;max-width:none;"/>
          </p>
          <p>
           Store transition
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw88/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq50_HTML.jpg" style="width:88px;max-width:none;"/>
           in
           <i>
            D
           </i>
          </p>
          <p>
           Sample random minibatch of transitions
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw87/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq51_HTML.jpg" style="width:87px;max-width:none;"/>
           from
           <i>
            D
           </i>
          </p>
          <p>
           Set
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw385/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq52_HTML.jpg"/>
          </p>
          <p>
           Perform a gradient descent step on
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw119/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq53_HTML.jpg" style="width:119px;max-width:none;"/>
           with respect to the network parameters
           <i>
            θ
           </i>
          </p>
          <p>
           Every
           <i>
            C
           </i>
           steps reset
           <img alt="" src="//media-springernature-com.proxy.lib.ohio-state.edu/lw38/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_IEq54_HTML.jpg" style="width:38px;max-width:none;"/>
          </p>
          <p>
           <b>
            End For
           </b>
          </p>
          <p>
           <b>
            End For
           </b>
          </p>
         </div>
        </div>
       </section>
      </div>
      <div>
       <div id="MagazineFulltextArticleBodySuffix">
        <section aria-labelledby="Bib1" data-title="References">
         <div class="c-article-section" id="Bib1-section">
          <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">
           References
          </h2>
          <div class="c-article-section__content" id="Bib1-content">
           <div data-container-section="references">
            <ol class="c-article-references" data-track-component="outbound reference">
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1">
              <p class="c-article-references__text" id="ref-CR1">
               Sutton, R. &amp; Barto, A.
               <i>
                Reinforcement Learning: An Introduction
               </i>
               (MIT Press, 1998)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="MATH reference 1" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1407.68009" rel="nofollow noopener">
                MATH
               </a>
               <a aria-label="Google Scholar reference 1" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20Learning%3A%20An%20Introduction&amp;publication_year=1998&amp;author=Sutton%2CR&amp;author=Barto%2CA" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2">
              <p class="c-article-references__text" id="ref-CR2">
               Thorndike, E. L.
               <i>
                Animal Intelligence: Experimental studies
               </i>
               (Macmillan, 1911)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Book reference 2" data-doi="10.5962/bhl.title.55072" data-track="click" data-track-action="book reference" data-track-label="10.5962/bhl.title.55072" href="https://doi-org.proxy.lib.ohio-state.edu/10.5962%2Fbhl.title.55072" rel="nofollow noopener">
                Book
               </a>
               <a aria-label="Google Scholar reference 2" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Animal%20Intelligence%3A%20Experimental%20studies&amp;doi=10.5962%2Fbhl.title.55072&amp;publication_year=1911&amp;author=Thorndike%2CEL" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3">
              <p class="c-article-references__text" id="ref-CR3">
               Schultz, W., Dayan, P. &amp; Montague, P. R. A neural substrate of prediction and reward.
               <i>
                Science
               </i>
               <b>
                275
               </b>
               , 1593–1599 (1997)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 3" data-doi="10.1126/science.275.5306.1593" data-track="click" data-track-action="article reference" data-track-label="10.1126/science.275.5306.1593" href="https://doi-org.proxy.lib.ohio-state.edu/10.1126%2Fscience.275.5306.1593" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 3" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DyaK2sXhvFSntro%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 3" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20neural%20substrate%20of%20prediction%20and%20reward&amp;journal=Science&amp;doi=10.1126%2Fscience.275.5306.1593&amp;volume=275&amp;pages=1593-1599&amp;publication_year=1997&amp;author=Schultz%2CW&amp;author=Dayan%2CP&amp;author=Montague%2CPR" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4">
              <p class="c-article-references__text" id="ref-CR4">
               Serre, T., Wolf, L. &amp; Poggio, T. Object recognition with features inspired by visual cortex.
               <i>
                Proc. IEEE. Comput. Soc. Conf. Comput. Vis. Pattern. Recognit.
               </i>
               994–1000 (2005)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 4" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Object%20recognition%20with%20features%20inspired%20by%20visual%20cortex&amp;pages=994-1000&amp;publication_year=2005&amp;author=Serre%2CT&amp;author=Wolf%2CL&amp;author=Poggio%2CT" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5">
              <p class="c-article-references__text" id="ref-CR5">
               Fukushima, K. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.
               <i>
                Biol. Cybern.
               </i>
               <b>
                36
               </b>
               , 193–202 (1980)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 5" data-doi="10.1007/BF00344251" data-track="click" data-track-action="article reference" data-track-label="10.1007/BF00344251" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2FBF00344251" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 5" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:STN:280:DyaL3c7nsFKntw%3D%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 5" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocognitron%3A%20A%20self-organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern%20recognition%20unaffected%20by%20shift%20in%20position&amp;journal=Biol.%20Cybern.&amp;doi=10.1007%2FBF00344251&amp;volume=36&amp;pages=193-202&amp;publication_year=1980&amp;author=Fukushima%2CK" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6">
              <p class="c-article-references__text" id="ref-CR6">
               Tesauro, G. Temporal difference learning and TD-Gammon.
               <i>
                Commun. ACM
               </i>
               <b>
                38
               </b>
               , 58–68 (1995)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 6" data-doi="10.1145/203330.203343" data-track="click" data-track-action="article reference" data-track-label="10.1145/203330.203343" href="https://doi-org.proxy.lib.ohio-state.edu/10.1145%2F203330.203343" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 6" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20difference%20learning%20and%20TD-Gammon&amp;journal=Commun.%20ACM&amp;doi=10.1145%2F203330.203343&amp;volume=38&amp;pages=58-68&amp;publication_year=1995&amp;author=Tesauro%2CG" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7">
              <p class="c-article-references__text" id="ref-CR7">
               Riedmiller, M., Gabel, T., Hafner, R. &amp; Lange, S. Reinforcement learning for robot soccer.
               <i>
                Auton. Robots
               </i>
               <b>
                27
               </b>
               , 55–73 (2009)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 7" data-doi="10.1007/s10514-009-9120-4" data-track="click" data-track-action="article reference" data-track-label="10.1007/s10514-009-9120-4" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs10514-009-9120-4" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 7" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20for%20robot%20soccer&amp;journal=Auton.%20Robots&amp;doi=10.1007%2Fs10514-009-9120-4&amp;volume=27&amp;pages=55-73&amp;publication_year=2009&amp;author=Riedmiller%2CM&amp;author=Gabel%2CT&amp;author=Hafner%2CR&amp;author=Lange%2CS" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8">
              <p class="c-article-references__text" id="ref-CR8">
               Diuk, C., Cohen, A. &amp; Littman, M. L. An object-oriented representation for efficient reinforcement learning.
               <i>
                Proc. Int. Conf. Mach. Learn.
               </i>
               240–247 (2008)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 8" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20object-oriented%20representation%20for%20efficient%20reinforcement%20learning&amp;pages=240-247&amp;publication_year=2008&amp;author=Diuk%2CC&amp;author=Cohen%2CA&amp;author=Littman%2CML" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9">
              <p class="c-article-references__text" id="ref-CR9">
               Bengio, Y. Learning deep architectures for AI.
               <i>
                Foundations and Trends in Machine Learning
               </i>
               <b>
                2
               </b>
               , 1–127 (2009)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 9" data-doi="10.1561/2200000006" data-track="click" data-track-action="article reference" data-track-label="10.1561/2200000006" href="https://doi-org.proxy.lib.ohio-state.edu/10.1561%2F2200000006" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 9" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20deep%20architectures%20for%20AI&amp;journal=Foundations%20and%20Trends%20in%20Machine%20Learning&amp;doi=10.1561%2F2200000006&amp;volume=2&amp;pages=1-127&amp;publication_year=2009&amp;author=Bengio%2CY" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10">
              <p class="c-article-references__text" id="ref-CR10">
               Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks.
               <i>
                Adv. Neural Inf. Process. Syst.
               </i>
               <b>
                25
               </b>
               , 1106–1114 (2012)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 10" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=25&amp;pages=1106-1114&amp;publication_year=2012&amp;author=Krizhevsky%2CA&amp;author=Sutskever%2CI&amp;author=Hinton%2CG" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11">
              <p class="c-article-references__text" id="ref-CR11">
               Hinton, G. E. &amp; Salakhutdinov, R. R. Reducing the dimensionality of data with neural networks.
               <i>
                Science
               </i>
               <b>
                313
               </b>
               , 504–507 (2006)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 11" data-doi="10.1126/science.1127647" data-track="click" data-track-action="article reference" data-track-label="10.1126/science.1127647" href="https://doi-org.proxy.lib.ohio-state.edu/10.1126%2Fscience.1127647" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="ADS reference 11" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2006Sci...313..504H" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="MathSciNet reference 11" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2242509" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="CAS reference 11" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BD28Xnt1KntrY%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 11" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks&amp;journal=Science&amp;doi=10.1126%2Fscience.1127647&amp;volume=313&amp;pages=504-507&amp;publication_year=2006&amp;author=Hinton%2CGE&amp;author=Salakhutdinov%2CRR" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12">
              <p class="c-article-references__text" id="ref-CR12">
               Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents.
               <i>
                J. Artif. Intell. Res.
               </i>
               <b>
                47
               </b>
               , 253–279 (2013)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 12" data-doi="10.1613/jair.3912" data-track="click" data-track-action="article reference" data-track-label="10.1613/jair.3912" href="https://doi-org.proxy.lib.ohio-state.edu/10.1613%2Fjair.3912" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 12" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20arcade%20learning%20environment%3A%20An%20evaluation%20platform%20for%20general%20agents&amp;journal=J.%20Artif.%20Intell.%20Res.&amp;doi=10.1613%2Fjair.3912&amp;volume=47&amp;pages=253-279&amp;publication_year=2013&amp;author=Bellemare%2CMG&amp;author=Naddaf%2CY&amp;author=Veness%2CJ&amp;author=Bowling%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13">
              <p class="c-article-references__text" id="ref-CR13">
               Legg, S. &amp; Hutter, M. Universal Intelligence: a definition of machine intelligence.
               <i>
                Minds Mach.
               </i>
               <b>
                17
               </b>
               , 391–444 (2007)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 13" data-doi="10.1007/s11023-007-9079-x" data-track="click" data-track-action="article reference" data-track-label="10.1007/s11023-007-9079-x" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs11023-007-9079-x" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 13" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Universal%20Intelligence%3A%20a%20definition%20of%20machine%20intelligence&amp;journal=Minds%20Mach.&amp;doi=10.1007%2Fs11023-007-9079-x&amp;volume=17&amp;pages=391-444&amp;publication_year=2007&amp;author=Legg%2CS&amp;author=Hutter%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14">
              <p class="c-article-references__text" id="ref-CR14">
               Genesereth, M., Love, N. &amp; Pell, B. General game playing: overview of the AAAI competition.
               <i>
                AI Mag.
               </i>
               <b>
                26
               </b>
               , 62–72 (2005)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 14" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20game%20playing%3A%20overview%20of%20the%20AAAI%20competition&amp;journal=AI%20Mag.&amp;volume=26&amp;pages=62-72&amp;publication_year=2005&amp;author=Genesereth%2CM&amp;author=Love%2CN&amp;author=Pell%2CB" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15">
              <p class="c-article-references__text" id="ref-CR15">
               Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games.
               <i>
                Proc. Conf. AAAI. Artif. Intell.
               </i>
               864–871 (2012)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 15" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Investigating%20contingency%20awareness%20using%20Atari%202600%20games&amp;pages=864-871&amp;publication_year=2012&amp;author=Bellemare%2CMG&amp;author=Veness%2CJ&amp;author=Bowling%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16">
              <p class="c-article-references__text" id="ref-CR16">
               McClelland, J. L., Rumelhart, D. E. &amp; Group, T. P. R.
               <i>
                Parallel Distributed Processing: Explorations in the Microstructure of Cognition
               </i>
               (MIT Press, 1986)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 16" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20Distributed%20Processing%3A%20Explorations%20in%20the%20Microstructure%20of%20Cognition&amp;publication_year=1986&amp;author=McClelland%2CJL&amp;author=Rumelhart%2CDE&amp;author=Group%2CTPR" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17">
              <p class="c-article-references__text" id="ref-CR17">
               LeCun, Y., Bottou, L., Bengio, Y. &amp; Haffner, P. Gradient-based learning applied to document recognition.
               <i>
                Proc. IEEE
               </i>
               <b>
                86
               </b>
               , 2278–2324 (1998)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 17" data-doi="10.1109/5.726791" data-track="click" data-track-action="article reference" data-track-label="10.1109/5.726791" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F5.726791" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 17" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Gradient-based%20learning%20applied%20to%20document%20recognition&amp;journal=Proc.%20IEEE&amp;doi=10.1109%2F5.726791&amp;volume=86&amp;pages=2278-2324&amp;publication_year=1998&amp;author=LeCun%2CY&amp;author=Bottou%2CL&amp;author=Bengio%2CY&amp;author=Haffner%2CP" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18">
              <p class="c-article-references__text" id="ref-CR18">
               Hubel, D. H. &amp; Wiesel, T. N. Shape and arrangement of columns in cat’s striate cortex.
               <i>
                J. Physiol.
               </i>
               <b>
                165
               </b>
               , 559–568 (1963)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 18" data-doi="10.1113/jphysiol.1963.sp007079" data-track="click" data-track-action="article reference" data-track-label="10.1113/jphysiol.1963.sp007079" href="https://doi-org.proxy.lib.ohio-state.edu/10.1113%2Fjphysiol.1963.sp007079" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 18" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:STN:280:DyaF387kslWitA%3D%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 18" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Shape%20and%20arrangement%20of%20columns%20in%20cat%E2%80%99s%20striate%20cortex&amp;journal=J.%20Physiol.&amp;doi=10.1113%2Fjphysiol.1963.sp007079&amp;volume=165&amp;pages=559-568&amp;publication_year=1963&amp;author=Hubel%2CDH&amp;author=Wiesel%2CTN" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19">
              <p class="c-article-references__text" id="ref-CR19">
               Watkins, C. J. &amp; Dayan, P. Q-learning.
               <i>
                Mach. Learn.
               </i>
               <b>
                8
               </b>
               , 279–292 (1992)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="MATH reference 19" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?0773.68062" rel="nofollow noopener">
                MATH
               </a>
               <a aria-label="Google Scholar reference 19" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Q-learning&amp;journal=Mach.%20Learn.&amp;volume=8&amp;pages=279-292&amp;publication_year=1992&amp;author=Watkins%2CCJ&amp;author=Dayan%2CP" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20">
              <p class="c-article-references__text" id="ref-CR20">
               Tsitsiklis, J. &amp; Roy, B. V. An analysis of temporal-difference learning with function approximation.
               <i>
                IEEE Trans. Automat. Contr.
               </i>
               <b>
                42
               </b>
               , 674–690 (1997)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 20" data-doi="10.1109/9.580874" data-track="click" data-track-action="article reference" data-track-label="10.1109/9.580874" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F9.580874" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 20" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=1454208" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 20" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20analysis%20of%20temporal-difference%20learning%20with%20function%20approximation&amp;journal=IEEE%20Trans.%20Automat.%20Contr.&amp;doi=10.1109%2F9.580874&amp;volume=42&amp;pages=674-690&amp;publication_year=1997&amp;author=Tsitsiklis%2CJ&amp;author=Roy%2CBV" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21">
              <p class="c-article-references__text" id="ref-CR21">
               McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.
               <i>
                Psychol. Rev.
               </i>
               <b>
                102
               </b>
               , 419–457 (1995)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 21" data-doi="10.1037/0033-295X.102.3.419" data-track="click" data-track-action="article reference" data-track-label="10.1037/0033-295X.102.3.419" href="https://doi-org.proxy.lib.ohio-state.edu/10.1037%2F0033-295X.102.3.419" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 21" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20there%20are%20complementary%20learning%20systems%20in%20the%20hippocampus%20and%20neocortex%3A%20insights%20from%20the%20successes%20and%20failures%20of%20connectionist%20models%20of%20learning%20and%20memory&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.102.3.419&amp;volume=102&amp;pages=419-457&amp;publication_year=1995&amp;author=McClelland%2CJL&amp;author=McNaughton%2CBL&amp;author=O%E2%80%99Reilly%2CRC" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22">
              <p class="c-article-references__text" id="ref-CR22">
               O’Neill, J., Pleydell-Bouverie, B., Dupret, D. &amp; Csicsvari, J. Play it again: reactivation of waking experience and memory.
               <i>
                Trends Neurosci.
               </i>
               <b>
                33
               </b>
               , 220–229 (2010)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 22" data-doi="10.1016/j.tins.2010.01.006" data-track="click" data-track-action="article reference" data-track-label="10.1016/j.tins.2010.01.006" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2Fj.tins.2010.01.006" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="Google Scholar reference 22" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Play%20it%20again%3A%20reactivation%20of%20waking%20experience%20and%20memory&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2010.01.006&amp;volume=33&amp;pages=220-229&amp;publication_year=2010&amp;author=O%E2%80%99Neill%2CJ&amp;author=Pleydell-Bouverie%2CB&amp;author=Dupret%2CD&amp;author=Csicsvari%2CJ" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23">
              <p class="c-article-references__text" id="ref-CR23">
               Lin, L.-J. Reinforcement learning for robots using neural networks. Technical Report, DTIC Document. (1993)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24">
              <p class="c-article-references__text" id="ref-CR24">
               Riedmiller, M. Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method.
               <i>
                Mach. Learn.: ECML
               </i>
               <b>
                3720
               </b>
               , 317–328 (Springer, 2005)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 24" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20fitted%20Q%20iteration%20-%20first%20experiences%20with%20a%20data%20efficient%20neural%20reinforcement%20learning%20method&amp;journal=Mach.%20Learn.%3A%20ECML&amp;volume=3720&amp;pages=317-328&amp;publication_year=2005&amp;author=Riedmiller%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25">
              <p class="c-article-references__text" id="ref-CR25">
               Van der Maaten, L. J. P. &amp; Hinton, G. E. Visualizing high-dimensional data using t-SNE.
               <i>
                J. Mach. Learn. Res.
               </i>
               <b>
                9
               </b>
               , 2579–2605 (2008)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="MATH reference 25" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1225.68219" rel="nofollow noopener">
                MATH
               </a>
               <a aria-label="Google Scholar reference 25" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Visualizing%20high-dimensional%20data%20using%20t-SNE&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=9&amp;pages=2579-2605&amp;publication_year=2008&amp;author=Van%20der%20Maaten%2CLJP&amp;author=Hinton%2CGE" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26">
              <p class="c-article-references__text" id="ref-CR26">
               Lange, S. &amp; Riedmiller, M. Deep auto-encoder neural networks in reinforcement learning.
               <i>
                Proc. Int. Jt. Conf. Neural. Netw.
               </i>
               1–8 (2010)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 26" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20auto-encoder%20neural%20networks%20in%20reinforcement%20learning&amp;pages=1-8&amp;publication_year=2010&amp;author=Lange%2CS&amp;author=Riedmiller%2CM" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27">
              <p class="c-article-references__text" id="ref-CR27">
               Law, C.-T. &amp; Gold, J. I. Reinforcement learning can account for associative and perceptual learning on a visual decision task.
               <i>
                Nature Neurosci.
               </i>
               <b>
                12
               </b>
               , 655 (2009)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 27" data-doi="10.1038/nn.2304" data-track="click" data-track-action="article reference" data-track-label="10.1038/nn.2304" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnn.2304" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 27" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXks12ktbw%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 27" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20can%20account%20for%20associative%20and%20perceptual%20learning%20on%20a%20visual%20decision%20task&amp;journal=Nature%20Neurosci.&amp;doi=10.1038%2Fnn.2304&amp;volume=12&amp;publication_year=2009&amp;author=Law%2CC-T&amp;author=Gold%2CJI" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28">
              <p class="c-article-references__text" id="ref-CR28">
               Sigala, N. &amp; Logothetis, N. K. Visual categorization shapes feature selectivity in the primate temporal cortex.
               <i>
                Nature
               </i>
               <b>
                415
               </b>
               , 318–320 (2002)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 28" data-doi="10.1038/415318a" data-track="click" data-track-action="article reference" data-track-label="10.1038/415318a" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F415318a" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="ADS reference 28" data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2002Natur.415..318S" rel="nofollow noopener">
                ADS
               </a>
               <a aria-label="CAS reference 28" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BD38Xptlajsg%3D%3D" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 28" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20categorization%20shapes%20feature%20selectivity%20in%20the%20primate%20temporal%20cortex&amp;journal=Nature&amp;doi=10.1038%2F415318a&amp;volume=415&amp;pages=318-320&amp;publication_year=2002&amp;author=Sigala%2CN&amp;author=Logothetis%2CNK" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29">
              <p class="c-article-references__text" id="ref-CR29">
               Bendor, D. &amp; Wilson, M. A. Biasing the content of hippocampal replay during sleep.
               <i>
                Nature Neurosci.
               </i>
               <b>
                15
               </b>
               , 1439–1444 (2012)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 29" data-doi="10.1038/nn.3203" data-track="click" data-track-action="article reference" data-track-label="10.1038/nn.3203" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnn.3203" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="CAS reference 29" data-track="click" data-track-action="cas reference" data-track-label="link" href="/articles/cas-redirect/1:CAS:528:DC%2BC38Xht12js7bO" rel="nofollow noopener">
                CAS
               </a>
               <a aria-label="Google Scholar reference 29" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Biasing%20the%20content%20of%20hippocampal%20replay%20during%20sleep&amp;journal=Nature%20Neurosci.&amp;doi=10.1038%2Fnn.3203&amp;volume=15&amp;pages=1439-1444&amp;publication_year=2012&amp;author=Bendor%2CD&amp;author=Wilson%2CMA" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30">
              <p class="c-article-references__text" id="ref-CR30">
               Moore, A. &amp; Atkeson, C. Prioritized sweeping: reinforcement learning with less data and less real time.
               <i>
                Mach. Learn.
               </i>
               <b>
                13
               </b>
               , 103–130 (1993)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 30" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Prioritized%20sweeping%3A%20reinforcement%20learning%20with%20less%20data%20and%20less%20real%20time&amp;journal=Mach.%20Learn.&amp;volume=13&amp;pages=103-130&amp;publication_year=1993&amp;author=Moore%2CA&amp;author=Atkeson%2CC" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31">
              <p class="c-article-references__text" id="ref-CR31">
               Jarrett, K., Kavukcuoglu, K., Ranzato, M. A. &amp; LeCun, Y. What is the best multi-stage architecture for object recognition?
               <i>
                Proc. IEEE. Int. Conf. Comput. Vis.
               </i>
               2146–2153 (2009)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Google Scholar reference 31" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20is%20the%20best%20multi-stage%20architecture%20for%20object%20recognition&amp;pages=2146-2153&amp;publication_year=2009&amp;author=Jarrett%2CK&amp;author=Kavukcuoglu%2CK&amp;author=Ranzato%2CMA&amp;author=LeCun%2CY" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32">
              <p class="c-article-references__text" id="ref-CR32">
               Nair, V. &amp; Hinton, G. E. Rectified linear units improve restricted Boltzmann machines.
               <i>
                Proc. Int. Conf. Mach. Learn.
               </i>
               807–814 (2010)
              </p>
             </li>
             <li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33">
              <p class="c-article-references__text" id="ref-CR33">
               Kaelbling, L. P., Littman, M. L. &amp; Cassandra, A. R. Planning and acting in partially observable stochastic domains.
               <i>
                Artificial Intelligence
               </i>
               <b>
                101
               </b>
               , 99–134 (1994)
              </p>
              <p class="c-article-references__links u-hide-print">
               <a aria-label="Article reference 33" data-doi="10.1016/S0004-3702(98)00023-X" data-track="click" data-track-action="article reference" data-track-label="10.1016/S0004-3702(98)00023-X" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0004-3702%2898%2900023-X" rel="nofollow noopener">
                Article
               </a>
               <a aria-label="MathSciNet reference 33" data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=1641530" rel="nofollow noopener">
                MathSciNet
               </a>
               <a aria-label="Google Scholar reference 33" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Planning%20and%20acting%20in%20partially%20observable%20stochastic%20domains&amp;journal=Artificial%20Intelligence&amp;doi=10.1016%2FS0004-3702%2898%2900023-X&amp;volume=101&amp;pages=99-134&amp;publication_year=1994&amp;author=Kaelbling%2CLP&amp;author=Littman%2CML&amp;author=Cassandra%2CAR" rel="nofollow noopener">
                Google Scholar
               </a>
              </p>
             </li>
            </ol>
            <p class="c-article-references__download u-hide-print">
             <a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed-springer-com.proxy.lib.ohio-state.edu/v2/references/10.1038/nature14236?format=refman&amp;flavour=references" rel="nofollow">
              Download references
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-download" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </p>
           </div>
          </div>
         </div>
        </section>
       </div>
       <section data-title="Acknowledgements">
        <div class="c-article-section" id="Ack1-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">
          Acknowledgements
         </h2>
         <div class="c-article-section__content" id="Ack1-content">
          <p>
           We thank G. Hinton, P. Dayan and M. Bowling for discussions, A. Cain and J. Keene for work on the visuals, K. Keller and P. Rogers for help with the visuals, G. Wayne for comments on an earlier version of the manuscript, and the rest of the DeepMind team for their support, ideas and encouragement.
          </p>
         </div>
        </div>
       </section>
       <section aria-labelledby="author-information" data-title="Author information">
        <div class="c-article-section" id="author-information-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">
          Author information
         </h2>
         <div class="c-article-section__content" id="author-information-content">
          <span class="c-article-author-information__subtitle u-visually-hidden" id="author-notes">
           Author notes
          </span>
          <ol class="c-article-author-information__list">
           <li class="c-article-author-information__item" id="na1">
            <p>
             Volodymyr Mnih, Koray Kavukcuoglu and David Silver: These authors contributed equally to this work.
            </p>
           </li>
          </ol>
          <h3 class="c-article__sub-heading" id="affiliations">
           Authors and Affiliations
          </h3>
          <ol class="c-article-author-affiliation__list">
           <li id="Aff1">
            <p class="c-article-author-affiliation__address">
             Google DeepMind, 5 New Street Square, London EC4A 3TW, UK,
            </p>
            <p class="c-article-author-affiliation__authors-list">
             Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg &amp; Demis Hassabis
            </p>
           </li>
          </ol>
          <div class="u-js-hide u-hide-print" data-test="author-info">
           <span class="c-article__sub-heading">
            Authors
           </span>
           <ol class="c-article-authors-search u-list-reset">
            <li id="auth-Volodymyr-Mnih-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Volodymyr Mnih
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Volodymyr%20Mnih" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Volodymyr%20Mnih" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Volodymyr%20Mnih%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Koray-Kavukcuoglu-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Koray Kavukcuoglu
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Koray%20Kavukcuoglu" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Koray%20Kavukcuoglu" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Koray%20Kavukcuoglu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-David-Silver-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              David Silver
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=David%20Silver" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=David%20Silver" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David%20Silver%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Andrei_A_-Rusu-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Andrei A. Rusu
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Andrei%20A.%20Rusu" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Andrei%20A.%20Rusu" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Andrei%20A.%20Rusu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Joel-Veness-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Joel Veness
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Joel%20Veness" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Joel%20Veness" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Joel%20Veness%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Marc_G_-Bellemare-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Marc G. Bellemare
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Marc%20G.%20Bellemare" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Marc%20G.%20Bellemare" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Marc%20G.%20Bellemare%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Alex-Graves-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Alex Graves
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Alex%20Graves" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Alex%20Graves" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alex%20Graves%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Martin-Riedmiller-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Martin Riedmiller
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Martin%20Riedmiller" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Martin%20Riedmiller" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Martin%20Riedmiller%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Andreas_K_-Fidjeland-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Andreas K. Fidjeland
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Andreas%20K.%20Fidjeland" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Andreas%20K.%20Fidjeland" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Andreas%20K.%20Fidjeland%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Georg-Ostrovski-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Georg Ostrovski
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Georg%20Ostrovski" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Georg%20Ostrovski" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Georg%20Ostrovski%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Stig-Petersen-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Stig Petersen
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Stig%20Petersen" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Stig%20Petersen" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Stig%20Petersen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Charles-Beattie-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Charles Beattie
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Charles%20Beattie" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Charles%20Beattie" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Charles%20Beattie%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Amir-Sadik-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Amir Sadik
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Amir%20Sadik" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Amir%20Sadik" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Amir%20Sadik%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Ioannis-Antonoglou-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Ioannis Antonoglou
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Ioannis%20Antonoglou" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Ioannis%20Antonoglou" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ioannis%20Antonoglou%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Helen-King-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Helen King
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Helen%20King" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Helen%20King" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Helen%20King%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Dharshan-Kumaran-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Dharshan Kumaran
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Dharshan%20Kumaran" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Dharshan%20Kumaran" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Dharshan%20Kumaran%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Daan-Wierstra-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Daan Wierstra
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Daan%20Wierstra" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Daan%20Wierstra" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Daan%20Wierstra%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Shane-Legg-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Shane Legg
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Shane%20Legg" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Shane%20Legg" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Shane%20Legg%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
            <li id="auth-Demis-Hassabis-Aff1">
             <span class="c-article-authors-search__title u-h3 js-search-name">
              Demis Hassabis
             </span>
             <div class="c-article-authors-search__list">
              <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
               <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?author=Demis%20Hassabis" rel="nofollow">
                View author publications
               </a>
              </div>
              <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
               <p class="search-in-title-js c-article-authors-search__text">
                You can also search for this author in
                <span class="c-article-identifiers">
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Demis%20Hassabis" rel="nofollow">
                  PubMed
                 </a>
                 <span class="u-hide">
                 </span>
                 <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Demis%20Hassabis%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                  Google Scholar
                 </a>
                </span>
               </p>
              </div>
             </div>
            </li>
           </ol>
          </div>
          <h3 class="c-article__sub-heading" id="contributions">
           Contributions
          </h3>
          <p>
           V.M., K.K., D.S., J.V., M.G.B., M.R., A.G., D.W., S.L. and D.H. conceptualized the problem and the technical framework. V.M., K.K., A.A.R. and D.S. developed and tested the algorithms. J.V., S.P., C.B., A.A.R., M.G.B., I.A., A.K.F., G.O. and A.S. created the testing platform. K.K., H.K., S.L. and D.H. managed the project. K.K., D.K., D.H., V.M., D.S., A.G., A.A.R., J.V. and M.G.B. wrote the paper.
          </p>
          <h3 class="c-article__sub-heading" id="corresponding-author">
           Corresponding authors
          </h3>
          <p id="corresponding-author-list">
           Correspondence to
           <a href="mailto:korayk@google.com" id="corresp-c1">
            Koray Kavukcuoglu
           </a>
           or
           <a href="mailto:demishassabis@google.com" id="corresp-c2">
            Demis Hassabis
           </a>
           .
          </p>
         </div>
        </div>
       </section>
       <section data-title="Ethics declarations">
        <div class="c-article-section" id="ethics-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">
          Ethics declarations
         </h2>
         <div class="c-article-section__content" id="ethics-content">
          <h3 class="c-article__sub-heading">
           Competing interests
          </h3>
          <p>
           The authors declare no competing financial interests.
          </p>
         </div>
        </div>
       </section>
       <section data-title="Extended data figures and tables">
        <div class="c-article-section" id="Sec11-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec11">
          Extended data figures and tables
         </h2>
         <div class="c-article-section__content" id="Sec11-content">
          <div data-test="supplementary-info">
           <div class="c-article-figshare-container" data-test="figshare-container" id="figshareContainer">
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig5">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig5_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 1 two-dimensional t-sne embed" href="/articles/nature14236/figures/5">
              Extended Data Figure 1 Two-dimensional t-SNE embedding of the representations in the last hidden layer assigned by DQN to game states experienced during a combination of human and agent play in Space Invaders.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              The plot was generated by running the t-SNE algorithm
              <sup>
               <a aria-label="Reference 25" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR25" id="ref-link-section-d27533759e2189" title="Van der Maaten, L. J. P. &amp; Hinton, G. E. Visualizing high-dimensional data using t-SNE. J. Mach. Learn. Res. 9, 2579–2605 (2008)">
                25
               </a>
              </sup>
              on the last hidden layer representation assigned by DQN to game states experienced during a combination of human (30 min) and agent (2 h) play. The fact that there is similar structure in the two-dimensional embeddings corresponding to the DQN representation of states experienced during human play (orange points) and DQN play (blue points) suggests that the representations learned by DQN do indeed generalize to data generated from policies other than its own. The presence in the t-SNE embedding of overlapping clusters of points corresponding to the network representation of states experienced during human and agent play shows that the DQN agent also follows sequences of states similar to those found in human play. Screenshots corresponding to selected states are shown (human: orange border; DQN: blue border).
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig6">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig6_ESM.jpg" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="extended data figure 2 visualization of learned va" href="/articles/nature14236/figures/6">
              Extended Data Figure 2 Visualization of learned value functions on two games, Breakout and Pong.
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              <b>
               a
              </b>
              , A visualization of the learned value function on the game Breakout. At time points 1 and 2, the state value is predicted to be
              <span class="stix">
               ∼
              </span>
              17 and the agent is clearing the bricks at the lowest level. Each of the peaks in the value function curve corresponds to a reward obtained by clearing a brick. At time point 3, the agent is about to break through to the top level of bricks and the value increases to
              <span class="stix">
               ∼
              </span>
              21 in anticipation of breaking out and clearing a large set of bricks. At point 4, the value is above 23 and the agent has broken through. After this point, the ball will bounce at the upper part of the bricks clearing many of them by itself.
              <b>
               b
              </b>
              , A visualization of the learned action-value function on the game Pong. At time point 1, the ball is moving towards the paddle controlled by the agent on the right side of the screen and the values of all actions are around 0.7, reflecting the expected value of this state based on previous experience. At time point 2, the agent starts moving the paddle towards the ball and the value of the ‘up’ action stays high while the value of the ‘down’ action falls to −0.9. This reflects the fact that pressing ‘down’ would lead to the agent losing the ball and incurring a reward of −1. At time point 3, the agent hits the ball by pressing ‘up’ and the expected reward keeps increasing until time point 4, when the ball reaches the left edge of the screen and the value of all actions reflects that the agent is about to receive a reward of 1. Note, the dashed line shows the past trajectory of the ball purely for illustrative purposes (that is, not shown during the game). With permission from Atari Interactive, Inc.
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-1">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab1">
                Extended Data Table 1 List of hyperparameters and their values
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 1" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature14236/tables/1" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-2">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab2">
                Extended Data Table 2 Comparison of games scores obtained by DQN agents with methods from the literature
                <sup>
                 <a aria-label="Reference 12" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR12" id="ref-link-section-d27533759e2264" title="Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents. J. Artif. Intell. Res. 47, 253–279 (2013)">
                  12
                 </a>
                 ,
                 <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e2267" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
                  15
                 </a>
                </sup>
                and a professional human games tester
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 2" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature14236/tables/2" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-3">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab3">
                Extended Data Table 3 The effects of replay and separating the target Q-network
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 3" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature14236/tables/3" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item">
            <div class="c-article-table" data-container-section="table" data-test="inline-table" id="table-4">
             <figure>
              <figcaption class="c-article-table__figcaption">
               <b data-test="table-caption" id="Tab4">
                Extended Data Table 4 Comparison of DQN performance with linear function approximator
               </b>
              </figcaption>
              <div class="u-text-right u-hide-print">
               <a aria-label="Full size table 4" class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" href="/articles/nature14236/tables/4" rel="nofollow">
                <span>
                 Full size table
                </span>
                <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
                 <use xlink:href="#icon-chevron-right" xmlns:xlink="http://www.w3.org/1999/xlink">
                 </use>
                </svg>
               </a>
              </div>
             </figure>
            </div>
           </div>
          </div>
         </div>
        </div>
       </section>
       <section data-title="Supplementary information">
        <div class="c-article-section" id="Sec12-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">
          Supplementary information
         </h2>
         <div class="c-article-section__content" id="Sec12-content">
          <div data-test="supplementary-info">
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM122">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="supplementary information" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM122_ESM.pdf">
              Supplementary Information
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              This file contains a Supplementary Discussion. (PDF 110 kb)
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM123">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="performance of dqn in the game space invaders" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM123_ESM.mov">
              Performance of DQN in the Game Space Invaders
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              This video shows the performance of the DQN agent while playing the game of Space Invaders. The DQN agent successfully clears the enemy ships on the screen while the enemy ships move down and sideways with gradually increasing speed. (MOV 5106 kb)
             </p>
            </div>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM124">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="demonstration of learning progress in the game bre" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM124_ESM.mov">
              Demonstration of Learning Progress in the Game Breakout
             </a>
            </h3>
            <div class="c-article-supplementary__description" data-component="thumbnail-container">
             <p>
              This video shows the improvement in the performance of DQN over training (i.e. after 100, 200, 400 and 600 episodes). After 600 episodes DQN finds and exploits the optimal strategy in this game, which is to make a tunnel around the side, and then allow the ball to hit blocks by bouncing behind the wall. Note: the score is displayed at the top left of the screen (maximum for clearing one screen is 448 points), number of lives remaining is shown in the middle (starting with 5 lives), and the “1” on the top right indicates this is a 1-player game. (MOV 1500 kb)
             </p>
            </div>
           </div>
          </div>
         </div>
        </div>
       </section>
       <section data-title="PowerPoint slides">
        <div class="c-article-section" id="Sec13-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">
          PowerPoint slides
         </h2>
         <div class="c-article-section__content" id="Sec13-content">
          <div data-test="supplementary-info">
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM118">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 1" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM118_ESM.ppt">
              PowerPoint slide for Fig. 1
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM119">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 2" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM119_ESM.ppt">
              PowerPoint slide for Fig. 2
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM120">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 3" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM120_ESM.ppt">
              PowerPoint slide for Fig. 3
             </a>
            </h3>
           </div>
           <div class="c-article-supplementary__item" data-test="supp-item" id="MOESM121">
            <h3 class="c-article-supplementary__title u-h3">
             <a class="print-link" data-supp-info-image="" data-test="supp-info-link" data-track="click" data-track-action="view supplementary info" data-track-label="powerpoint slide for fig. 4" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_MOESM121_ESM.ppt">
              PowerPoint slide for Fig. 4
             </a>
            </h3>
           </div>
          </div>
         </div>
        </div>
       </section>
       <section data-title="Rights and permissions">
        <div class="c-article-section" id="rightslink-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">
          Rights and permissions
         </h2>
         <div class="c-article-section__content" id="rightslink-content">
          <p class="c-article-rights">
           <a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Human-level%20control%20through%20deep%20reinforcement%20learning&amp;author=Volodymyr%20Mnih%20et%20al&amp;contentID=10.1038%2Fnature14236&amp;copyright=Springer%20Nature%20Limited&amp;publication=0028-0836&amp;publicationDate=2015-02-25&amp;publisherName=SpringerNature&amp;orderBeanReset=true">
            Reprints and Permissions
           </a>
          </p>
         </div>
        </div>
       </section>
       <section aria-labelledby="article-info" data-title="About this article">
        <div class="c-article-section" id="article-info-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">
          About this article
         </h2>
         <div class="c-article-section__content" id="article-info-content">
          <div class="c-bibliographic-information">
           <div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border">
            <a data-crossmark="10.1038/nature14236" data-test="crossmark" data-track="click" data-track-action="Click Crossmark" data-track-label="link" href="https://crossmark-crossref-org.proxy.lib.ohio-state.edu/dialog/?doi=10.1038/nature14236" rel="noopener" target="_blank">
             <img alt="Check for updates. Verify currency and authenticity via CrossMark" height="81" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" width="57"/>
            </a>
           </div>
           <div class="c-bibliographic-information__column">
            <h3 class="c-article__sub-heading" id="citeas">
             Cite this article
            </h3>
            <p class="c-bibliographic-information__citation">
             Mnih, V., Kavukcuoglu, K., Silver, D.
             <i>
              et al.
             </i>
             Human-level control through deep reinforcement learning.
             <i>
              Nature
             </i>
             <b>
              518
             </b>
             , 529–533 (2015). https://doi-org.proxy.lib.ohio-state.edu/10.1038/nature14236
            </p>
            <p class="c-bibliographic-information__download-citation u-hide-print">
             <a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-external="" data-track-label="link" href="https://citation-needed-springer-com.proxy.lib.ohio-state.edu/v2/references/10.1038/nature14236?format=refman&amp;flavour=citation" rel="nofollow">
              Download citation
              <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
               <use xlink:href="#icon-download" xmlns:xlink="http://www.w3.org/1999/xlink">
               </use>
              </svg>
             </a>
            </p>
            <ul class="c-bibliographic-information__list" data-test="publication-history">
             <li class="c-bibliographic-information__list-item">
              <p>
               Received
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2014-07-10">
                 10 July 2014
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item">
              <p>
               Accepted
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2015-01-16">
                 16 January 2015
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item">
              <p>
               Published
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2015-02-25">
                 25 February 2015
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item">
              <p>
               Issue Date
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                <time datetime="2015-02-26">
                 26 February 2015
                </time>
               </span>
              </p>
             </li>
             <li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width">
              <p>
               <abbr title="Digital Object Identifier">
                DOI
               </abbr>
               <span class="u-hide">
                :
               </span>
               <span class="c-bibliographic-information__value">
                https://doi-org.proxy.lib.ohio-state.edu/10.1038/nature14236
               </span>
              </p>
             </li>
            </ul>
            <div data-component="share-box">
             <div class="c-article-share-box u-display-block">
              <h3 class="c-article__sub-heading">
               Share this article
              </h3>
              <p class="c-article-share-box__description">
               Anyone you share the following link with will be able to read this content:
              </p>
              <button class="js-get-share-url c-article-share-box__button" data-track="click" data-track-action="get shareable link" data-track-external="" data-track-label="button" id="get-share-url" type="button">
               Get shareable link
              </button>
              <div class="js-no-share-url-container u-display-none" hidden="">
               <p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">
                Sorry, a shareable link is not currently available for this article.
               </p>
              </div>
              <div class="js-share-url-container u-display-none" hidden="">
               <p class="js-share-url c-article-share-box__only-read-input" data-track="click" data-track-action="select share url" data-track-label="button" id="share-url">
               </p>
               <button class="js-copy-share-url c-article-share-box__button--link-like" data-track="click" data-track-action="copy share url" data-track-external="" data-track-label="button" id="copy-share-url" type="button">
                Copy to clipboard
               </button>
              </div>
              <p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
               Provided by the Springer Nature SharedIt content-sharing initiative
              </p>
             </div>
            </div>
            <div data-component="article-info-list">
             <h3 class="c-article__sub-heading">
              Subjects
             </h3>
             <ul class="c-article-subject-list">
              <li class="c-article-subject-list__subject">
               <a data-track="click" data-track-action="view subject" data-track-label="link" href="/subjects/computer-science">
                Computer science
               </a>
              </li>
             </ul>
            </div>
           </div>
          </div>
         </div>
        </div>
       </section>
      </div>
      <section>
       <div class="c-article-section js-article-section" id="further-reading-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">
         This article is cited by
        </h2>
        <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
         <ul class="c-article-further-reading__list" id="further-reading-list">
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Joint optimization of energy trading and consensus mechanism in blockchain-empowered smart grids: a reinforcement learning approach" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s13677-023-00498-4">
             Joint optimization of energy trading and consensus mechanism in blockchain-empowered smart grids: a reinforcement learning approach
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Ruohan Wang
            </li>
            <li>
             Yunlong Chen
            </li>
            <li>
             Xueyao Zhang
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Cloud Computing
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Task offloading optimization mechanism based on deep neural network in edge-cloud environment" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s13677-023-00450-6">
             Task offloading optimization mechanism based on deep neural network in edge-cloud environment
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Lingkang Meng
            </li>
            <li>
             Yingjie Wang
            </li>
            <li>
             Zhipeng Cai
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Cloud Computing
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Governance and sustainability of distributed continuum systems: a big data approach" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s40537-023-00737-0">
             Governance and sustainability of distributed continuum systems: a big data approach
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Praveen Kumar Donta
            </li>
            <li>
             Boris Sedlak
            </li>
            <li>
             Schahram Dustdar
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Big Data
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:Collaborative on-demand dynamic deployment via deep reinforcement learning for IoV service in multi edge clouds" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s13677-023-00488-6">
             Collaborative on-demand dynamic deployment via deep reinforcement learning for IoV service in multi edge clouds
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Yuze Huang
            </li>
            <li>
             Beipeng Feng
            </li>
            <li>
             Boren Zheng
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Cloud Computing
            </i>
            (2023)
           </p>
          </li>
          <li class="c-article-further-reading__item js-ref-item">
           <h3 class="c-article-further-reading__title">
            <a class="print-link" data-track="click" data-track-action="view further reading article" data-track-label="link:UDL: a cloud task scheduling framework based on multiple deep neural networks" href="https://doi-org.proxy.lib.ohio-state.edu/10.1186/s13677-023-00490-y">
             UDL: a cloud task scheduling framework based on multiple deep neural networks
            </a>
           </h3>
           <ul class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto" data-test="author-list">
            <li>
             Qirui Li
            </li>
            <li>
             Zhiping Peng
            </li>
            <li>
             Hao Zhang
            </li>
           </ul>
           <p class="c-article-further-reading__journal-title">
            <i>
             Journal of Cloud Computing
            </i>
            (2023)
           </p>
          </li>
         </ul>
        </div>
       </div>
      </section>
      <section data-title="Comments">
       <div class="c-article-section" id="article-comments-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-comments">
         Comments
        </h2>
        <div class="c-article-section__content" id="article-comments-content">
         <p>
          By submitting a comment you agree to abide by our
          <a href="/info/tandc.html">
           Terms
          </a>
          and
          <a href="/info/community-guidelines.html">
           Community Guidelines
          </a>
          . If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.
         </p>
        </div>
       </div>
      </section>
      <div id="inject-comments">
       <div class="placeholder" data-disqus-placeholder="/platform/disqus?doi=10.1038/nature14236 #article-comments-container" data-replace="true">
       </div>
      </div>
     </div>
    </article>
   </main>
   <aside aria-label="Article navigation" class="c-article-extras u-hide-print" data-component-reading-companion="" data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
     <noscript>
      <div class="c-nature-box c-nature-box--side" data-component="entitlement-box">
       <p class="c-nature-box__text js-text">
        You have full access to this article via your institution.
       </p>
       <div class="c-pdf-download u-clear-both js-pdf-download">
        <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature14236.pdf">
         <span class="c-pdf-download__text">
          Download PDF
         </span>
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
          <use xlink:href="#icon-download">
          </use>
         </svg>
        </a>
       </div>
      </div>
     </noscript>
     <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
      <div class="c-nature-box c-nature-box--side u-hide-print" data-component="entitlement-box" id="entitlement-box-right-column">
       <p class="c-nature-box__text js-text">
        You have full access to this article via
        <strong>
         Ohio State University Libraries
        </strong>
       </p>
       <div class="c-pdf-download u-clear-both js-pdf-download">
        <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="download-pdf" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="link" download="" href="/articles/nature14236.pdf">
         <span class="c-pdf-download__text">
          Download PDF
         </span>
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
          <use xlink:href="#icon-download">
          </use>
         </svg>
        </a>
       </div>
      </div>
     </div>
    </div>
    <div class="c-article-editorial-summary__container u-mb-16" data-component-show-more="true" id="editorial-summary">
     <section>
      <h2 class="c-article-editorial-summary__title u-h3 u-mb-16">
       Editorial Summary
      </h2>
      <h3 class="c-article-editorial-summary__article-title u-mb-8">
       Self-taught AI agent masters Atari arcade games
      </h3>
      <div class="c-article-editorial-summary__content c-article-editorial-summary__content--less">
       <p>
        For an artificial agent to be considered truly intelligent it needs to excel at a variety of tasks considered challenging for humans. To date, it has only been possible to create individual algorithms able to master a single discipline — for example, IBM's Deep Blue beat the human world champion at chess but was not able to do anything else. Now a team working at Google's DeepMind subsidiary has developed an artificial agent — dubbed a deep Q-network — that learns to play 49 classic Atari 2600 'arcade' games directly from sensory experience, achieving performance on a par with that of an expert human player. By combining reinforcement learning (selecting actions that maximize reward — in this case the game score) with deep learning (multilayered feature extraction from high-dimensional data — in this case the pixels), the game-playing agent takes artificial intelligence a step nearer the goal of systems capable of learning a diversity of challenging tasks from scratch.
       </p>
      </div>
      <button class="c-article-editorial-summary__button" data-track="click" data-track-action="editorial summary show less" data-track-label="button" id="show-button" type="button">
       show all
      </button>
     </section>
    </div>
    <div class="c-article-associated-content__container">
     <section>
      <h2 class="c-article-associated-content__title u-mb-24">
       Associated Content
      </h2>
      <div class="c-article-associated-content__collection collection u-mb-24">
       <section>
        <p class="c-article-associated-content__collection-label u-sans-serif u-text-bold u-mb-8">
         Collection
        </p>
        <h3 class="c-article-associated-content__collection-title u-h3 u-mb-8">
         <a class="u-link-inherit" data-test="collection-link" data-track="click" data-track-action="view collection" data-track-category="associated content" data-track-label="collection" href="https://www-nature-com.proxy.lib.ohio-state.edu/collections/csgqqsrfxh">
          The multidisciplinary nature of machine intelligence
         </a>
        </h3>
       </section>
      </div>
      <div class="u-full-height u-mb-24">
       <article class="u-full-height c-card c-card--flush">
        <div class="c-card__layout u-full-height">
         <div class="c-card__body">
          <h3 class="c-card__title">
           <a class="c-card__link u-link-inherit" data-track="click" data-track-action="view article" data-track-category="associated content" data-track-label="news_and_views" href="/articles/518486a">
            Learning to see and act
           </a>
          </h3>
          <ul class="c-author-list c-author-list--compact" data-test="author-list">
           <li>
            Bernhard Schölkopf
           </li>
          </ul>
          <div class="c-card__section c-meta">
           <span class="c-meta__item">
            Nature
           </span>
           <span class="c-meta__item" data-test="article.type">
            <span class="c-meta__type">
             News &amp; Views
            </span>
           </span>
           <time class="c-meta__item" datetime="2015-02-25">
            25 Feb 2015
           </time>
          </div>
         </div>
        </div>
       </article>
      </div>
     </section>
    </div>
    <script>
     window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "collection;news_and_views";
    </script>
    <div class="c-reading-companion">
     <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky" style="top: 40px;">
      <ul class="c-reading-companion__tabs" role="tablist">
       <li role="presentation">
        <button aria-controls="tabpanel-sections" aria-selected="true" class="c-reading-companion__tab c-reading-companion__tab--active" data-tab-target="sections" data-track="click" data-track-action="sections tab" data-track-label="tab" id="tab-sections" role="tab">
         Sections
        </button>
       </li>
       <li role="presentation">
        <button aria-controls="tabpanel-figures" aria-selected="false" class="c-reading-companion__tab" data-tab-target="figures" data-track="click" data-track-action="figures tab" data-track-label="tab" id="tab-figures" role="tab" tabindex="-1">
         Figures
        </button>
       </li>
       <li role="presentation">
        <button aria-controls="tabpanel-references" aria-selected="false" class="c-reading-companion__tab" data-tab-target="references" data-track="click" data-track-action="references tab" data-track-label="tab" id="tab-references" role="tab" tabindex="-1">
         References
        </button>
       </li>
      </ul>
      <div aria-labelledby="tab-sections" class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections" role="tabpanel">
       <div class="c-reading-companion__scroll-pane" style="max-height: none;">
        <ul class="c-reading-companion__sections-list">
         <li class="c-reading-companion__section-item" id="rc-sec-Abs3">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Abstract" href="#Abs3">
           Abstract
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Main" href="#Sec1">
           Main
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec2">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Methods" href="#Sec2">
           Methods
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Bib1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:References" href="#Bib1">
           References
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Ack1">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Acknowledgements" href="#Ack1">
           Acknowledgements
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-author-information">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Author information" href="#author-information">
           Author information
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-ethics">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Ethics declarations" href="#ethics">
           Ethics declarations
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec11">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Extended data figures and tables" href="#Sec11">
           Extended data figures and tables
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec12">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Supplementary information" href="#Sec12">
           Supplementary information
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-Sec13">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:PowerPoint slides" href="#Sec13">
           PowerPoint slides
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-rightslink">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Rights and permissions" href="#rightslink">
           Rights and permissions
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-article-info">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:About this article" href="#article-info">
           About this article
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-further-reading">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:This article is cited by" href="#further-reading">
           This article is cited by
          </a>
         </li>
         <li class="c-reading-companion__section-item" id="rc-sec-article-comments">
          <a data-track="click" data-track-action="section anchor" data-track-label="link:Comments" href="#article-comments">
           Comments
          </a>
         </li>
        </ul>
       </div>
       <div class="u-lazy-ad-wrapper u-mt-16 u-show" data-component-mpu="">
        <div class="c-ad c-ad--300x250">
         <div class="c-ad__inner">
          <p class="c-ad__label">
           Advertisement
          </p>
          <div class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide" data-ad-type="right" data-gpt="" data-gpt-sizes="300x250" data-gpt-targeting="type=article;pos=right;artid=nature14236;doi=10.1038/nature14236;techmeta=119,129;subjmeta=117,639,705;kwrd=Computer+science" data-gpt-unitpath="/285/nature.com/article" data-pa11y-ignore="" data-test="right-ad" id="div-gpt-ad-right-2">
           <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=300x250&amp;c=-688972654&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnature14236%26doi%3D10.1038/nature14236%26techmeta%3D119,129%26subjmeta%3D117,639,705%26kwrd%3DComputer+science">
             <img alt="Advertisement" data-test="gpt-advert-fallback-img" height="250" src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=300x250&amp;c=-688972654&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnature14236%26doi%3D10.1038/nature14236%26techmeta%3D119,129%26subjmeta%3D117,639,705%26kwrd%3DComputer+science" width="300"/>
            </a>
           </noscript>
          </div>
         </div>
        </div>
       </div>
      </div>
      <div aria-labelledby="tab-figures" class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures" role="tabpanel">
       <div class="c-reading-companion__scroll-pane">
        <ul class="c-reading-companion__figures-list">
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig1">
             Figure 1: Schematic illustration of the convolutional neural network.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg?"/>
            <img alt="figure 1" aria-describedby="rc-Fig1" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig1_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig1">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236/figures/1" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig2">
             Figure 2: Training curves tracking the agent’s average score and average predicted action-value.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig2_HTML.jpg?"/>
            <img alt="figure 2" aria-describedby="rc-Fig2" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig2_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig2">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236/figures/2" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig3">
             Figure 3: Comparison of the DQN agent with the best reinforcement learning methods
             <sup>
              <a aria-label="Reference 15" data-test="citation-ref" data-track="click" data-track-action="reference anchor" data-track-label="link" href="/articles/nature14236#ref-CR15" id="ref-link-section-d27533759e1051" title="Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games. Proc. Conf. AAAI. Artif. Intell. 864–871 (2012)">
               15
              </a>
             </sup>
             in the literature.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig3_HTML.jpg?"/>
            <img alt="figure 3" aria-describedby="rc-Fig3" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig3_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig3">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236/figures/3" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig4">
             Figure 4: Two-dimensional t-SNE embedding of the representations in the last hidden layer assigned by DQN to game states experienced while playing Space Invaders.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig4_HTML.jpg?"/>
            <img alt="figure 4" aria-describedby="rc-Fig4" data-src="https://media-springernature-com.proxy.lib.ohio-state.edu/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig4_HTML.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig4">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236/figures/4" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig5">
             Extended Data Figure 1 Two-dimensional t-SNE embedding of the representations in the last hidden layer assigned by DQN to game states experienced during a combination of human and agent play in Space Invaders.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig5_ESM.jpg?"/>
            <img alt="extended data figure 5" aria-describedby="rc-Fig5" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig5_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig5">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236/figures/5" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
         <li class="c-reading-companion__figure-item">
          <figure>
           <figcaption>
            <b class="c-reading-companion__figure-title u-h4" id="rc-Fig6">
             Extended Data Figure 2 Visualization of learned value functions on two games, Breakout and Pong.
            </b>
           </figcaption>
           <picture>
            <source data-srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig6_ESM.jpg?"/>
            <img alt="extended data figure 6" aria-describedby="rc-Fig6" data-src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnature14236/MediaObjects/41586_2015_BFnature14236_Fig6_ESM.jpg"/>
           </picture>
           <p class="c-reading-companion__figure-links">
            <a data-track="click" data-track-action="figure anchor" data-track-label="link" href="#Fig6">
             View in article
            </a>
            <a class="c-reading-companion__figure-full-link" data-track="click" data-track-action="view figure" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/nature14236/figures/6" rel="nofollow">
             Full size image
             <svg class="u-icon" height="16" width="16">
              <use href="#icon-chevron-right">
              </use>
             </svg>
            </a>
           </p>
          </figure>
         </li>
        </ul>
       </div>
      </div>
      <div aria-labelledby="tab-references" class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references" role="tabpanel">
       <div class="c-reading-companion__scroll-pane">
        <ol class="c-reading-companion__references-list c-reading-companion__references-list--numeric">
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR1">
           Sutton, R. &amp; Barto, A.
           <i>
            Reinforcement Learning: An Introduction
           </i>
           (MIT Press, 1998)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1407.68009">
            MATH
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20Learning%3A%20An%20Introduction&amp;publication_year=1998&amp;author=Sutton%2CR&amp;author=Barto%2CA">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR2">
           Thorndike, E. L.
           <i>
            Animal Intelligence: Experimental studies
           </i>
           (Macmillan, 1911)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="book reference" data-track-label="10.5962/bhl.title.55072" href="https://doi-org.proxy.lib.ohio-state.edu/10.5962%2Fbhl.title.55072">
            Book
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Animal%20Intelligence%3A%20Experimental%20studies&amp;doi=10.5962%2Fbhl.title.55072&amp;publication_year=1911&amp;author=Thorndike%2CEL">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR3">
           Schultz, W., Dayan, P. &amp; Montague, P. R. A neural substrate of prediction and reward.
           <i>
            Science
           </i>
           <b>
            275
           </b>
           , 1593–1599 (1997)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1126/science.275.5306.1593" href="https://doi-org.proxy.lib.ohio-state.edu/10.1126%2Fscience.275.5306.1593">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DyaK2sXhvFSntro%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20neural%20substrate%20of%20prediction%20and%20reward&amp;journal=Science&amp;doi=10.1126%2Fscience.275.5306.1593&amp;volume=275&amp;pages=1593-1599&amp;publication_year=1997&amp;author=Schultz%2CW&amp;author=Dayan%2CP&amp;author=Montague%2CPR">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR4">
           Serre, T., Wolf, L. &amp; Poggio, T. Object recognition with features inspired by visual cortex.
           <i>
            Proc. IEEE. Comput. Soc. Conf. Comput. Vis. Pattern. Recognit.
           </i>
           994–1000 (2005)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Object%20recognition%20with%20features%20inspired%20by%20visual%20cortex&amp;pages=994-1000&amp;publication_year=2005&amp;author=Serre%2CT&amp;author=Wolf%2CL&amp;author=Poggio%2CT">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR5">
           Fukushima, K. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.
           <i>
            Biol. Cybern.
           </i>
           <b>
            36
           </b>
           , 193–202 (1980)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/BF00344251" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2FBF00344251">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:STN:280:DyaL3c7nsFKntw%3D%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocognitron%3A%20A%20self-organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern%20recognition%20unaffected%20by%20shift%20in%20position&amp;journal=Biol.%20Cybern.&amp;doi=10.1007%2FBF00344251&amp;volume=36&amp;pages=193-202&amp;publication_year=1980&amp;author=Fukushima%2CK">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR6">
           Tesauro, G. Temporal difference learning and TD-Gammon.
           <i>
            Commun. ACM
           </i>
           <b>
            38
           </b>
           , 58–68 (1995)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1145/203330.203343" href="https://doi-org.proxy.lib.ohio-state.edu/10.1145%2F203330.203343">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20difference%20learning%20and%20TD-Gammon&amp;journal=Commun.%20ACM&amp;doi=10.1145%2F203330.203343&amp;volume=38&amp;pages=58-68&amp;publication_year=1995&amp;author=Tesauro%2CG">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR7">
           Riedmiller, M., Gabel, T., Hafner, R. &amp; Lange, S. Reinforcement learning for robot soccer.
           <i>
            Auton. Robots
           </i>
           <b>
            27
           </b>
           , 55–73 (2009)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/s10514-009-9120-4" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs10514-009-9120-4">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20for%20robot%20soccer&amp;journal=Auton.%20Robots&amp;doi=10.1007%2Fs10514-009-9120-4&amp;volume=27&amp;pages=55-73&amp;publication_year=2009&amp;author=Riedmiller%2CM&amp;author=Gabel%2CT&amp;author=Hafner%2CR&amp;author=Lange%2CS">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR8">
           Diuk, C., Cohen, A. &amp; Littman, M. L. An object-oriented representation for efficient reinforcement learning.
           <i>
            Proc. Int. Conf. Mach. Learn.
           </i>
           240–247 (2008)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20object-oriented%20representation%20for%20efficient%20reinforcement%20learning&amp;pages=240-247&amp;publication_year=2008&amp;author=Diuk%2CC&amp;author=Cohen%2CA&amp;author=Littman%2CML">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR9">
           Bengio, Y. Learning deep architectures for AI.
           <i>
            Foundations and Trends in Machine Learning
           </i>
           <b>
            2
           </b>
           , 1–127 (2009)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1561/2200000006" href="https://doi-org.proxy.lib.ohio-state.edu/10.1561%2F2200000006">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20deep%20architectures%20for%20AI&amp;journal=Foundations%20and%20Trends%20in%20Machine%20Learning&amp;doi=10.1561%2F2200000006&amp;volume=2&amp;pages=1-127&amp;publication_year=2009&amp;author=Bengio%2CY">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR10">
           Krizhevsky, A., Sutskever, I. &amp; Hinton, G. ImageNet classification with deep convolutional neural networks.
           <i>
            Adv. Neural Inf. Process. Syst.
           </i>
           <b>
            25
           </b>
           , 1106–1114 (2012)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=ImageNet%20classification%20with%20deep%20convolutional%20neural%20networks&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=25&amp;pages=1106-1114&amp;publication_year=2012&amp;author=Krizhevsky%2CA&amp;author=Sutskever%2CI&amp;author=Hinton%2CG">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR11">
           Hinton, G. E. &amp; Salakhutdinov, R. R. Reducing the dimensionality of data with neural networks.
           <i>
            Science
           </i>
           <b>
            313
           </b>
           , 504–507 (2006)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1126/science.1127647" href="https://doi-org.proxy.lib.ohio-state.edu/10.1126%2Fscience.1127647">
            Article
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2006Sci...313..504H">
            ADS
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=2242509">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BD28Xnt1KntrY%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks&amp;journal=Science&amp;doi=10.1126%2Fscience.1127647&amp;volume=313&amp;pages=504-507&amp;publication_year=2006&amp;author=Hinton%2CGE&amp;author=Salakhutdinov%2CRR">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR12">
           Bellemare, M. G., Naddaf, Y., Veness, J. &amp; Bowling, M. The arcade learning environment: An evaluation platform for general agents.
           <i>
            J. Artif. Intell. Res.
           </i>
           <b>
            47
           </b>
           , 253–279 (2013)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1613/jair.3912" href="https://doi-org.proxy.lib.ohio-state.edu/10.1613%2Fjair.3912">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20arcade%20learning%20environment%3A%20An%20evaluation%20platform%20for%20general%20agents&amp;journal=J.%20Artif.%20Intell.%20Res.&amp;doi=10.1613%2Fjair.3912&amp;volume=47&amp;pages=253-279&amp;publication_year=2013&amp;author=Bellemare%2CMG&amp;author=Naddaf%2CY&amp;author=Veness%2CJ&amp;author=Bowling%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR13">
           Legg, S. &amp; Hutter, M. Universal Intelligence: a definition of machine intelligence.
           <i>
            Minds Mach.
           </i>
           <b>
            17
           </b>
           , 391–444 (2007)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1007/s11023-007-9079-x" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2Fs11023-007-9079-x">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Universal%20Intelligence%3A%20a%20definition%20of%20machine%20intelligence&amp;journal=Minds%20Mach.&amp;doi=10.1007%2Fs11023-007-9079-x&amp;volume=17&amp;pages=391-444&amp;publication_year=2007&amp;author=Legg%2CS&amp;author=Hutter%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR14">
           Genesereth, M., Love, N. &amp; Pell, B. General game playing: overview of the AAAI competition.
           <i>
            AI Mag.
           </i>
           <b>
            26
           </b>
           , 62–72 (2005)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20game%20playing%3A%20overview%20of%20the%20AAAI%20competition&amp;journal=AI%20Mag.&amp;volume=26&amp;pages=62-72&amp;publication_year=2005&amp;author=Genesereth%2CM&amp;author=Love%2CN&amp;author=Pell%2CB">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR15">
           Bellemare, M. G., Veness, J. &amp; Bowling, M. Investigating contingency awareness using Atari 2600 games.
           <i>
            Proc. Conf. AAAI. Artif. Intell.
           </i>
           864–871 (2012)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Investigating%20contingency%20awareness%20using%20Atari%202600%20games&amp;pages=864-871&amp;publication_year=2012&amp;author=Bellemare%2CMG&amp;author=Veness%2CJ&amp;author=Bowling%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR16">
           McClelland, J. L., Rumelhart, D. E. &amp; Group, T. P. R.
           <i>
            Parallel Distributed Processing: Explorations in the Microstructure of Cognition
           </i>
           (MIT Press, 1986)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20Distributed%20Processing%3A%20Explorations%20in%20the%20Microstructure%20of%20Cognition&amp;publication_year=1986&amp;author=McClelland%2CJL&amp;author=Rumelhart%2CDE&amp;author=Group%2CTPR">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR17">
           LeCun, Y., Bottou, L., Bengio, Y. &amp; Haffner, P. Gradient-based learning applied to document recognition.
           <i>
            Proc. IEEE
           </i>
           <b>
            86
           </b>
           , 2278–2324 (1998)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1109/5.726791" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F5.726791">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Gradient-based%20learning%20applied%20to%20document%20recognition&amp;journal=Proc.%20IEEE&amp;doi=10.1109%2F5.726791&amp;volume=86&amp;pages=2278-2324&amp;publication_year=1998&amp;author=LeCun%2CY&amp;author=Bottou%2CL&amp;author=Bengio%2CY&amp;author=Haffner%2CP">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR18">
           Hubel, D. H. &amp; Wiesel, T. N. Shape and arrangement of columns in cat’s striate cortex.
           <i>
            J. Physiol.
           </i>
           <b>
            165
           </b>
           , 559–568 (1963)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1113/jphysiol.1963.sp007079" href="https://doi-org.proxy.lib.ohio-state.edu/10.1113%2Fjphysiol.1963.sp007079">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:STN:280:DyaF387kslWitA%3D%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Shape%20and%20arrangement%20of%20columns%20in%20cat%E2%80%99s%20striate%20cortex&amp;journal=J.%20Physiol.&amp;doi=10.1113%2Fjphysiol.1963.sp007079&amp;volume=165&amp;pages=559-568&amp;publication_year=1963&amp;author=Hubel%2CDH&amp;author=Wiesel%2CTN">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR19">
           Watkins, C. J. &amp; Dayan, P. Q-learning.
           <i>
            Mach. Learn.
           </i>
           <b>
            8
           </b>
           , 279–292 (1992)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?0773.68062">
            MATH
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Q-learning&amp;journal=Mach.%20Learn.&amp;volume=8&amp;pages=279-292&amp;publication_year=1992&amp;author=Watkins%2CCJ&amp;author=Dayan%2CP">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR20">
           Tsitsiklis, J. &amp; Roy, B. V. An analysis of temporal-difference learning with function approximation.
           <i>
            IEEE Trans. Automat. Contr.
           </i>
           <b>
            42
           </b>
           , 674–690 (1997)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1109/9.580874" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F9.580874">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=1454208">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20analysis%20of%20temporal-difference%20learning%20with%20function%20approximation&amp;journal=IEEE%20Trans.%20Automat.%20Contr.&amp;doi=10.1109%2F9.580874&amp;volume=42&amp;pages=674-690&amp;publication_year=1997&amp;author=Tsitsiklis%2CJ&amp;author=Roy%2CBV">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR21">
           McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.
           <i>
            Psychol. Rev.
           </i>
           <b>
            102
           </b>
           , 419–457 (1995)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1037/0033-295X.102.3.419" href="https://doi-org.proxy.lib.ohio-state.edu/10.1037%2F0033-295X.102.3.419">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20there%20are%20complementary%20learning%20systems%20in%20the%20hippocampus%20and%20neocortex%3A%20insights%20from%20the%20successes%20and%20failures%20of%20connectionist%20models%20of%20learning%20and%20memory&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.102.3.419&amp;volume=102&amp;pages=419-457&amp;publication_year=1995&amp;author=McClelland%2CJL&amp;author=McNaughton%2CBL&amp;author=O%E2%80%99Reilly%2CRC">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR22">
           O’Neill, J., Pleydell-Bouverie, B., Dupret, D. &amp; Csicsvari, J. Play it again: reactivation of waking experience and memory.
           <i>
            Trends Neurosci.
           </i>
           <b>
            33
           </b>
           , 220–229 (2010)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1016/j.tins.2010.01.006" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2Fj.tins.2010.01.006">
            Article
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Play%20it%20again%3A%20reactivation%20of%20waking%20experience%20and%20memory&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2010.01.006&amp;volume=33&amp;pages=220-229&amp;publication_year=2010&amp;author=O%E2%80%99Neill%2CJ&amp;author=Pleydell-Bouverie%2CB&amp;author=Dupret%2CD&amp;author=Csicsvari%2CJ">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR23">
           Lin, L.-J. Reinforcement learning for robots using neural networks. Technical Report, DTIC Document. (1993)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR24">
           Riedmiller, M. Neural fitted Q iteration - first experiences with a data efficient neural reinforcement learning method.
           <i>
            Mach. Learn.: ECML
           </i>
           <b>
            3720
           </b>
           , 317–328 (Springer, 2005)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20fitted%20Q%20iteration%20-%20first%20experiences%20with%20a%20data%20efficient%20neural%20reinforcement%20learning%20method&amp;journal=Mach.%20Learn.%3A%20ECML&amp;volume=3720&amp;pages=317-328&amp;publication_year=2005&amp;author=Riedmiller%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR25">
           Van der Maaten, L. J. P. &amp; Hinton, G. E. Visualizing high-dimensional data using t-SNE.
           <i>
            J. Mach. Learn. Res.
           </i>
           <b>
            9
           </b>
           , 2579–2605 (2008)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1225.68219">
            MATH
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Visualizing%20high-dimensional%20data%20using%20t-SNE&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=9&amp;pages=2579-2605&amp;publication_year=2008&amp;author=Van%20der%20Maaten%2CLJP&amp;author=Hinton%2CGE">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR26">
           Lange, S. &amp; Riedmiller, M. Deep auto-encoder neural networks in reinforcement learning.
           <i>
            Proc. Int. Jt. Conf. Neural. Netw.
           </i>
           1–8 (2010)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20auto-encoder%20neural%20networks%20in%20reinforcement%20learning&amp;pages=1-8&amp;publication_year=2010&amp;author=Lange%2CS&amp;author=Riedmiller%2CM">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR27">
           Law, C.-T. &amp; Gold, J. I. Reinforcement learning can account for associative and perceptual learning on a visual decision task.
           <i>
            Nature Neurosci.
           </i>
           <b>
            12
           </b>
           , 655 (2009)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nn.2304" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnn.2304">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BD1MXks12ktbw%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Reinforcement%20learning%20can%20account%20for%20associative%20and%20perceptual%20learning%20on%20a%20visual%20decision%20task&amp;journal=Nature%20Neurosci.&amp;doi=10.1038%2Fnn.2304&amp;volume=12&amp;publication_year=2009&amp;author=Law%2CC-T&amp;author=Gold%2CJI">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR28">
           Sigala, N. &amp; Logothetis, N. K. Visual categorization shapes feature selectivity in the primate temporal cortex.
           <i>
            Nature
           </i>
           <b>
            415
           </b>
           , 318–320 (2002)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/415318a" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F415318a">
            Article
           </a>
           <a data-track="click" data-track-action="ads reference" data-track-label="link" href="http://adsabs.harvard.edu.proxy.lib.ohio-state.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2002Natur.415..318S">
            ADS
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BD38Xptlajsg%3D%3D">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20categorization%20shapes%20feature%20selectivity%20in%20the%20primate%20temporal%20cortex&amp;journal=Nature&amp;doi=10.1038%2F415318a&amp;volume=415&amp;pages=318-320&amp;publication_year=2002&amp;author=Sigala%2CN&amp;author=Logothetis%2CNK">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR29">
           Bendor, D. &amp; Wilson, M. A. Biasing the content of hippocampal replay during sleep.
           <i>
            Nature Neurosci.
           </i>
           <b>
            15
           </b>
           , 1439–1444 (2012)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nn.3203" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnn.3203">
            Article
           </a>
           <a data-track="click" data-track-action="cas reference" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/articles/cas-redirect/1:CAS:528:DC%2BC38Xht12js7bO">
            CAS
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Biasing%20the%20content%20of%20hippocampal%20replay%20during%20sleep&amp;journal=Nature%20Neurosci.&amp;doi=10.1038%2Fnn.3203&amp;volume=15&amp;pages=1439-1444&amp;publication_year=2012&amp;author=Bendor%2CD&amp;author=Wilson%2CMA">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR30">
           Moore, A. &amp; Atkeson, C. Prioritized sweeping: reinforcement learning with less data and less real time.
           <i>
            Mach. Learn.
           </i>
           <b>
            13
           </b>
           , 103–130 (1993)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Prioritized%20sweeping%3A%20reinforcement%20learning%20with%20less%20data%20and%20less%20real%20time&amp;journal=Mach.%20Learn.&amp;volume=13&amp;pages=103-130&amp;publication_year=1993&amp;author=Moore%2CA&amp;author=Atkeson%2CC">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR31">
           Jarrett, K., Kavukcuoglu, K., Ranzato, M. A. &amp; LeCun, Y. What is the best multi-stage architecture for object recognition?
           <i>
            Proc. IEEE. Int. Conf. Comput. Vis.
           </i>
           2146–2153 (2009)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20is%20the%20best%20multi-stage%20architecture%20for%20object%20recognition&amp;pages=2146-2153&amp;publication_year=2009&amp;author=Jarrett%2CK&amp;author=Kavukcuoglu%2CK&amp;author=Ranzato%2CMA&amp;author=LeCun%2CY">
            Google Scholar
           </a>
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR32">
           Nair, V. &amp; Hinton, G. E. Rectified linear units improve restricted Boltzmann machines.
           <i>
            Proc. Int. Conf. Mach. Learn.
           </i>
           807–814 (2010)
          </p>
         </li>
         <li class="c-reading-companion__reference-item">
          <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR33">
           Kaelbling, L. P., Littman, M. L. &amp; Cassandra, A. R. Planning and acting in partially observable stochastic domains.
           <i>
            Artificial Intelligence
           </i>
           <b>
            101
           </b>
           , 99–134 (1994)
          </p>
          <p class="c-reading-companion__reference-links">
           <a data-track="click" data-track-action="article reference" data-track-label="10.1016/S0004-3702(98)00023-X" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0004-3702%2898%2900023-X">
            Article
           </a>
           <a data-track="click" data-track-action="mathscinet reference" data-track-label="link" href="http://www-ams-org.proxy.lib.ohio-state.edu/mathscinet-getitem?mr=1641530">
            MathSciNet
           </a>
           <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Planning%20and%20acting%20in%20partially%20observable%20stochastic%20domains&amp;journal=Artificial%20Intelligence&amp;doi=10.1016%2FS0004-3702%2898%2900023-X&amp;volume=101&amp;pages=99-134&amp;publication_year=1994&amp;author=Kaelbling%2CLP&amp;author=Littman%2CML&amp;author=Cassandra%2CAR">
            Google Scholar
           </a>
          </p>
         </li>
        </ol>
       </div>
      </div>
     </div>
    </div>
   </aside>
  </div>
  <footer class="composite-layer" itemscope="" itemtype="http://schema.org/Periodical">
   <meta content="Springer Nature" itemprop="publisher"/>
   <div class="u-mt-16 u-mb-16">
    <div class="u-container">
     <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
      <p class="c-meta u-ma-0 u-flex-shrink">
       <span class="c-meta__item">
        Nature (
        <i>
         Nature
        </i>
        )
       </span>
       <span class="c-meta__item">
        <abbr title="International Standard Serial Number">
         ISSN
        </abbr>
        <span itemprop="onlineIssn">
         1476-4687
        </span>
        (online)
       </span>
       <span class="c-meta__item">
        <abbr title="International Standard Serial Number">
         ISSN
        </abbr>
        <span itemprop="printIssn">
         0028-0836
        </span>
        (print)
       </span>
      </p>
     </div>
    </div>
   </div>
   <div class="c-footer">
    <div class="u-hide-print" data-track-component="footer">
     <h2 class="u-visually-hidden">
      nature.com sitemap
     </h2>
     <div class="c-footer__container">
      <div class="c-footer__grid c-footer__group--separator">
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         About Nature Portfolio
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="about us" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/npg_/company_info/index.html">
           About us
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="press releases" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/npg_/press_room/press_releases.html">
           Press releases
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="press office" data-track-label="link" href="https://press-nature-com.proxy.lib.ohio-state.edu/">
           Press office
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="contact us" data-track-label="link" href="https://support-nature-com.proxy.lib.ohio-state.edu/support/home">
           Contact us
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Discover content
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="journals a-z" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/siteindex">
           Journals A-Z
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="article by subject" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/subjects/">
           Articles by subject
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nano" data-track-label="link" href="https://nano-nature-com.proxy.lib.ohio-state.edu/">
           Nano
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="protocol exchange" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/protocolexchange/">
           Protocol Exchange
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature index" data-track-label="link" href="https://www.natureindex.com/">
           Nature Index
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Publishing policies
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Nature portfolio policies" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/authors/editorial_policies/">
           Nature portfolio policies
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="open access" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nature-research/open-access">
           Open access
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Author &amp; Researcher services
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="reprints and permissions" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/reprints/">
           Reprints &amp; permissions
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="data research service" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/authors/research-data">
           Research data
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="language editing" data-track-label="link" href="https://authorservices-springernature-com.proxy.lib.ohio-state.edu/language-editing/">
           Language editing
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="scientific editing" data-track-label="link" href="https://authorservices-springernature-com.proxy.lib.ohio-state.edu/scientific-editing/">
           Scientific editing
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature masterclasses" data-track-label="link" href="https://masterclasses-nature-com.proxy.lib.ohio-state.edu/">
           Nature Masterclasses
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="live expert trainer-led workshops" data-track-label="link" href="https://masterclasses-nature-com.proxy.lib.ohio-state.edu/live-expert-trainer-led/23649702">
           Live Expert Trainer-led workshops
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="research solutions" data-track-label="link" href="https://solutions-springernature-com.proxy.lib.ohio-state.edu/">
           Research Solutions
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Libraries &amp; institutions
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="librarian service and tools" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians/tools-services">
           Librarian service &amp; tools
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="librarian portal" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians/manage-your-account/librarianportal">
           Librarian portal
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="open research" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/openresearch/about-open-access/information-for-institutions/">
           Open research
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Recommend to library" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians/recommend-to-your-library">
           Recommend to library
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Advertising &amp; partnerships
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="advertising" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/product/digital-advertising/">
           Advertising
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="partnerships and services" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/">
           Partnerships &amp; Services
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="media kits" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/media-kits/">
           Media kits
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track-action="branded content" data-track-label="link" href="https://partnerships-nature-com.proxy.lib.ohio-state.edu/product/branded-content-native-advertising/">
           Branded
                        content
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Career development
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature careers" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/naturecareers">
           Nature Careers
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature conferences" data-track-label="link" href="https://conferences-nature-com.proxy.lib.ohio-state.edu">
           Nature
           <span class="u-visually-hidden">
           </span>
           Conferences
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature events" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/natureevents/">
           Nature
           <span class="u-visually-hidden">
           </span>
           events
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading u-mt-0">
         Regional websites
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature africa" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/natafrica">
           Nature Africa
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature china" data-track-label="link" href="http://www.naturechina.com">
           Nature China
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature india" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nindia">
           Nature India
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature Italy" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/natitaly">
           Nature Italy
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature japan" data-track-label="link" href="https://www-natureasia-com.proxy.lib.ohio-state.edu/ja-jp/">
           Nature Japan
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature korea" data-track-label="link" href="https://www-natureasia-com.proxy.lib.ohio-state.edu/ko-kr/">
           Nature Korea
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="nature middle east" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/nmiddleeast/">
           Nature Middle East
          </a>
         </li>
        </ul>
       </div>
      </div>
     </div>
     <div class="c-footer__container">
      <ul class="c-footer__links">
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="privacy policy" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/privacy">
         Privacy
                Policy
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="use of cookies" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/cookies">
         Use
                of cookies
        </a>
       </li>
       <li class="c-footer__item">
        <button class="optanon-toggle-display c-footer__link" data-cc-action="preferences" data-track="click" data-track-action="manage cookies" data-track-label="link" onclick="javascript:;">
         Your privacy choices/Manage cookies
        </button>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="legal notice" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/legal-notice">
         Legal
                notice
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="accessibility statement" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/accessibility-statement">
         Accessibility
                statement
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="terms and conditions" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/info/terms-and-conditions">
         Terms &amp; Conditions
        </a>
       </li>
       <li class="c-footer__item">
        <a class="c-footer__link" data-track="click" data-track-action="california privacy statement" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/ccpa">
         Your US state privacy rights
        </a>
       </li>
      </ul>
     </div>
    </div>
    <div class="c-footer__container">
     <a class="c-footer__link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/">
      <img alt="Springer Nature" height="20" loading="lazy" src="/static/images/logos/sn-logo-white-ea63208b81.svg" width="200"/>
     </a>
     <p class="c-footer__legal" data-test="copyright">
      © 2023 Springer Nature Limited
     </p>
    </div>
   </div>
   <div aria-hidden="true" class="u-visually-hidden">
    <!--?xml version="1.0" encoding="UTF-8"?-->
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
     <defs>
      <path d="M0 .74h56.72v55.24H0z" id="a">
      </path>
     </defs>
     <symbol id="icon-access" viewbox="0 0 18 18">
      <path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-account" viewbox="0 0 18 18">
      <path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-alert" viewbox="0 0 18 18">
      <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-broad" viewbox="0 0 16 16">
      <path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)">
      </path>
     </symbol>
     <symbol id="icon-arrow-down" viewbox="0 0 16 16">
      <path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-left" viewbox="0 0 16 16">
      <path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-right" viewbox="0 0 16 16">
      <path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-sub" viewbox="0 0 16 16">
      <path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-arrow-up" viewbox="0 0 16 16">
      <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-article" viewbox="0 0 18 18">
      <path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-audio" viewbox="0 0 18 18">
      <path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-block" viewbox="0 0 24 24">
      <path d="m0 0h24v24h-24z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-book" viewbox="0 0 18 18">
      <path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-broad" viewbox="0 0 24 24">
      <path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)">
      </path>
     </symbol>
     <symbol id="icon-calendar" viewbox="0 0 18 18">
      <path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-cart" viewbox="0 0 18 18">
      <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z">
      </path>
     </symbol>
     <symbol id="icon-chevron-less" viewbox="0 0 10 10">
      <path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)">
      </path>
     </symbol>
     <symbol id="icon-chevron-more" viewbox="0 0 10 10">
      <path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)">
      </path>
     </symbol>
     <symbol id="icon-chevron-right" viewbox="0 0 10 10">
      <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
      </path>
     </symbol>
     <symbol id="icon-circle-fill" viewbox="0 0 16 16">
      <path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-circle" viewbox="0 0 16 16">
      <path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-citation" viewbox="0 0 18 18">
      <path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-close" viewbox="0 0 16 16">
      <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-collections" viewbox="0 0 18 18">
      <path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-compare" viewbox="0 0 18 18">
      <path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-download-file" viewbox="0 0 18 18">
      <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-download" viewbox="0 0 16 16">
      <path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-editors" viewbox="0 0 18 18">
      <path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-email" viewbox="0 0 18 18">
      <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-error" viewbox="0 0 18 18">
      <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-ethics" viewbox="0 0 18 18">
      <path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-expand">
      <path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-explore" viewbox="0 0 18 18">
      <path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-filter" viewbox="0 0 16 16">
      <path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z">
      </path>
     </symbol>
     <symbol id="icon-home" viewbox="0 0 18 18">
      <path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-image" viewbox="0 0 18 18">
      <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-info" viewbox="0 0 18 18">
      <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-institution" viewbox="0 0 18 18">
      <path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-location" viewbox="0 0 18 18">
      <path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-minus" viewbox="0 0 16 16">
      <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-newsletter" viewbox="0 0 18 18">
      <path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-orcid" viewbox="0 0 18 18">
      <path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-plus" viewbox="0 0 16 16">
      <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-print" viewbox="0 0 18 18">
      <path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-search" viewbox="0 0 22 22">
      <path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-social-facebook" viewbox="0 0 24 24">
      <path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-social-twitter" viewbox="0 0 24 24">
      <path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-social-youtube" viewbox="0 0 24 24">
      <path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-subject-medicine" viewbox="0 0 18 18">
      <path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-success" viewbox="0 0 18 18">
      <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-table" viewbox="0 0 18 18">
      <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-tick-circle" viewbox="0 0 24 24">
      <path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-tick" viewbox="0 0 16 16">
      <path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-update" viewbox="0 0 18 18">
      <path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-upload" viewbox="0 0 18 18">
      <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-video" viewbox="0 0 18 18">
      <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-warning" viewbox="0 0 18 18">
      <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-altmetric">
      <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm-1.886 9.684-1.101 1.845a1 1 0 0 1-.728.479l-.13.008H3.056a9.001 9.001 0 0 0 17.886 0l-4.564-.001-2.779 4.156c-.454.68-1.467.55-1.758-.179l-.038-.113-1.69-6.195ZM12 3a9.001 9.001 0 0 0-8.947 8.016h4.533l2.017-3.375c.452-.757 1.592-.6 1.824.25l1.73 6.345 1.858-2.777a1 1 0 0 1 .707-.436l.124-.008h5.1A9.001 9.001 0 0 0 12 3Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-checklist-banner" viewbox="0 0 56.69 56.69">
      <path d="M0 0h56.69v56.69H0z" style="fill:none">
      </path>
      <clippath id="b">
       <use style="overflow:visible" xlink:href="#a">
       </use>
      </clippath>
      <path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round">
      </path>
      <path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round">
      </path>
     </symbol>
     <symbol id="icon-chevron-down" viewbox="0 0 16 16">
      <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)">
      </path>
     </symbol>
     <symbol id="icon-citations">
      <path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM5.483 14.35c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Zm5 0c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-eds-checklist" viewbox="0 0 32 32">
      <path d="M19.2 1.333a3.468 3.468 0 0 1 3.381 2.699L24.667 4C26.515 4 28 5.52 28 7.38v19.906c0 1.86-1.485 3.38-3.333 3.38H7.333c-1.848 0-3.333-1.52-3.333-3.38V7.38C4 5.52 5.485 4 7.333 4h2.093A3.468 3.468 0 0 1 12.8 1.333h6.4ZM9.426 6.667H7.333c-.36 0-.666.312-.666.713v19.906c0 .401.305.714.666.714h17.334c.36 0 .666-.313.666-.714V7.38c0-.4-.305-.713-.646-.714l-2.121.033A3.468 3.468 0 0 1 19.2 9.333h-6.4a3.468 3.468 0 0 1-3.374-2.666Zm12.715 5.606c.586.446.7 1.283.253 1.868l-7.111 9.334a1.333 1.333 0 0 1-1.792.306l-3.556-2.333a1.333 1.333 0 1 1 1.463-2.23l2.517 1.651 6.358-8.344a1.333 1.333 0 0 1 1.868-.252ZM19.2 4h-6.4a.8.8 0 0 0-.8.8v1.067a.8.8 0 0 0 .8.8h6.4a.8.8 0 0 0 .8-.8V4.8a.8.8 0 0 0-.8-.8Z">
      </path>
     </symbol>
     <symbol id="icon-eds-i-external-link-medium" viewbox="0 0 24 24">
      <path d="M9 2a1 1 0 1 1 0 2H4.6c-.371 0-.6.209-.6.5v15c0 .291.229.5.6.5h14.8c.371 0 .6-.209.6-.5V15a1 1 0 0 1 2 0v4.5c0 1.438-1.162 2.5-2.6 2.5H4.6C3.162 22 2 20.938 2 19.5v-15C2 3.062 3.162 2 4.6 2H9Zm6 0h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L22 3v6a1 1 0 0 1-2 0V5.414l-6.693 6.693a1 1 0 0 1-1.414-1.414L18.584 4H15a1 1 0 0 1-.993-.883L14 3a1 1 0 0 1 1-1Z">
      </path>
     </symbol>
     <symbol id="icon-eds-i-info-filled-medium" viewbox="0 0 24 24">
      <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 9h-1.5a1 1 0 0 0-1 1l.007.117A1 1 0 0 0 10.5 12h.5v4H9.5a1 1 0 0 0 0 2h5a1 1 0 0 0 0-2H13v-5a1 1 0 0 0-1-1Zm0-4.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 5.5Z">
      </path>
     </symbol>
     <symbol id="icon-eds-menu" viewbox="0 0 24 24">
      <path d="M21.09 5c.503 0 .91.448.91 1s-.407 1-.91 1H2.91C2.406 7 2 6.552 2 6s.407-1 .91-1h18.18Zm-3.817 6c.401 0 .727.448.727 1s-.326 1-.727 1H2.727C2.326 13 2 12.552 2 12s.326-1 .727-1h14.546Zm3.818 6c.502 0 .909.448.909 1s-.407 1-.91 1H2.91c-.503 0-.91-.448-.91-1s.407-1 .91-1h18.18Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-eds-search" viewbox="0 0 24 24">
      <path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-eds-small-arrow-right" viewbox="0 0 16 16">
      <g fill-rule="evenodd" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
       <path d="M2 8.092h12M8 2l6 6.092M8 14.127l6-6.035">
       </path>
      </g>
     </symbol>
     <symbol id="icon-eds-user-single" viewbox="0 0 24 24">
      <path d="M12 12c5.498 0 10 4.001 10 9a1 1 0 0 1-2 0c0-3.838-3.557-7-8-7s-8 3.162-8 7a1 1 0 0 1-2 0c0-4.999 4.502-9 10-9Zm0-11a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm0 2a3 3 0 1 1 0 6 3 3 0 0 1 0-6Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-email-new" viewbox="0 0 24 24">
      <path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z">
      </path>
     </symbol>
     <symbol id="icon-expand-image" viewbox="0 0 18 18">
      <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-github" viewbox="0 0 100 100">
      <path clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill-rule="evenodd">
      </path>
     </symbol>
     <symbol id="icon-mentions">
      <g fill-rule="evenodd" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
       <path d="M22 15.255A9.373 9.373 0 0 1 8.745 2L22 15.255ZM15.477 8.523l4.215-4.215">
       </path>
       <path d="m7 13-5 9h10l-1-5">
       </path>
      </g>
     </symbol>
     <symbol id="icon-metrics-accesses">
      <path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM7.708 13.308c2.004 0 3.969 1.198 5.802 2.995l.23.23a2.285 2.285 0 0 1 .009 3.233C11.853 21.693 9.799 23 7.707 23c-2.091 0-4.14-1.305-6.033-3.226a2.285 2.285 0 0 1-.007-3.233c1.9-1.93 3.949-3.233 6.04-3.233Zm0 2c-1.396 0-3.064 1.062-4.623 2.644a.285.285 0 0 0 .007.41C4.642 19.938 6.311 21 7.707 21c1.397 0 3.069-1.065 4.623-2.644a.285.285 0 0 0 0-.404l-.23-.229c-1.487-1.451-3.064-2.415-4.393-2.415Zm-.036 1.077a1.77 1.77 0 1 1 .126 3.537 1.77 1.77 0 0 1-.126-3.537Zm.072 1.538a.23.23 0 1 0-.017.461.23.23 0 0 0 .017-.46Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-metrics">
      <path d="M3 22a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v7h4V8a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v13a1 1 0 0 1-.883.993L21 22H3Zm17-2V9h-4v11h4Zm-6-8h-4v8h4v-8ZM8 4H4v16h4V4Z" fill-rule="nonzero">
      </path>
     </symbol>
     <symbol id="icon-springer-arrow-left">
      <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z">
      </path>
     </symbol>
     <symbol id="icon-springer-arrow-right">
      <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z">
      </path>
     </symbol>
     <symbol id="icon-submit-open" viewbox="0 0 16 17">
      <path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero">
      </path>
     </symbol>
    </svg>
   </div>
  </footer>
  <div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif" data-component-expirydays="30" data-component-id="nature-briefing-banner" data-component-trigger-scroll-percentage="15" data-track="in-view" data-track-action="in-view" data-track-category="nature briefing" data-track-label="Briefing banner visible: Flagship">
   <div class="c-site-messages__banner-large">
    <div class="c-site-messages__close-container">
     <button class="c-site-messages__close" data-track="click" data-track-category="nature briefing" data-track-label="Briefing banner dismiss: Flagship">
      <svg aria-hidden="true" focusable="false" height="25px" version="1.1" viewbox="0 0 25 25" width="25px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
       <title>
        Close banner
       </title>
       <defs>
       </defs>
       <g fill="none" fill-rule="evenodd" stroke="none" stroke-width="1">
        <rect height="25" opacity="0" width="25" x="0" y="0">
        </rect>
        <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff">
        </path>
       </g>
      </svg>
      <span class="visually-hidden">
       Close
      </span>
     </button>
    </div>
    <div class="c-site-messages__form-container">
     <div class="grid grid-12 last">
      <div class="grid grid-4">
       <img alt="Nature Briefing" height="40" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250"/>
       <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">
        Sign up for the
        <em>
         Nature Briefing
        </em>
        newsletter — what matters in science, free to your inbox daily.
       </p>
      </div>
      <div class="grid grid-8 last">
       <form action="https://briefer.public.springernature.app/" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship" method="post">
        <input id="briefing-banner-signup-form-input-track-originReferralPoint" name="track_originReferralPoint" type="hidden" value="MainBriefingBanner"/>
        <input id="briefing-banner-signup-form-input-track-formType" name="track_formType" type="hidden" value="DirectEmailBanner"/>
        <input id="gdpr_tick" name="gdpr_tick" type="hidden" value="false"/>
        <input id="marketing" name="marketing" type="hidden" value="false"/>
        <input id="marketing_tick" name="marketing_tick" type="hidden" value="false"/>
        <input id="brieferEntryPoint" name="brieferEntryPoint" type="hidden" value="MainBriefingBanner"/>
        <label class="nature-briefing-banner__email-label" for="emailAddress">
         Email address
        </label>
        <div class="nature-briefing-banner__email-wrapper">
         <input class="nature-briefing-banner__email-input box-sizing text14" data-test-element="briefing-emailbanner-email-input" id="emailAddress" name="emailAddress" placeholder="e.g. jo.smith@university.ac.uk" required="" type="email" value=""/>
         <input id="defaultNewsletter" name="N:nature_briefing_daily" type="hidden" value="true"/>
         <button class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button" type="submit">
          Sign up
         </button>
        </div>
        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
         <input class="nature-briefing-banner__checkbox-checkbox" data-test-element="briefing-emailbanner-gdpr-checkbox" id="gdpr-briefing-banner-checkbox" name="gdpr" required="" type="checkbox" value="true"/>
         <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">
          I agree my information will be processed in accordance with the
          <em>
           Nature
          </em>
          and Springer Nature Limited
          <a href="https://www-nature-com.proxy.lib.ohio-state.edu/info/privacy">
           Privacy Policy
          </a>
          .
         </label>
        </div>
       </form>
      </div>
     </div>
    </div>
   </div>
   <div class="c-site-messages__banner-small">
    <div class="c-site-messages__close-container">
     <button class="c-site-messages__close" data-track="click" data-track-category="nature briefing" data-track-label="Briefing banner dismiss: Flagship">
      <svg aria-hidden="true" focusable="false" height="25px" version="1.1" viewbox="0 0 25 25" width="25px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
       <title>
        Close banner
       </title>
       <defs>
       </defs>
       <g fill="none" fill-rule="evenodd" stroke="none" stroke-width="1">
        <rect height="25" opacity="0" width="25" x="0" y="0">
        </rect>
        <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff">
        </path>
       </g>
      </svg>
      <span class="visually-hidden">
       Close
      </span>
     </button>
    </div>
    <div class="c-site-messages__content text14">
     <span class="c-site-messages--nature-briefing__strapline strong">
      Get the most important science stories of the day, free in your inbox.
     </span>
     <a class="nature-briefing__link text14 sans-serif" data-test-element="briefing-banner-link" data-track="click" data-track-category="nature briefing" data-track-label="Small-screen banner CTA to site" href="https://www-nature-com.proxy.lib.ohio-state.edu/briefing/signup/?brieferEntryPoint=MainBriefingBanner" rel="noreferrer noopener" target="_blank">
      Sign up for Nature Briefing
     </a>
    </div>
   </div>
  </div>
  <noscript>
   <img alt="" height="0" hidden="" src="https://verify-nature-com.proxy.lib.ohio-state.edu/verify/nature.png" style="display: none" width="0"/>
  </noscript>
  <script async="" src="//content.readcube.com/ping?doi=10.1038/nature14236&amp;format=js&amp;last_modified=2015-02-26">
  </script>
  <img alt="" class="u-visually-hidden" height="1" src="/m1e17p2n/article/nature14236" width="1"/>
  <div class="c-cookie-banner">
   <div class="c-cookie-banner__container">
    <p>
     This website sets only cookies which are necessary for it to function. They are used to enable core functionality such as security, network management and accessibility. These cookies cannot be switched off in our systems. You may disable these by changing your browser settings, but this may affect how the website functions. Please view our privacy policy for further details on how we process your information.
     <button class="c-cookie-banner__dismiss">
      Dismiss
     </button>
    </p>
   </div>
  </div>
  <script src="https://verify-nature-com.proxy.lib.ohio-state.edu/verify/nature.min.js">
  </script>
 </body>
</html>
