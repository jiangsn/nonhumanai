Main:
Current damage recovery in deployed robots typically involves two phases: self-diagnosis, followed by selection of the best pre-designed contingency plan9,13,14,15. Such self-diagnosing robots are expensive, because self-monitoring sensors are expensive, and are difficult to design, because robot engineers cannot foresee every possible situation: this approach often fails either because the diagnosis is incorrect13,14 or because an appropriate contingency plan is not provided15. Injured animals respond differently (see Fig. 1a): they learn by trial and error how to compensate for damage (for example, learning which limp minimizes pain)16,17. Similarly, trial-and-error learning algorithms could allow robots to creatively discover compensatory behaviours without being limited to their designers’ assumptions about how damage may occur and how to compensate for each type of damage. However, state-of-the-art learning algorithms are impractical because of the “curse of dimensionality”12: the fastest algorithms, from fields like reinforcement learning12 and modular robotics10,11, depend on human demonstrations12 or take 15 min or more even for relatively small search spaces (for example, 6–12 parameters, requiring 15–30 min10,11). Algorithms without these limitations take several hours12. Damage recovery would be much more practical and effective if robots adapted as creatively and quickly as animals do (for example, in less than 2 min) in larger search spaces and without expensive, self-diagnosing sensors. Figure 1: Using the Intelligent Trial and Error (IT&E) algorithm, robots, like animals, can quickly adapt to recover from damage.a, Most animals can find a compensatory behaviour after an injury. Without relying on predefined compensatory behaviours, they learn how to avoid behaviours that are painful or no longer effective. Photo credit: Michael Lloyd/The Oregonian (2012). b, An undamaged, hexapod robot. RGB-D stands for red, green, blue, depth. c, One type of damage the hexapod may have to cope with (broken leg). d, After damage occurs, in this case making the robot unable to walk fast and in a straight line, damage recovery via IT&E begins. The robot tests different types of behaviours from an automatically generated map of the behaviour–performance space. After each test, the robot updates its predictions of which behaviours will perform well despite the damage. In this way, the robot rapidly discovers an effective compensatory behaviour. 
PowerPoint slide
Here we show that rapid adaptation can be achieved by guiding an intelligent trial-and-error learning algorithm with an automatically generated, pre-computed behaviour–performance map that predicts the performance of thousands of different behaviours (Supplementary Video 1). Current learning algorithms either start with no knowledge of the search space12 or with minimal knowledge from a few human demonstrations12,18. Our hypothesis is that animals understand the space of possible behaviours and their value from previous experience19, and that animals adapt by intelligently selecting tests that validate or invalidate whole families of promising compensatory behaviours. The key insight here is that robots could do the same. Our robots store knowledge from previous experience in the form of a map of the behaviour–performance space. Guided by this map, a damaged robot tries different types of behaviours that are predicted to perform well and, as tests are conducted, updates its estimates of the performance of those types of behaviours. The process ends when the robot predicts that the most effective behaviour has already been discovered. A key assumption is that information about many different behaviours of the undamaged robot will still be useful after damage, because some of these behaviours will still be functional despite the damage. The results of our experiments support this assumption for all the types of damage we tested, revealing that a robot can quickly discover a way to compensate for damage (for example, see Fig. 1c) without a detailed mechanistic understanding of its cause, as occurs with animals. We call this approach ‘Intelligent Trial and Error’ (IT&E) (see Fig. 1d). The behaviour–performance map is created using a novel algorithm and a simulation of the robot, which can be either a standard physics simulator or automatically discovered14. The robot’s designers need only describe the dimensions of the space of possible behaviours and a performance measure. For instance, walking gaits could be described by how much each leg touches the ground (a behavioural measure) and speed (a performance measure). An alternative gait behavioural measure could be the percentage of time a robot’s torso has positive pitch, roll, and yaw angles. For grasping, performance could be measured by the amount of surface contact, and it has been demonstrated that 90% of effective poses for the 21-degree-of-freedom human hand can be captured by a three-dimensional behavioural space describing the principal components of ways in which hand-poses commonly vary20. To fill in the behaviour–performance map, an optimization algorithm simultaneously searches for a high-performing solution at each point in the behavioural space (Fig. 2a, b and Extended Data Fig. 1). This step requires simulating millions of behaviours, but needs to be performed only once per robot design before deployment (Supplementary Methods). Figure 2: The two steps of IT&E.a, b, Creating the behaviour–performance map. A user reduces a high-dimensional search space to a low-dimensional behaviour space by defining dimensions along which behaviours vary. In simulation, the high-dimensional space is then automatically searched to find a high-performing behaviour at each point in the low-dimensional behaviour space, creating a behaviour–performance map of the performance potential of each location in the low-dimensional space. In our hexapod robot experiments, the behaviour space is six-dimensional, with each dimension representing the portion of time that one leg is in contact with the ground. The confidence regarding the accuracy of the predicted performance for each behaviour in the behaviour–performance map is initially low because no tests on the physical robot have been conducted. c–e, Adaptation step: after damage, the robot selects a promising behaviour, tests it, updates the predicted performance of that behaviour in the behaviour–performance map, and allocates a high confidence to this performance prediction. The predicted performances of nearby behaviours—and confidence in those predictions—are likely to be similar to the tested behaviour and are thus updated accordingly. This select–test–update loop is repeated until a tested behaviour on the physical robot performs better than 90% of the best predicted performance in the behaviour–performance map, a value that can decrease with each test (Extended Data Fig. 1). The algorithm that selects which behaviour to test next balances between choosing the behaviour with the highest predicted performance and behaviours that are different from those tested so far. Overall, the IT&E approach presented here rapidly locates which types of behaviours are least affected by the damage to find an effective, compensatory behaviour. 
PowerPoint slide
A low confidence is assigned to the predicted performance of behaviours stored in this behaviour–performance map because they have not been tried in reality (Fig. 2b and Extended Data Fig. 1). During the robot’s mission, if performance drops below a user-defined threshold (owing either to damage or to a different environment), the robot selects the most promising behaviour from the behaviour–performance map, tests it, and measures its performance. The robot subsequently updates its prediction for that behaviour and nearby behaviours, assigns high confidence to these predictions (Fig. 2c, d and Extended Data Fig. 1), and continues the select–test–update process until it finds a satisfactory compensatory behaviour (Fig. 2e and Extended Data Fig. 1). All of these ideas are technically captured via a Gaussian process model21, which approximates the performance function with already acquired data, and a Bayesian optimization procedure22,23, which exploits this model to search for the maximum of the performance function (see Supplementary Methods). The robot selects which behaviours to test by maximizing an information acquisition function that balances exploration (selecting points whose performance is uncertain) and exploitation (selecting points whose performance is expected to be high) (see Supplementary Methods). The selected behaviour is tested on the physical robot and the actual performance is recorded. The algorithm updates the expected performance of the tested behaviour and lowers its uncertainty. These updates are propagated to neighbouring solutions in the behavioural space by updating the Gaussian process (Supplementary Methods). These updated performance and confidence distributions affect which behaviour is tested next. This select–test–update loop repeats until the robot finds a behaviour whose measured performance is greater than some user-defined percentage (here, 90%) of the best performance predicted for any behaviour in the behaviour–performance map (Supplementary Methods). We first tested our algorithm on a hexapod robot that needs to walk as fast as possible (Fig. 1b, d). The robot has 18 motors, an onboard computer, and a depth camera that allows the robot to estimate its walking speed (Supplementary Methods). The gait is parameterized by 36 real-valued parameters (Supplementary Methods) that describe, for each joint, the amplitude of oscillation, phase shift, and duty cycle (the fraction of the period that the joint angle is on one side of the midline). The behaviour space is six-dimensional, where each dimension is the proportion of time the ith leg spends in contact with the ground (that is, the duty factor)1 (Supplementary Methods). The behaviour–performance map created contains approximately 13,000 different gaits (Supplementary Video 2). We tested our robot under six different conditions: undamaged (C1 in Fig. 3a), four different structural failures (C2–C5 in Fig. 3a), and a temporary leg repair (C6 in Fig. 3a). We compare the walking speed of resultant gaits with a widely used, classic, hand-designed tripod gait1 (Supplementary Methods). For each of the six damage conditions, we ran our adaptation step five times for each of eight independently generated behaviour–performance maps (with the default ‘duty factor’ behavioural description), leading to 6 × 5 × 8 = 240 experiments in total. We also ran our adaptation step five times on eight independently generated behaviour–performance maps defined by an alternative behavioural description (‘body orientation’, see Supplementary Methods) on two damage conditions (Fig. 3b, c), leading to 2 × 5 × 8 = 80 additional experiments. Figure 3: Main experiments and results.a, Conditions tested on the physical hexapod robot. C1, The undamaged robot. C2, One leg is shortened by half. C3, One leg is unpowered. C4, One leg is missing. C5, Two legs are missing. C6, An imperfect, makeshift repair to the tip of one leg (by a human operator). b, Performance after adaptation. Box plots represent IT&E. The central circle is the median, the edges of the box are the 25th and 75th percentiles, the whiskers extend to the most extreme data points that are not considered outliers, and outliers are plotted individually. Yellow stars represent the performance of the handmade reference tripod gait (Supplementary Methods). Conditions C1–C6 are tested five times each for eight independently created behaviour–performance maps with the ‘duty factor’ behaviour description (that is, 40 experiments per damage condition, Supplementary Methods). Damage conditions C1 and C3 are also tested five times each for eight independently created behaviour–performance maps with the ‘body orientation’ behaviour description (Supplementary Methods). c, Time and number of trials required to adapt. Box plots represent IT&E. d, Robotic arm experiment. The eight-jointed, planar robot arm has to drop a ball into a bin. e, Example conditions tested on the physical robotic arm. C1, One joint is stuck at 45 degrees. C2, One joint has a permanent 45° offset. C3, One broken and one offset joint. Each of these damage conditions was replicated with 15 independent maps. A total of 14 conditions were tested (Extended Data Fig. 7). f, Time and number of trials required to reach within 5 cm of the bin centre. Each condition is tested with 15 independently created behaviour–performance maps. 
PowerPoint slide

Source data
When the robot is undamaged (C1 in Fig. 3a), our approach yields dynamic gaits that are 30% faster than the classic reference gait (Fig. 3b, median 0.32 m s−1, 5th and 95th percentiles [0.26 m s−1; 0.36 m s−1] versus 0.24 m s−1), suggesting that IT&E is a good search algorithm for automatically producing successful robot behaviours, putting aside damage recovery. In all the damage scenarios, the reference gait is no longer effective (around 0.04 m s−1 for the four damage conditions, C2–C5 in Fig. 3b). After IT&E, the compensatory gaits achieve a reasonably fast speed (>0.15 m s−1) and are between three and seven times more efficient than the reference gait for that damage condition (gaits given in metres per second: 0.24 [0.18; 0.31] versus 0.04 for C2; 0.22 [0.18; 0.26] versus 0.03 for C3; 0.21 [0.17; 0.26] versus 0.04 for C4; 0.17 [0.12; 0.24] versus 0.05 for C5; and 0.3 [0.21; 0.33] versus 0.12 for C6). These experiments demonstrate that IT&E allows the robot both to initially learn fast gaits and to recover reliably after physical damage. Additional experiments reveal that these capabilities are substantially faster than state-of-the-art algorithms (Bayesian optimization and policy gradient, Extended Data Fig. 2), and that IT&E can help with another major challenge in robotics: adapting to new environments (such as differently sloped terrain, Extended Data Fig. 3). On the undamaged or repaired robot (C6 in Fig. 3a), IT&E learns a walking gait in less than 30 s (Fig. 3c, the undamaged robot takes 24 s [16 s; 41 s] in 3 [2; 5] physical trials and the repaired robot takes 29 s [16 s; 82 s] in 3.5 [2; 10] trials). For the five damage scenarios, the robot adapts in approximately one minute (66 s [24 s; 134 s] in 8 [3; 16] trials). It is possible that for certain types of damage the prior information from the undamaged robot does not help, and could even hurt, in learning a compensatory behaviour (for example, if the map does not contain a compensatory behaviour). We did not find such a case in our experiments with the hexapod robot, but we did find a case on another robot in which the prior information provided little benefit (experiment 1 in the Supplementary Information). Our results are qualitatively unchanged when using different behavioural characterizations, including randomly choosing six descriptors among 63 possibilities (Fig. 3b, c and Extended Data Fig. 4). Additional experiments show that reducing the high-dimensional parameter space to a low-dimensional behaviour space via the behaviour–performance map is the key component for IT&E: standard Bayesian optimization in the original parameter space does not find working controllers (gaits) (Extended Data Fig. 2). We investigated how the behaviour–performance map is updated when the robot loses a leg (C4 in Fig. 3a). Initially, the map predicts large areas of high performance. During adaptation, these areas disappear because the behaviours do not work well on the damaged robot. IT&E quickly identifies one of the few remaining high-performance behaviours (Fig. 4 and Extended Data Figs 5 and 6). Figure 4: An example behaviour–performance map.This map stores high-performing behaviours at each point in a six-dimensional behaviour space. Each dimension is the portion of time that each leg is in contact with the ground. The behavioural space is discretized at five values for each dimension (0; 0.25; 0.5; 0.75 and 1). Each coloured pixel represents the highest-performing behaviour discovered during map creation at that point in the behaviour space. The matrices visualize the six-dimensional behavioural space in two dimensions according to the legend at the top left. The behaviour–performance map is created with a simulated robot (bottom left) in the Open Dynamics Engine physics simulator (http://www.ode.org). The left matrix is a pre-adaptation map produced by the map creation algorithm. During adaptation, the map is updated as tests are conducted (in this case, for the damage condition where the robot is missing one leg: C4 in Fig. 3a). The right matrix shows the state of the map after a compensatory behaviour is discovered. The arrows and white circles represent the order in which behaviours were tested on the physical robot. The red circle is the final, discovered, compensatory behaviour. Among other areas, high-performing behaviours can be found for the damaged robot in the first two columns of the third dimension. These columns represent behaviours that use the central-left leg least, which is the leg that is missing. 
PowerPoint slide

Source data
The same damage recovery approach can be applied to any robot, such as a robotic arm. We tested 14 different damage conditions with a planar, eight-jointed robotic arm (Fig. 3d–f and Extended Data Fig. 7). The behaviour–performance map’s behavioural dimensions are the x, y position of the hand at the end of the arm. To show that the map-generating performance measure can be different from the ultimate performance measure, and to encourage smooth arm movements, the performance measure during map-generation is minimizing the variance of the eight specified motor angles (Supplementary Methods). During adaptation, performance is measured as distance to the target. As with the hexapod robot, our approach discovers a compensatory behaviour in less than 2 min, usually in less than 30 s, and with fewer than ten trials (Fig. 3f and Extended Data Fig. 7). Although animals do not use the specific algorithm we present, there are parallels between IT&E and animal learning. Damage recovery in animals may occur without learning—for instance, due to the built-in robustness of evolved control loops24—but if such pre-programmed robustness fails, many animals turn to learning19. As in our robot, such learning probably exploits an animal’s intuitions about how its intact body works to experiment with different behaviours to find what works best. Also like animals25, IT&E allows the quick identification of working behaviours with a few, diverse tests instead of trying behaviours at random or trying small modifications to the best behaviour found so far. Additionally, the Bayesian optimization procedure followed by our robot appears similar to the technique employed by humans when they optimize an unknown function23, and there is strong evidence that animal brains learn probability distributions, combine them with prior knowledge, and act as Bayesian optimizers26,27. An additional parallel is that IT&E primes the robot for creativity during a motionless period, after which the generated ideas are tested. This process is reminiscent of the finding that some animals start the day with new ideas that they may quickly disregard after experimenting with them28, and more generally, that sleep improves creativity on cognitive tasks29. A final parallel is that the simulator and Gaussian process components of IT&E are two forms of predictive models, which are known to exist in animals14,30. Overall, we have shown that IT&E has parallels in biology and makes robots behave more like animals by endowing them with the ability to adapt rapidly to unforeseen circumstances.