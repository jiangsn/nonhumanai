Problem setup and overview: An input video \( Q \) (a) and a proxy CAD model \( S \) (b) are expanded using a deformable model built on the fly (c). The user manually defines the object contour through an intuitive graph-based foreground extraction (d) and roughly aligns the CAD model on the image (e) to obtain the camera/object position. Our method automatically refines the mesh and aligns it non-rigidly with the image by computing \(\mathscr {T}( S )\) through an energy minimization process (f). Finally, the user can interact with the targeted object (g) by manipulating its geometry and by editing its local and global physical properties gathered in the set \(\phi \) and the function \(\mathbf {F}\). The resulting composite video \( Q ^*\) maintains visual fidelity \(\mathscr {A}\) using image-based inverse rendering