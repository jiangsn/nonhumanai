<html class="js" lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="pc,mobile" name="applicable-device"/>
  <meta content="width=device-width, initial-scale=1" name="viewport"/>
  <meta content="Yes" name="access"/>
  <meta content="1268d79b5e96aecf3ff2a7dac04ad990" name="360-site-verification"/>
  <title>
   3-D Depth Reconstruction from a Single Still Image | International Journal of Computer Vision
  </title>
  <meta content="@SpringerLink" name="twitter:site"/>
  <meta content="summary_large_image" name="twitter:card"/>
  <meta content="Content cover image" name="twitter:image:alt"/>
  <meta content="3-D Depth Reconstruction from a Single Still Image" name="twitter:title"/>
  <meta content="International Journal of Computer Vision - We consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by..." name="twitter:description"/>
  <meta content="https://static-content.springer.com/cover/journal/11263/76/1.jpg" name="twitter:image"/>
  <meta content="11263" name="journal_id"/>
  <meta content="3-D Depth Reconstruction from a Single Still Image" name="dc.title"/>
  <meta content="International Journal of Computer Vision 2007 76:1" name="dc.source"/>
  <meta content="text/html" name="dc.format"/>
  <meta content="Springer" name="dc.publisher"/>
  <meta content="2007-08-16" name="dc.date"/>
  <meta content="OriginalPaper" name="dc.type"/>
  <meta content="En" name="dc.language"/>
  <meta content="2007 Springer Science+Business Media, LLC" name="dc.copyright"/>
  <meta content="2007 Springer Science+Business Media, LLC" name="dc.rights"/>
  <meta content="journalpermissions@springernature.com" name="dc.rightsAgent"/>
  <meta content="We consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured indoor and outdoor environments which include forests, sidewalks, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the value of the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a hierarchical, multiscale Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models the depths and the relation between depths at different points in the image. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. We further propose a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone." name="dc.description"/>
  <meta content="1573-1405" name="prism.issn"/>
  <meta content="International Journal of Computer Vision" name="prism.publicationName"/>
  <meta content="2007-08-16" name="prism.publicationDate"/>
  <meta content="76" name="prism.volume"/>
  <meta content="1" name="prism.number"/>
  <meta content="OriginalPaper" name="prism.section"/>
  <meta content="53" name="prism.startingPage"/>
  <meta content="69" name="prism.endingPage"/>
  <meta content="2007 Springer Science+Business Media, LLC" name="prism.copyright"/>
  <meta content="journalpermissions@springernature.com" name="prism.rightsAgent"/>
  <meta content="https://link-springer-com.proxy.lib.ohio-state.edu/article/10.1007/s11263-007-0071-y" name="prism.url"/>
  <meta content="doi:10.1007/s11263-007-0071-y" name="prism.doi"/>
  <meta content="https://link-springer-com.proxy.lib.ohio-state.edu/content/pdf/10.1007/s11263-007-0071-y.pdf" name="citation_pdf_url"/>
  <meta content="https://link-springer-com.proxy.lib.ohio-state.edu/article/10.1007/s11263-007-0071-y" name="citation_fulltext_html_url"/>
  <meta content="International Journal of Computer Vision" name="citation_journal_title"/>
  <meta content="Int J Comput Vis" name="citation_journal_abbrev"/>
  <meta content="Springer US" name="citation_publisher"/>
  <meta content="1573-1405" name="citation_issn"/>
  <meta content="3-D Depth Reconstruction from a Single Still Image" name="citation_title"/>
  <meta content="76" name="citation_volume"/>
  <meta content="1" name="citation_issue"/>
  <meta content="2008/01" name="citation_publication_date"/>
  <meta content="2007/08/16" name="citation_online_date"/>
  <meta content="53" name="citation_firstpage"/>
  <meta content="69" name="citation_lastpage"/>
  <meta content="Article" name="citation_article_type"/>
  <meta content="" name="citation_fulltext_world_readable"/>
  <meta content="en" name="citation_language"/>
  <meta content="doi:10.1007/s11263-007-0071-y" name="dc.identifier"/>
  <meta content="10.1007/s11263-007-0071-y" name="DOI"/>
  <meta content="123703" name="size"/>
  <meta content="10.1007/s11263-007-0071-y" name="citation_doi"/>
  <meta content="http://api.springer-com.proxy.lib.ohio-state.edu/xmldata/jats?q=doi:10.1007/s11263-007-0071-y&amp;api_key=" name="citation_springer_api_url"/>
  <meta content="We consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collec" name="description"/>
  <meta content="Saxena, Ashutosh" name="dc.creator"/>
  <meta content="Chung, Sung H." name="dc.creator"/>
  <meta content="Ng, Andrew Y." name="dc.creator"/>
  <meta content="Computer Imaging, Vision, Pattern Recognition and Graphics" name="dc.subject"/>
  <meta content="Artificial Intelligence" name="dc.subject"/>
  <meta content="Image Processing and Computer Vision" name="dc.subject"/>
  <meta content="Pattern Recognition" name="dc.subject"/>
  <meta content="citation_journal_title=ACM Transactions on Graphics; citation_title=SCAPE: shape completion and animation of people; citation_author=D. Anguelov, P. Srinivasan, D. Koller, S. Thrun, J. Rodgers, J. Davis; citation_volume=24; citation_issue=3; citation_publication_date=2005; citation_pages=408-416; citation_doi=10.1145/1073204.1073207; citation_id=CR1" name="citation_reference"/>
  <meta content="citation_journal_title=International Journal of Computer Vision; citation_title=Performance of optical flow techniques; citation_author=J. L. Barron, D. J. Fleet, S. S. Beauchemin; citation_volume=12; citation_publication_date=1994; citation_pages=43-77; citation_doi=10.1007/BF01420984; citation_id=CR2" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence; citation_title=Advances in computational stereo; citation_author=M. Z. Brown, D. Burschka, G. D. Hager; citation_volume=25; citation_issue=8; citation_publication_date=2003; citation_pages=993-1008; citation_doi=10.1109/TPAMI.2003.1217603; citation_id=CR3" name="citation_reference"/>
  <meta content="citation_journal_title=Nature Neuroscience; citation_title=Top-down influences on stereoscopic depth-perception; citation_author=I. Bulthoff, H. Bulthoff, P. Sinha; citation_volume=1; citation_publication_date=1998; citation_pages=254-257; citation_doi=10.1038/699; citation_id=CR4" name="citation_reference"/>
  <meta content="
Cornelis, N., Leibe, B., Cornelis, K., &amp; Van Gool, L. (2006). 3d city modeling using cognitive loops. In Video proceedings of CVPR (VPCVPR).
" name="citation_reference"/>
  <meta content="citation_journal_title=International Journal of Computer Vision; citation_title=Single view metrology; citation_author=A. Criminisi, I. Reid, A. Zisserman; citation_volume=40; citation_publication_date=2000; citation_pages=123-148; citation_doi=10.1023/A:1026598000963; citation_id=CR6" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence; citation_title=Performance analysis of stereo, vergence, and focus as depth cues for active vision; citation_author=S. Das, N. Ahuja; citation_volume=17; citation_issue=12; citation_publication_date=1995; citation_pages=1213-1219; citation_doi=10.1109/34.476513; citation_id=CR7" name="citation_reference"/>
  <meta content="citation_title=Laws’ texture energy in 
                           ; citation_inbook_title=Machine vision: theory, algorithms, practicalities; citation_publication_date=1997; citation_id=CR8; citation_author=E. R. Davies; citation_publisher=Academic Press" name="citation_reference"/>
  <meta content="
Delage, E., Lee, H., &amp; Ng, A. Y. (2005). Automatic single-image 3d reconstructions of indoor Manhattan world scenes. In 12th International Symposium of Robotics Research (ISRR).
" name="citation_reference"/>
  <meta content="
Delage, E., Lee, H., &amp; Ng, A. Y. (2006). A dynamic Bayesian network model for autonomous 3D reconstruction from a single indoor image. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="citation_title=Computer vision: a modern approach; citation_publication_date=2003; citation_id=CR11; citation_author=D. A. Forsyth; citation_author=J. Ponce; citation_publisher=Prentice Hall" name="citation_reference"/>
  <meta content="
Frueh, C., &amp; Zakhor, A. (2003). Constructing 3D city models by merging ground-based and airborne views. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="
Gini, G., &amp; Marchi, A. (2002). Indoor robot navigation with single camera vision. In PRIS.
" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Chameleons use accommodation cues to judge distance; citation_author=L. Harkness; citation_volume=267; citation_publication_date=1977; citation_pages=346-349; citation_doi=10.1038/267346a0; citation_id=CR14" name="citation_reference"/>
  <meta content="
He, X., Zemel, R., &amp; Perpinan, M. (2004). Multiscale conditional random fields for image labeling. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence; citation_title=Example-based photometric stereo: Shape reconstruction with general, varying brdfs; citation_author=A. Hertzmann, S. M. Seitz; citation_volume=27; citation_issue=8; citation_publication_date=2005; citation_pages=1254-1264; citation_doi=10.1109/TPAMI.2005.158; citation_id=CR16" name="citation_reference"/>
  <meta content="
Hoiem, D., Efros, A. A., &amp; Herbert, M. (2005a). Geometric context from a single image. In International conference on computer vision (ICCV).
" name="citation_reference"/>
  <meta content="
Hoiem, D., Efros, A. A., &amp; Herbert, M. (2005b). Automatic photo pop-up. In ACM SIGGRAPH.
" name="citation_reference"/>
  <meta content="
Hoiem, D., Efros, A. A., &amp; Herbert, M. (2006). Putting objects in perspective. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="
Huang, J., Lee, A. B., &amp; Mumford, D. (2000). Statistics of range images. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Pattern Analysis and Machine Intelligence; citation_title=Probabilistic fusion of stereo with color and contrast for bilayer segmentation; citation_author=V. Kolmogorov, A. Criminisi, A. Blake, G. Cross, C. Rother; citation_volume=28; citation_issue=9; citation_publication_date=2006; citation_pages=1480-1492; citation_doi=10.1109/TPAMI.2006.193; citation_id=CR21" name="citation_reference"/>
  <meta content="
Konishi, S., &amp; Yuille, A. (2000). Statistical cues for domain specific image segmentation with performance analysis. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="
Kumar, S., &amp; Hebert, M. (2003). Discriminative fields for modeling spatial dependencies in natural images. In Neural information processing systems (NIPS) (Vol. 16).
" name="citation_reference"/>
  <meta content="
Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional random fields: probabilistic models for segmenting and labeling sequence data. In International conference on machine learning (ICML).
" name="citation_reference"/>
  <meta content="
Lindeberg, T., &amp; Garding, J. (1993). Shape from texture from a multi-scale perspective. In International conference on computer vision (ICCV).
" name="citation_reference"/>
  <meta content="citation_journal_title=Nature News and Views; citation_title=Looking down is looking up; citation_author=J. M. Loomis; citation_volume=414; citation_publication_date=2001; citation_pages=155-156; citation_doi=10.1038/35102648; citation_id=CR26" name="citation_reference"/>
  <meta content="citation_journal_title=International Journal of Computer Vision; citation_title=Geotensity: combining motion and lighting for 3d surface reconstruction; citation_author=A. Maki, M. Watanabe, C. Wiles; citation_volume=48; citation_issue=2; citation_publication_date=2002; citation_pages=75-90; citation_doi=10.1023/A:1016057422703; citation_id=CR27" name="citation_reference"/>
  <meta content="citation_journal_title=Journal of the Optical Society of America A; citation_title=Preattentive texture discrimination with early vision mechanisms; citation_author=J. Malik, P. Perona; citation_volume=7; citation_issue=5; citation_publication_date=1990; citation_pages=923-932; citation_doi=10.1364/JOSAA.7.000923; citation_id=CR28" name="citation_reference"/>
  <meta content="citation_journal_title=International Journal of Computer Vision; citation_title=Computing local surface orientation and shape from texture for curved surfaces; citation_author=J. Malik, R. Rosenholtz; citation_volume=23; citation_issue=2; citation_publication_date=1997; citation_pages=149-168; citation_doi=10.1023/A:1007958829620; citation_id=CR29" name="citation_reference"/>
  <meta content="
Michels, J., Saxena, A., &amp; Ng, A. Y. (2005). High speed obstacle avoidance using monocular vision and reinforcement learning. In 22nd international conference on machine learning (ICML).
" name="citation_reference"/>
  <meta content="
Moldovan, T. M., Roth, S., &amp; Black, M. J. (2006). Denoising archival films using a learned Bayesian model. In International conference on image processing (ICIP).
" name="citation_reference"/>
  <meta content="
Mortensen, E. N., Deng, H., &amp; Shapiro, L. (2005). A SIFT descriptor with global context. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="
Murphy, K., Torralba, A., &amp; Freeman, W. T. (2003). Using the forest to see the trees: a graphical model relating features, objects, and scenes. In Neural information processing systems (NIPS) (Vol. 16).
" name="citation_reference"/>
  <meta content="
Nagai, T., Naruse, T., Ikehara, M., &amp; Kurematsu, A. (2002). Hmm-based surface reconstruction from single images. In IEEE international conference on image processing (ICIP).
" name="citation_reference"/>
  <meta content="
Narasimhan, S. G., &amp; Nayar, S. K. (2003). Shedding light on the weather. In Computer vision and pattern recognition (CVPR)
                        " name="citation_reference"/>
  <meta content="citation_journal_title=Journal of Electronic Imaging; citation_title=Efficient spatial-domain implementation of a multiscale image representation based on Gabor functions; citation_author=O. Nestares, R. Navarro, J. Portilia, A. Tabernero; citation_volume=7; citation_issue=1; citation_publication_date=1998; citation_pages=166-173; citation_doi=10.1117/1.482638; citation_id=CR36" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence; citation_title=Building the gist of a scene: the role of global image features in recognition; citation_author=A. Oliva, A. Torralba; citation_volume=155; citation_publication_date=2006; citation_pages=23-36; citation_id=CR37" name="citation_reference"/>
  <meta content="citation_journal_title=Vision Research; citation_title=Sparse coding with an over-complete basis set: a strategy employed by v1?; citation_author=B. A. Olshausen, D. J. Field; citation_volume=37; citation_publication_date=1997; citation_pages=3311-3325; citation_doi=10.1016/S0042-6989(97)00169-7; citation_id=CR38" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Robust and optimal use of information in stereo vision; citation_author=J. Porrill, J. P. Frisby, W. J. Adams, D. Buckley; citation_volume=397; citation_publication_date=1999; citation_pages=63-66; citation_doi=10.1038/16244; citation_id=CR39" name="citation_reference"/>
  <meta content="
Quartulli, M., &amp; Datcu, M. (2001). Bayesian model based city reconstruction from high resolution ISAR data. In IEEE/ISPRS joint workshop remote sensing and data fusion over urban areas.
" name="citation_reference"/>
  <meta content="
Saxena, A., Anand, A., &amp; Mukerjee, A. (2004). Robust facial expression recognition using spatially localized geometric model. In International conf systemics, cybernetics and informatics (ICSCI).
" name="citation_reference"/>
  <meta content="
Saxena, A., Chung, S. H., &amp; Ng, A. Y. (2005). Learning depth from single monocular images. In Neural information processing system (NIPS) (Vol. 18).
" name="citation_reference"/>
  <meta content="
Saxena, A., Driemeyer, J., Kearns, J., Osondu, C., &amp; Ng, A. Y. (2006a). Learning to grasp novel objects using vision. In 10th international symposium on experimental robotics (ISER).
" name="citation_reference"/>
  <meta content="
Saxena, A., Sun, M., Agarwal, R., &amp; Ng, A. Y. (2006b). Learning 3-d scene structure from a single still image. Stanford Technical Report, November 2006.
" name="citation_reference"/>
  <meta content="
Saxena, A., Driemeyer, J., Kearns, J., &amp; Ng, A. Y. (2006c). Robotic grasping of novel objects. In Neural information processing systems (NIPS) (Vol. 19).
" name="citation_reference"/>
  <meta content="
Saxena, A., Schulte, J., &amp; Ng, A. Y. (2007). Depth estimation using monocular and stereo cues. In International joint conference on artificial intelligence (IJCAI).
" name="citation_reference"/>
  <meta content="citation_journal_title=International Journal of Computer Vision; citation_title=A taxonomy and evaluation of dense two-frame stereo correspondence algorithms; citation_author=D. Scharstein, R. Szeliski; citation_volume=47; citation_issue=1; citation_publication_date=2002; citation_pages=7-42; citation_doi=10.1023/A:1014573219977; citation_id=CR47" name="citation_reference"/>
  <meta content="
Scharstein, D., &amp; Szeliski, R. (2003) High-accuracy stereo depth maps using structured light. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="citation_title=Visual perception; citation_publication_date=1999; citation_id=CR49; citation_author=S. H. Schwartz; citation_publisher=Appleton and Lange" name="citation_reference"/>
  <meta content="
Serre, T., Wolf, L., &amp; Poggio, T. (2005). Object recognition with features inspired by visual cortex. In Computer vision and pattern recognition (CVPR).
" name="citation_reference"/>
  <meta content="citation_title=Wavelets and filter banks; citation_publication_date=1997; citation_id=CR51; citation_author=G. Strang; citation_author=T. Nguyen; citation_publisher=Wellesley-Cambridge Press" name="citation_reference"/>
  <meta content="
Sudderth, E. B., Torralba, A., Freeman, W. T., &amp; Willisky, A. S. (2006). Depth from familiar objects: A hierarchical model for 3D scenes. In Computer vision and pattern recognition (CVPR)
                        " name="citation_reference"/>
  <meta content="
Szeliski, R. (1990). Bayesian modeling of uncertainty in low-level vision. In International conference on computer vision (ICCV).
" name="citation_reference"/>
  <meta content="
Thrun, S., &amp; Wegbreit, B. (2005). Shape from symmetry. In International conference on computer vision (ICCV).
" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence; citation_title=Depth estimation from image structure; citation_author=A. Torralba, A. Oliva; citation_volume=24; citation_issue=9; citation_publication_date=2002; citation_pages=1-13; citation_doi=10.1109/TPAMI.2002.1033214; citation_id=CR55" name="citation_reference"/>
  <meta content="
Torresani, L., &amp; Hertzmann, A. (2004). Automatic non-rigid 3D modeling from video. In European conference on computer vision.
" name="citation_reference"/>
  <meta content="citation_title=Foundations of vision; citation_publication_date=1995; citation_id=CR57; citation_author=B. A. Wandell; citation_publisher=Sinauer Associates" name="citation_reference"/>
  <meta content="citation_journal_title=Nature Neuroscience; citation_title=3D shape perception from combined depth cues in human visual cortex; citation_author=A. E. Welchman, A. Deubelius, V. Conrad, H. H. Bülthoff, Z. Kourtzi; citation_volume=8; citation_publication_date=2005; citation_pages=820-827; citation_doi=10.1038/nn1461; citation_id=CR58" name="citation_reference"/>
  <meta content="citation_journal_title=Nature; citation_title=Self-motion and the perception of stationary objects; citation_author=M. Wexler, F. Panerai, I. Lamouret, J. Droulez; citation_volume=409; citation_publication_date=2001; citation_pages=85-88; citation_doi=10.1038/35051081; citation_id=CR59" name="citation_reference"/>
  <meta content="citation_journal_title=Proceedings IEEE; citation_title=Multiresolution Markov models for signal and image processing; citation_author=A. S. Willsky; citation_volume=90; citation_issue=8; citation_publication_date=2002; citation_pages=1396-1458; citation_doi=10.1109/JPROC.2002.800717; citation_id=CR60" name="citation_reference"/>
  <meta content="citation_journal_title=Letters to Nature; citation_title=Perceiving distance accurately by a directional process of integrating ground information; citation_author=B. Wu, T. L. Ooi, Z. J. He; citation_volume=428; citation_publication_date=2004; citation_pages=73-77; citation_doi=10.1038/nature02350; citation_id=CR61" name="citation_reference"/>
  <meta content="citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence; citation_title=Shape from shading: a survey; citation_author=R. Zhang, P.-S. Tsai, J. E. Cryer, M. Shah; citation_volume=21; citation_issue=8; citation_publication_date=1999; citation_pages=690-706; citation_doi=10.1109/34.784284; citation_id=CR62" name="citation_reference"/>
  <meta content="citation_journal_title=ACM Computing Surveys; citation_title=Face recognition: a literature survey; citation_author=W. Zhao, R. Chellappa, P. J. Phillips, A. Rosenfield; citation_volume=35; citation_publication_date=2003; citation_pages=399-458; citation_doi=10.1145/954339.954342; citation_id=CR63" name="citation_reference"/>
  <meta content="Saxena, Ashutosh" name="citation_author"/>
  <meta content="asaxena@cs.stanford.edu" name="citation_author_email"/>
  <meta content="Computer Science Department, Stanford University, Stanford, USA" name="citation_author_institution"/>
  <meta content="Chung, Sung H." name="citation_author"/>
  <meta content="codedeft@cs.stanford.edu" name="citation_author_email"/>
  <meta content="Computer Science Department, Stanford University, Stanford, USA" name="citation_author_institution"/>
  <meta content="Ng, Andrew Y." name="citation_author"/>
  <meta content="ang@cs.stanford.edu" name="citation_author_email"/>
  <meta content="Computer Science Department, Stanford University, Stanford, USA" name="citation_author_institution"/>
  <meta content="telephone=no" name="format-detection"/>
  <meta content="2008/01/01" name="citation_cover_date"/>
  <meta content="https://link-springer-com.proxy.lib.ohio-state.edu/article/10.1007/s11263-007-0071-y" property="og:url"/>
  <meta content="article" property="og:type"/>
  <meta content="SpringerLink" property="og:site_name"/>
  <meta content="3-D Depth Reconstruction from a Single Still Image - International Journal of Computer Vision" property="og:title"/>
  <meta content="We consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured indoor and outdoor environments which include forests, sidewalks, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the value of the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a hierarchical, multiscale Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models the depths and the relation between depths at different points in the image. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. We further propose a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone." property="og:description"/>
  <meta content="https://media-springernature-com.proxy.lib.ohio-state.edu/w200/springer-static/cover/journal/11263.jpg" property="og:image"/>
  <meta content="telephone=no" name="format-detection"/>
  <link href="/oscar-static/img/favicons/darwin/apple-touch-icon-92e819bf8a.png" rel="apple-touch-icon" sizes="180x180"/>
  <link href="/oscar-static/img/favicons/darwin/favicon-32x32-1435da3e82.png" rel="icon" sizes="32x32" type="image/png"/>
  <link href="/oscar-static/img/favicons/darwin/favicon-16x16-ed57f42bd2.png" rel="icon" sizes="16x16" type="image/png"/>
  <link data-test="shortcut-icon" href="/oscar-static/img/favicons/darwin/favicon-c6d59aafac.ico" rel="shortcut icon"/>
  <meta content="#e6e6e6" name="theme-color"/>
  <style>
   html{text-size-adjust:100%;line-height:1.15}body{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.5;margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#025e8d}sub{bottom:-.25em;font-size:75%;line-height:0;position:relative;vertical-align:baseline}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input{font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible}button{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[hidden]{display:none}button{cursor:pointer}
  </style>
  <style>
   @media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  body{background:#fff;color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;min-height:100%}a{color:#025e8d;text-decoration:underline;text-decoration-skip-ink:auto}button{cursor:pointer}img{border:0;height:auto;max-width:100%;vertical-align:middle}html{box-sizing:border-box;font-size:100%;height:100%;overflow-y:scroll}h1{font-size:2.25rem}h2{font-size:1.75rem}h1,h2,h3{font-weight:700;line-height:1.2}h3{font-size:1.5rem}body{font-size:1.125rem}*{box-sizing:inherit}p{margin-bottom:2rem;margin-top:0}p:last-of-type{margin-bottom:0}.c-breadcrumbs{color:#333;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs>li{display:inline}svg.c-breadcrumbs__chevron{fill:#333;height:10px;margin:0 .25rem;width:10px}.c-breadcrumbs--contrast,.c-breadcrumbs--contrast .c-breadcrumbs__link{color:#fff}.c-breadcrumbs--contrast svg.c-breadcrumbs__chevron{fill:#fff}@media only screen and (max-width:479px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;flex-direction:column;font-size:14px;min-width:0;padding:0}.c-card,.c-card__image{display:flex;overflow:hidden;position:relative}.c-card__image{justify-content:center;padding-bottom:56.25%}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-skip-link{background:#01324b;bottom:auto;color:#fff;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.l-with-sidebar{display:flex;flex-wrap:wrap}.l-with-sidebar>*{margin:0}.l-with-sidebar__sidebar{flex-basis:var(--with-sidebar--basis,400px);flex-grow:1}.l-with-sidebar>:not(.l-with-sidebar__sidebar){flex-basis:0px;flex-grow:999;min-width:var(--with-sidebar--min,53%)}.l-with-sidebar>:first-child{padding-right:4rem}@supports (gap:1em){.l-with-sidebar>:first-child{padding-right:0}.l-with-sidebar{gap:var(--with-sidebar--gap,4rem)}}.c-header{background-color:#fff;border-bottom:2px solid #01324b;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:16px;line-height:1.4;padding:8px 0 0}.c-header__container{align-items:center;display:flex;flex-wrap:nowrap;gap:8px 16px;justify-content:space-between;margin:0 auto 8px;max-width:1280px;padding:0 8px;position:relative}.c-header__nav{border-top:2px solid #cedbe0;padding-top:4px;position:relative}.c-header__nav-container{align-items:center;display:flex;flex-wrap:wrap;margin:0 auto 4px;max-width:1280px;padding:0 8px;position:relative}.c-header__nav-container>:not(:last-child){margin-right:32px}.c-header__link-container{align-items:center;display:flex;flex:1 0 auto;gap:8px 16px;justify-content:space-between}.c-header__list{list-style:none;margin:0;padding:0}.c-header__list-item{font-weight:700;margin:0 auto;max-width:1280px;padding:8px}.c-header__list-item:not(:last-child){border-bottom:2px solid #cedbe0}.c-header__item{color:inherit}@media only screen and (min-width:768px){.c-header__item--menu{display:none;visibility:hidden}.c-header__item--menu:first-child+*{margin-block-start:0}}.c-header__item--inline-links{display:none;visibility:hidden}@media only screen and (min-width:768px){.c-header__item--inline-links{display:flex;gap:16px 16px;visibility:visible}}.c-header__item--divider:before{border-left:2px solid #cedbe0;content:"";height:calc(100% - 16px);margin-left:-15px;position:absolute;top:8px}.c-header__brand a{display:block;line-height:1;padding:16px 8px;text-decoration:none}.c-header__brand img{height:24px;width:auto}.c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.c-header__link--static{flex:0 0 auto}.c-header__icon{fill:currentcolor;display:inline-block;font-size:24px;height:1em;transform:translate(0);vertical-align:bottom;width:1em}.c-header__icon+*{margin-left:8px}.c-header__expander{background-color:#ebf1f5}.c-header__search{padding:24px 0}@media only screen and (min-width:768px){.c-header__search{max-width:70%}}.c-header__search-container{position:relative}.c-header__search-label{color:inherit;display:inline-block;font-weight:700;margin-bottom:8px}.c-header__search-input{background-color:#fff;border:1px solid #000;padding:8px 48px 8px 8px;width:100%}.c-header__search-button{background-color:transparent;border:0;color:inherit;height:100%;padding:0 8px;position:absolute;right:0}.has-tethered.c-header__expander{border-bottom:2px solid #01324b;left:0;margin-top:-2px;top:100%;width:100%;z-index:10}@media only screen and (min-width:768px){.has-tethered.c-header__expander--menu{display:none;visibility:hidden}}.has-tethered .c-header__heading{display:none;visibility:hidden}.has-tethered .c-header__heading:first-child+*{margin-block-start:0}.has-tethered .c-header__search{margin:auto}.c-header__heading{margin:0 auto;max-width:1280px;padding:16px 16px 0}.c-masthead__colour-4{--background-color:#ff9500;--gradient-light:rgba(0,0,0,.5);--gradient-dark:rgba(0,0,0,.8)}.c-masthead{background:var(--background-color,#0070a8);position:relative}.c-masthead:after{background:radial-gradient(circle at top right,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)));bottom:0;content:"";left:0;position:absolute;right:0;top:0}@media only screen and (max-width:479px){.c-masthead:after{background:linear-gradient(225deg,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)))}}.c-masthead__container{color:#fff;margin:0 auto;max-width:1280px;padding:0 16px;position:relative;z-index:1}.c-meta{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;line-height:1.5;list-style:none;margin:0;padding:0}.c-meta__item{display:inline-block}.c-meta__item:not(:last-child){border-right:1px solid #999;margin-right:8px;padding-right:8px}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;position:relative;width:100%}.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #ccc;line-height:1.4;padding:16px}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--success .c-status-message__icon{color:#00b8b0}.app-checklist-banner{display:flex;flex:1 1 auto;font-size:1rem;justify-content:space-between;padding:16px}.app-checklist-banner--on-mobile{display:block;margin-bottom:32px}@media only screen and (min-width:1024px){.app-checklist-banner--on-mobile{display:none}}.app-checklist-banner__title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1.125rem;font-weight:700}.app-checklist-banner__icon-container{align-items:center;display:flex;flex:0 0 60px;justify-content:flex-end;width:60px}.app-checklist-banner__link{align-items:center;color:#004b83;display:inline-flex;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.app-checklist-banner__arrow-icon,.app-checklist-banner__paper-icon{fill:currentcolor;display:inline-block;transform:translate(0);vertical-align:text-top}.app-checklist-banner__paper-icon{height:36px!important;width:36px!important}.app-checklist-banner__arrow-icon{height:11px;margin:4px 0 0 8px;width:16px}.u-button{align-items:center;background-color:#01324b;background-image:none;border:4px solid transparent;border-radius:32px;cursor:pointer;display:inline-flex;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;font-weight:700;justify-content:center;line-height:1.3;margin:0;padding:16px 32px;position:relative;transition:all .2s ease 0s;width:auto}.u-button svg,.u-button--primary svg{fill:currentcolor}.u-button{text-decoration:none}.u-button,.u-button--primary{box-shadow:0 0 0 1px #01324b;color:#fff}.u-button--primary{background-color:#01324b;background-image:none;border:4px solid transparent;font-weight:700}.u-button--full-width{display:flex;width:100%}.u-clear-both{clear:both}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-display-flex{display:flex;width:100%}.u-flex-direction-column{flex-direction:column}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:768px){.u-hide-at-sm{display:none;visibility:hidden}}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-mt-0{margin-top:0}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-32{margin-bottom:32px}.u-sans-serif{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.u-serif{font-family:Merriweather,serif}h1,h2,h3{-webkit-font-smoothing:antialiased}p{overflow-wrap:break-word;word-break:break-word}.u-h4{font-size:1.25rem;font-weight:700;line-height:1.2}.c-article-header{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}@media only screen and (min-width:876px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:767px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#025e8d;border-color:transparent;color:#fff}.c-article-section__title{margin:0}@media only screen and (min-width:876px){.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #fff;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#025e8d;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{border:1px solid #d5d5d5;border-image:initial;border-left-width:0;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{font-size:1rem}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;font-size:1.25rem;font-weight:700;line-height:1.2;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-reading-companion__panel--active{display:block}.c-article-section__figure-description{font-size:1rem}.c-article-section__figure-description>*{margin-bottom:0}.c-cod{display:block;font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#025e8d;border:1px solid #025e8d;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#025e8d}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-pdf-download{display:flex}@media only screen and (min-width:768px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:767px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:768px){.c-pdf-download__text{padding-right:8px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:767px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:16px}.c-recommendations-title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.24;margin:0;padding-bottom:16px}.c-recommendations-close{background-color:transparent;border:0;cursor:pointer;height:2em;margin-right:-10px;margin-top:-5px;width:2em}.c-recommendations-authors{line-height:1.24;margin:0}.c-recommendations-list-container{position:relative}.c-recommendations-list{display:flex;flex-wrap:nowrap;justify-content:space-between;margin:0 auto;overflow-x:hidden;padding:0 0 16px;scroll-behavior:smooth;scroll-snap-type:x mandatory;width:calc(100% - 96px)}@media only screen and (max-width:767px){.c-recommendations-list{display:block;height:40vh;overflow-y:auto;width:100%}}.c-recommendations-list__item{display:flex;flex:0 0 calc(33.3333% - 32px);margin:0 16px;scroll-snap-align:center}@media only screen and (max-width:767px){.c-recommendations-list__item{margin:0;padding:0 0 16px}}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 16px 0 0;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #d5d5d5;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:#025e8d;text-decoration:none}@media only screen and (max-width:767px){.c-recommendations-column-switch{display:flex;flex-direction:column-reverse}}.js-greyout-page-background{background-color:rgba(34,34,34,.75);bottom:0;left:0;position:fixed;right:0;top:0}.c-meta{color:inherit}.app-article-metrics-bar p{margin:0}.app-article-masthead{display:flex;flex-direction:column;gap:16px 16px;padding:16px 0 24px}.app-article-masthead__info{display:flex;flex-direction:column;flex-grow:1}.app-article-masthead__brand{border-top:1px solid hsla(0,0%,100%,.8);display:flex;flex-direction:column;flex-shrink:0;gap:8px 8px;min-height:96px;padding:16px 0 0}.app-article-masthead__brand img{border:1px solid #fff;border-radius:1px;left:0;position:absolute;width:72px}.app-article-masthead__journal-link{display:block;font-size:1.125rem;font-weight:700;margin:0 0 8px;max-width:400px;padding:0 0 0 88px;position:relative}.app-article-masthead__journal-title{-webkit-box-orient:vertical;-webkit-line-clamp:3;display:-webkit-box;overflow:hidden}.app-article-masthead__submission-link{align-items:center;display:flex;font-size:1rem;gap:4px 4px;margin:0 0 0 88px}.app-article-masthead__buttons{display:flex;flex-flow:column wrap;gap:16px 16px}.app-article-masthead a{color:#fff}@media only screen and (min-width:768px){.app-article-masthead{flex-direction:row;gap:64px 64px;padding:24px 0 48px}.app-article-masthead__brand{border:0;padding:0}.app-article-masthead__brand img{position:static;width:auto}.app-article-masthead__buttons{align-items:center;flex-direction:row;margin-top:auto}.app-article-masthead__journal-link{display:flex;flex-direction:column;gap:24px 24px;margin:0 0 8px;padding:0}.app-article-masthead__submission-link{margin:0}.app-article-masthead .c-pdf-container{flex-grow:0}}@media only screen and (min-width:1024px){.app-article-masthead__brand{flex-basis:400px}}.app-article-masthead__buttons .c-pdf-container{justify-content:flex-start}.app-article-masthead .c-article-identifiers{font-size:.875rem;font-weight:300;line-height:1;margin:0 0 24px;overflow:hidden;padding:0}.app-article-masthead .c-article-identifiers *{color:#fff}.app-article-masthead .c-cod{display:none}.app-article-masthead .c-article-identifiers__item{border-left:1px solid #fff;border-right:0;margin:0 17px 12px -9px;padding:0 0 0 8px}@media only screen and (min-width:768px){.app-article-masthead .c-article-identifiers{margin:0 0 32px}}.app-article-metrics-bar a,.app-cite-as a{color:#222}.app-article-metrics-bar .app-article-metrics-bar__item{padding:16px 16px 0 0}.app-article-metrics-bar .app-article-metrics-bar__item--metrics{padding-right:0}.app-article-metrics-bar__icon{height:auto;margin-right:4px;margin-top:-4px;width:auto}.app-article-metrics-bar__arrow-icon{margin:4px 0 0 4px}.app-cite-as{flex-basis:100%;font-size:1rem;margin-top:0}.c-pdf-container{flex-grow:1}.c-pdf-download{margin-bottom:0}.app-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem}.app-article-metrics-bar__item{padding:16px 16px 16px 0}.app-article-metrics-bar__count{font-weight:700}.app-article-metrics-bar__label{font-weight:400;padding-left:4px}.c-article-sidebar{display:none}@media only screen and (min-width:1024px){.c-article-sidebar{display:block}}.c-cod__form{border-radius:12px}.c-cod .c-status-message{align-items:inherit;justify-content:center;margin-bottom:16px;padding-bottom:16px}.c-cod .c-status-message__icon{margin-top:4px}.c-article-body ol p,.c-article-body ul p,.c-cod .c-cod__prompt{margin-bottom:16px}.app-article-access .u-button--primary,.c-cod__row .u-button--primary{background-color:#025e8d;border:2px solid #025e8d;box-shadow:none;font-size:1rem;font-weight:400;gap:8px 8px;justify-content:center;padding:8px 24px}.app-article-access .u-button--primary svg,.c-cod__row .u-button--primary svg{margin:4px 0}.app-article-access .u-button--primary:hover,.c-cod__row .u-button--primary:hover{background-color:#fff}.c-cod__input{flex-basis:auto;width:100%}.c-article-title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:2.25rem;font-weight:700;line-height:1.2;margin:12px 0 16px}.c-reading-companion__figure-item figure{margin:0}@media only screen and (min-width:768px){.c-article-title{margin:16px 0 24px}}.c-article-section__title{border-bottom:1px solid #cedbe0;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1.75rem;font-weight:700;margin-bottom:16px;padding-bottom:8px}.app-checklist-banner{border:1px solid #cedbe0;border-radius:12px;margin:-16px 0 48px}.app-checklist-banner__title{margin:0 0 8px}@media only screen and (min-width:1024px){.app-checklist-banner{margin:0 0 24px}}.c-status-message{font-size:1rem}.c-article-section{line-height:1.8;margin-bottom:48px}.c-article-body{font-size:1.125rem}.c-reading-companion__figure-item{border-top-color:#cedbe0}.c-reading-companion__sticky{max-width:400px}.c-article-section .c-article-section__figure-description>*{font-size:1rem;margin-bottom:16px}.c-reading-companion__reference-item{border:0;padding:8px 0 24px}.c-article-authors-search__item .c-article-button{background:0 0;border:2px solid #025e8d;border-radius:32px;box-shadow:none;color:#025e8d;font-size:1rem;font-weight:700;line-height:1.5;margin:0;padding:8px 24px;transition:all .2s ease 0s;width:100%}.c-pdf-download{max-height:none}.c-pdf-download .u-button{background-color:#fff;border:2px solid #fff;color:#01324b;justify-content:center}.c-context-bar__container .c-pdf-download .u-button svg,.c-pdf-download .u-button svg{fill:currentcolor}.c-context-bar__container .c-pdf-download .u-button{background-image:none;border:2px solid;color:#fff}.c-context-bar__container .c-pdf-download .u-button,.c-pdf-download .u-button{box-shadow:none;font-size:1rem;font-weight:700;line-height:1.5;padding:8px 24px}.c-context-bar__container .c-pdf-download .u-button{background-color:#025e8d}.c-pdf-download__link .u-icon{padding-top:0}.c-card__title-recommendation .c-card__link{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}#recommendations{background:hsla(0,0%,100%,.8)}.c-reading-companion__tab{background-color:#eee;color:#025e8d}.c-reading-companion__tab--active{background:#fff;color:#222}.c-status-message--boxed{border-radius:12px}.c-article-associated-content__collection-title{font-size:1rem}.c-article-author-list a,.c-article-author-list a:visited,.c-article-satellite-subtitle a,.c-article-satellite-subtitle a:visited,.c-breadcrumbs__link,.c-breadcrumbs__link:hover,.c-breadcrumbs__link:visited{color:#222}.c-article-author-list svg{height:24px;margin:2px 0 0 6px;width:24px} }
  </style>
  <!-- Please see discussion: https://github.com/springernature/frontend-open-space/issues/316-->
  <!--TODO: Implement alternative to CTM in here if the discussion concludes we do not continue with CTM as a practice-->
  <link href="/oscar-static/app-springerlink/css/print-b8af42253b.css" media="print" rel="stylesheet"/>
  <link data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/core-darwin-dc3aba008e.css" media="all" onload="this.media='all';this.onload=null" rel="stylesheet"/>
  <link data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-darwin-article-0ec07c4edb.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null" rel="stylesheet"/>
  <script async="" src="//cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_SVG.js">
  </script>
  <script type="text/javascript">
   config = {
            env: 'live',
            site: '11263.springer.com',
            siteWithPath: '11263.springer.com' + window.location.pathname,
            twitterHashtag: '11263',
            cmsPrefix: 'https://studio-cms-springernature-com.proxy.lib.ohio-state.edu/studio/',
            
            
            
            
            publisherBrand: 'Springer',
            mustardcut: false
        };
  </script>
  <script data-consent="link-springer-com.proxy.lib.ohio-state.edu" src="/oscar-static/js/cookie-consent-es5-bundle-2b0f06c1e4.js">
  </script>
  <script>
   window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/s11263-007-0071-y","Page":"article","springerJournal":true,"page":{"attributes":{"environment":"live"}},"Country":"US","japan":false,"doi":"10.1007-s11263-007-0071-y","Journal Title":"International Journal of Computer Vision","Journal Id":11263,"Keywords":"Monocular vision, Learning depth, 3D reconstruction, Dense reconstruction, Markov random field, Depth estimation, Monocular depth, Stereo vision, Hand-held camera, Visual modeling","kwrd":["Monocular_vision","Learning_depth","3D_reconstruction","Dense_reconstruction","Markov_random_field","Depth_estimation","Monocular_depth","Stereo_vision","Hand-held_camera","Visual_modeling"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"N","Features":["doNotAutoAssociate","cobranding","doNotAutoAssociate","cobranding"],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":["3000266689","8200724141"],"businessPartnerIDString":"3000266689|8200724141"}},"Access Type":"open","Bpids":"3000266689, 8200724141","Bpnames":"OhioLINK Consortium, Ohio State University Libraries","BPID":["3000266689","8200724141"],"VG Wort Identifier":"vgzm.415900-10.1007-s11263-007-0071-y","Full HTML":"N","Subject Codes":["SCI","SCI22005","SCI21000","SCI22021","SCI2203X"],"pmc":["I","I22005","I21000","I22021","I2203X"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-1405","pissn":"0920-5691"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Computer Imaging, Vision, Pattern Recognition and Graphics","2":"Artificial Intelligence","3":"Image Processing and Computer Vision","4":"Pattern Recognition"},"secondarySubjectCodes":{"1":"I22005","2":"I21000","3":"I22021","4":"I2203X"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article"}];
  </script>
  <script>
   window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    ga4MeasurementId: 'G-B3E4QL2TPR',
                    ga360TrackingId: 'UA-26408784-1',
                    twitterId: 'o47a7',
                    ga4ServerUrl: 'https://collect-springer-com.proxy.lib.ohio-state.edu',
                    imprint: 'springerlink',
                    page: {
                        attributes:{
                            featureFlags: [{ name: 'darwin-orion', active: true }, { name: 'new_checklist_banner', active: true }],
                            darwinAvailable: true
                            
                        }
                    }
                
                });
  </script>
  <script>
   (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
  </script>
  <script>
   (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
  </script>
  <script class="js-entry">
   if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
                window.onArticlePage = true;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-17b14d8af4.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-f934ac6316.js', 'async': false},
            ];

            var bodyScripts = [
                
                    {'src': '/oscar-static/js/app-es5-bundle-774ca0a0f5.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/app-es6-bundle-047cc3c848.js', 'async': false, 'module': true}
                
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-e58c6b68c9.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-c14b406246.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
  </script>
  <script src="/oscar-static/js/airbrake-es5-bundle-f934ac6316.js">
  </script>
  <script src="/oscar-static/js/polyfill-es5-bundle-17b14d8af4.js">
  </script>
  <script data-test="gtm-head">
   window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
  </script>
  <script>
   (function (w, d, t) {
    function cc() {
        var h = w.location.hostname;
        var e = d.createElement(t),
        s = d.getElementsByTagName(t)[0];

        
        if (h.indexOf('springer.com') > -1 && h.indexOf('biomedcentral.com') === -1 && h.indexOf('springeropen.com') === -1) {
            if (h.indexOf('link-qa.springer.com') > -1 || h.indexOf('test-www.springer.com') > -1) {
                e.src = 'https://cmp-static-springer-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-17-36.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = 'https://cmp-static-springer-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-17-36.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            }
        } else if (h.indexOf('biomedcentral.com') > -1) {
            if (h.indexOf('biomedcentral.com.qa') > -1) {
                e.src = 'https://cmp-biomedcentral-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-15-25.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = 'https://cmp-biomedcentral-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-15-25.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            }
        } else if (h.indexOf('springeropen.com') > -1) {
            if (h.indexOf('springeropen.com.qa') > -1) {
                e.src = 'https://cmp-springernature-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-16-26.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = 'https://cmp-springernature-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-16-26.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            }
        } else if (h.indexOf('springernature.com') > -1) {
            if (h.indexOf('beta-qa.springernature.com') > -1) {
                e.src = 'https://cmp-springernature-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-49-28.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-NK22KLS')");
            } else {
                e.src = 'https://cmp-springernature-com.proxy.lib.ohio-state.edu/production_live/en/consent-bundle-49-28.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-NK22KLS')");
            }
        } else {
            e.src = '/oscar-static/js/cookie-consent-es5-bundle-2b0f06c1e4.js';
            e.setAttribute('data-consent', h);
        }
        s.insertAdjacentElement('afterend', e);
    }

    cc();
})(window, document, 'script');
  </script>
  <link href="https://link-springer-com.proxy.lib.ohio-state.edu/article/10.1007/s11263-007-0071-y" rel="canonical"/>
  <script type="application/ld+json">
   {"mainEntity":{"headline":"3-D Depth Reconstruction from a Single Still Image","description":"\nWe consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured indoor and outdoor environments which include forests, sidewalks, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the value of the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a hierarchical, multiscale Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models the depths and the relation between depths at different points in the image. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. We further propose a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone.\n","datePublished":"2007-08-16","dateModified":"2007-08-16","pageStart":"53","pageEnd":"69","license":"https://creativecommons.org/licenses/by-nc/2.0","sameAs":"https://doi-org.proxy.lib.ohio-state.edu/10.1007/s11263-007-0071-y","keywords":"Computer Imaging,Vision,Pattern Recognition and Graphics,Artificial Intelligence,Image Processing and Computer Vision,Pattern Recognition","image":"","isPartOf":{"name":"International Journal of Computer Vision","issn":["1573-1405","0920-5691"],"volumeNumber":"76","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Springer US","logo":{"url":"https://www-springernature-com.proxy.lib.ohio-state.edu/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Ashutosh Saxena","affiliation":[{"name":"Stanford University","address":{"name":"Computer Science Department, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"asaxena@cs.stanford.edu","@type":"Person"},{"name":"Sung H. Chung","affiliation":[{"name":"Stanford University","address":{"name":"Computer Science Department, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Andrew Y. Ng","affiliation":[{"name":"Stanford University","address":{"name":"Computer Science Department, Stanford University, Stanford, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}
  </script>
  <style type="text/css">
   .c-cookie-banner {
			background-color: #01324b;
			color: white;
			font-size: 1rem;
			position: fixed;
			bottom: 0;
			left: 0;
			right: 0;
			padding: 16px 0;
			font-family: sans-serif;
			z-index: 100002;
			text-align: center;
		}
		.c-cookie-banner__container {
			margin: 0 auto;
			max-width: 1280px;
			padding: 0 16px;
		}
		.c-cookie-banner p {
			margin-bottom: 8px;
		}
		.c-cookie-banner p:last-child {
			margin-bottom: 0;
		}	
		.c-cookie-banner__dismiss {
			background-color: transparent;
			border: 0;
			padding: 0;
			margin-left: 4px;
			color: inherit;
			text-decoration: underline;
			font-size: inherit;
		}
		.c-cookie-banner__dismiss:hover {
			text-decoration: none;
		}
  </style>
  <style type="text/css">
   .MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
  </style>
  <style type="text/css">
   #MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
  </style>
  <style type="text/css">
   .MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
  </style>
  <style type="text/css">
   #MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
  </style>
  <style type="text/css">
   .MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
  </style>
  <style type="text/css">
   .MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
  </style>
  <script>
   window.dataLayer = window.dataLayer || [];
            window.dataLayer.push({
                recommendations: {
                    recommender: 'semantic',
                    model: 'specter',
                    policy_id: 'speedy-BootstrappedUCB',
                    timestamp: 1698023172,
                    embedded_user: 'null'
                }
            });
  </script>
 </head>
 <body class="">
  <div id="MathJax_Message" style="">
   Loading [MathJax]/jax/output/HTML-CSS/config.js
  </div>
  <!-- Google Tag Manager (noscript) -->
  <noscript>
   <iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ" style="display:none;visibility:hidden" width="0">
   </iframe>
  </noscript>
  <!-- End Google Tag Manager (noscript) -->
  <div aria-hidden="true" class="u-visually-hidden">
   <!--?xml version="1.0" encoding="UTF-8"?-->
   <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <defs>
     <path d="M0 .74h56.72v55.24H0z" id="a">
     </path>
    </defs>
    <symbol id="icon-access" viewbox="0 0 18 18">
     <path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-account" viewbox="0 0 18 18">
     <path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-alert" viewbox="0 0 18 18">
     <path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-arrow-broad" viewbox="0 0 16 16">
     <path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)">
     </path>
    </symbol>
    <symbol id="icon-arrow-down" viewbox="0 0 16 16">
     <path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-arrow-left" viewbox="0 0 16 16">
     <path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-arrow-right" viewbox="0 0 16 16">
     <path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-arrow-sub" viewbox="0 0 16 16">
     <path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-arrow-up" viewbox="0 0 16 16">
     <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-article" viewbox="0 0 18 18">
     <path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-audio" viewbox="0 0 18 18">
     <path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-block" viewbox="0 0 24 24">
     <path d="m0 0h24v24h-24z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-book" viewbox="0 0 18 18">
     <path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-broad" viewbox="0 0 24 24">
     <path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)">
     </path>
    </symbol>
    <symbol id="icon-calendar" viewbox="0 0 18 18">
     <path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-cart" viewbox="0 0 18 18">
     <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z">
     </path>
    </symbol>
    <symbol id="icon-chevron-less" viewbox="0 0 10 10">
     <path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)">
     </path>
    </symbol>
    <symbol id="icon-chevron-more" viewbox="0 0 10 10">
     <path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)">
     </path>
    </symbol>
    <symbol id="icon-chevron-right" viewbox="0 0 10 10">
     <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
     </path>
    </symbol>
    <symbol id="icon-circle-fill" viewbox="0 0 16 16">
     <path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-circle" viewbox="0 0 16 16">
     <path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-citation" viewbox="0 0 18 18">
     <path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-close" viewbox="0 0 16 16">
     <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-collections" viewbox="0 0 18 18">
     <path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-compare" viewbox="0 0 18 18">
     <path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-download-file" viewbox="0 0 18 18">
     <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-download" viewbox="0 0 16 16">
     <path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-editors" viewbox="0 0 18 18">
     <path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-email" viewbox="0 0 18 18">
     <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-error" viewbox="0 0 18 18">
     <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-ethics" viewbox="0 0 18 18">
     <path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-expand">
     <path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-explore" viewbox="0 0 18 18">
     <path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-filter" viewbox="0 0 16 16">
     <path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z">
     </path>
    </symbol>
    <symbol id="icon-home" viewbox="0 0 18 18">
     <path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-image" viewbox="0 0 18 18">
     <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-info" viewbox="0 0 18 18">
     <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-institution" viewbox="0 0 18 18">
     <path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-location" viewbox="0 0 18 18">
     <path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-minus" viewbox="0 0 16 16">
     <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-newsletter" viewbox="0 0 18 18">
     <path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-orcid" viewbox="0 0 18 18">
     <path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-plus" viewbox="0 0 16 16">
     <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-print" viewbox="0 0 18 18">
     <path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-search" viewbox="0 0 22 22">
     <path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-social-facebook" viewbox="0 0 24 24">
     <path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-social-twitter" viewbox="0 0 24 24">
     <path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-social-youtube" viewbox="0 0 24 24">
     <path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-subject-medicine" viewbox="0 0 18 18">
     <path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-success" viewbox="0 0 18 18">
     <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-table" viewbox="0 0 18 18">
     <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-tick-circle" viewbox="0 0 24 24">
     <path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-tick" viewbox="0 0 16 16">
     <path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-update" viewbox="0 0 18 18">
     <path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-upload" viewbox="0 0 18 18">
     <path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-video" viewbox="0 0 18 18">
     <path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-warning" viewbox="0 0 18 18">
     <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-altmetric">
     <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm-1.886 9.684-1.101 1.845a1 1 0 0 1-.728.479l-.13.008H3.056a9.001 9.001 0 0 0 17.886 0l-4.564-.001-2.779 4.156c-.454.68-1.467.55-1.758-.179l-.038-.113-1.69-6.195ZM12 3a9.001 9.001 0 0 0-8.947 8.016h4.533l2.017-3.375c.452-.757 1.592-.6 1.824.25l1.73 6.345 1.858-2.777a1 1 0 0 1 .707-.436l.124-.008h5.1A9.001 9.001 0 0 0 12 3Z" fill-rule="nonzero">
     </path>
    </symbol>
    <symbol id="icon-checklist-banner" viewbox="0 0 56.69 56.69">
     <path d="M0 0h56.69v56.69H0z" style="fill:none">
     </path>
     <clippath id="b">
      <use style="overflow:visible" xlink:href="#a">
      </use>
     </clippath>
     <path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round">
     </path>
     <path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round">
     </path>
    </symbol>
    <symbol id="icon-chevron-down" viewbox="0 0 16 16">
     <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)">
     </path>
    </symbol>
    <symbol id="icon-citations">
     <path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM5.483 14.35c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Zm5 0c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-eds-checklist" viewbox="0 0 32 32">
     <path d="M19.2 1.333a3.468 3.468 0 0 1 3.381 2.699L24.667 4C26.515 4 28 5.52 28 7.38v19.906c0 1.86-1.485 3.38-3.333 3.38H7.333c-1.848 0-3.333-1.52-3.333-3.38V7.38C4 5.52 5.485 4 7.333 4h2.093A3.468 3.468 0 0 1 12.8 1.333h6.4ZM9.426 6.667H7.333c-.36 0-.666.312-.666.713v19.906c0 .401.305.714.666.714h17.334c.36 0 .666-.313.666-.714V7.38c0-.4-.305-.713-.646-.714l-2.121.033A3.468 3.468 0 0 1 19.2 9.333h-6.4a3.468 3.468 0 0 1-3.374-2.666Zm12.715 5.606c.586.446.7 1.283.253 1.868l-7.111 9.334a1.333 1.333 0 0 1-1.792.306l-3.556-2.333a1.333 1.333 0 1 1 1.463-2.23l2.517 1.651 6.358-8.344a1.333 1.333 0 0 1 1.868-.252ZM19.2 4h-6.4a.8.8 0 0 0-.8.8v1.067a.8.8 0 0 0 .8.8h6.4a.8.8 0 0 0 .8-.8V4.8a.8.8 0 0 0-.8-.8Z">
     </path>
    </symbol>
    <symbol id="icon-eds-i-external-link-medium" viewbox="0 0 24 24">
     <path d="M9 2a1 1 0 1 1 0 2H4.6c-.371 0-.6.209-.6.5v15c0 .291.229.5.6.5h14.8c.371 0 .6-.209.6-.5V15a1 1 0 0 1 2 0v4.5c0 1.438-1.162 2.5-2.6 2.5H4.6C3.162 22 2 20.938 2 19.5v-15C2 3.062 3.162 2 4.6 2H9Zm6 0h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L22 3v6a1 1 0 0 1-2 0V5.414l-6.693 6.693a1 1 0 0 1-1.414-1.414L18.584 4H15a1 1 0 0 1-.993-.883L14 3a1 1 0 0 1 1-1Z">
     </path>
    </symbol>
    <symbol id="icon-eds-i-info-filled-medium" viewbox="0 0 24 24">
     <path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 9h-1.5a1 1 0 0 0-1 1l.007.117A1 1 0 0 0 10.5 12h.5v4H9.5a1 1 0 0 0 0 2h5a1 1 0 0 0 0-2H13v-5a1 1 0 0 0-1-1Zm0-4.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 5.5Z">
     </path>
    </symbol>
    <symbol id="icon-eds-menu" viewbox="0 0 24 24">
     <path d="M21.09 5c.503 0 .91.448.91 1s-.407 1-.91 1H2.91C2.406 7 2 6.552 2 6s.407-1 .91-1h18.18Zm-3.817 6c.401 0 .727.448.727 1s-.326 1-.727 1H2.727C2.326 13 2 12.552 2 12s.326-1 .727-1h14.546Zm3.818 6c.502 0 .909.448.909 1s-.407 1-.91 1H2.91c-.503 0-.91-.448-.91-1s.407-1 .91-1h18.18Z" fill-rule="nonzero">
     </path>
    </symbol>
    <symbol id="icon-eds-search" viewbox="0 0 24 24">
     <path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z" fill-rule="nonzero">
     </path>
    </symbol>
    <symbol id="icon-eds-small-arrow-right" viewbox="0 0 16 16">
     <g fill-rule="evenodd" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
      <path d="M2 8.092h12M8 2l6 6.092M8 14.127l6-6.035">
      </path>
     </g>
    </symbol>
    <symbol id="icon-eds-user-single" viewbox="0 0 24 24">
     <path d="M12 12c5.498 0 10 4.001 10 9a1 1 0 0 1-2 0c0-3.838-3.557-7-8-7s-8 3.162-8 7a1 1 0 0 1-2 0c0-4.999 4.502-9 10-9Zm0-11a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm0 2a3 3 0 1 1 0 6 3 3 0 0 1 0-6Z" fill-rule="nonzero">
     </path>
    </symbol>
    <symbol id="icon-email-new" viewbox="0 0 24 24">
     <path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z">
     </path>
    </symbol>
    <symbol id="icon-expand-image" viewbox="0 0 18 18">
     <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-github" viewbox="0 0 100 100">
     <path clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill-rule="evenodd">
     </path>
    </symbol>
    <symbol id="icon-mentions">
     <g fill-rule="evenodd" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
      <path d="M22 15.255A9.373 9.373 0 0 1 8.745 2L22 15.255ZM15.477 8.523l4.215-4.215">
      </path>
      <path d="m7 13-5 9h10l-1-5">
      </path>
     </g>
    </symbol>
    <symbol id="icon-metrics-accesses">
     <path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM7.708 13.308c2.004 0 3.969 1.198 5.802 2.995l.23.23a2.285 2.285 0 0 1 .009 3.233C11.853 21.693 9.799 23 7.707 23c-2.091 0-4.14-1.305-6.033-3.226a2.285 2.285 0 0 1-.007-3.233c1.9-1.93 3.949-3.233 6.04-3.233Zm0 2c-1.396 0-3.064 1.062-4.623 2.644a.285.285 0 0 0 .007.41C4.642 19.938 6.311 21 7.707 21c1.397 0 3.069-1.065 4.623-2.644a.285.285 0 0 0 0-.404l-.23-.229c-1.487-1.451-3.064-2.415-4.393-2.415Zm-.036 1.077a1.77 1.77 0 1 1 .126 3.537 1.77 1.77 0 0 1-.126-3.537Zm.072 1.538a.23.23 0 1 0-.017.461.23.23 0 0 0 .017-.46Z" fill-rule="nonzero">
     </path>
    </symbol>
    <symbol id="icon-metrics">
     <path d="M3 22a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v7h4V8a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v13a1 1 0 0 1-.883.993L21 22H3Zm17-2V9h-4v11h4Zm-6-8h-4v8h4v-8ZM8 4H4v16h4V4Z" fill-rule="nonzero">
     </path>
    </symbol>
    <symbol id="icon-springer-arrow-left">
     <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z">
     </path>
    </symbol>
    <symbol id="icon-springer-arrow-right">
     <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z">
     </path>
    </symbol>
    <symbol id="icon-submit-open" viewbox="0 0 16 17">
     <path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero">
     </path>
    </symbol>
   </svg>
  </div>
  <a class="c-skip-link" href="#main">
   Skip to main content
  </a>
  <header class="c-header" data-header="">
   <div class="c-header__container" data-header-expander-anchor="">
    <div class="c-header__brand">
     <a data-test="logo" data-track="click" data-track-action="click logo link" data-track-category="unified header" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu">
      <img alt="SpringerLink" src="/oscar-static/images/darwin/header/img/logo-springerlink-39ee2a28d8.svg"/>
     </a>
    </div>
    <a class="c-header__link c-header__link--static" data-test="login-link" data-track="click" data-track-action="click log in link" data-track-category="unified header" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs11263-007-0071-y">
     <svg aria-hidden="true" class="c-header__icon" focusable="false" height="24" width="24">
      <use xlink:href="#icon-eds-user-single">
      </use>
     </svg>
     <span>
      Log in
     </span>
    </a>
   </div>
   <nav aria-label="header navigation" class="c-header__nav">
    <div class="c-header__nav-container">
     <div class="c-header__item c-header__item--menu">
      <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" href="javascript:;" role="button">
       <svg aria-hidden="true" class="c-header__icon" focusable="false" height="24" width="24">
        <use xlink:href="#icon-eds-menu">
        </use>
       </svg>
       <span>
        Menu
       </span>
      </a>
     </div>
     <div class="c-header__item c-header__item--inline-links">
      <a class="c-header__link" data-track="click" data-track-action="click find a journal" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/journals/a/1">
       Find a journal
      </a>
      <a class="c-header__link" data-track="click" data-track-action="click publish with us link" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/authors">
       Publish with us
      </a>
     </div>
     <div class="c-header__link-container">
      <div class="c-header__item c-header__item--divider">
       <a aria-expanded="false" aria-haspopup="true" class="c-header__link" data-header-expander="" href="javascript:;" role="button">
        <svg aria-hidden="true" class="c-header__icon" focusable="false" height="24" width="24">
         <use xlink:href="#icon-eds-search">
         </use>
        </svg>
        <span>
         Search
        </span>
       </a>
      </div>
      <div class="c-header__item">
       <div class="c-header__cart-icon">
        <div class="c-header__item ecommerce-cart" id="ecommerce-header-cart-icon-link" style="display:inline-block">
         <a class="c-header__link" href="https://order-springer-com.proxy.lib.ohio-state.edu/public/cart" style="appearance:none;border:none;background:none;color:inherit;position:relative">
          <svg aria-hidden="true" focusable="false" height="24" id="eds-i-cart" style="vertical-align:bottom" viewbox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
           <path d="M2 1a1 1 0 0 0 0 2l1.659.001 2.257 12.808a2.599 2.599 0 0 0 2.435 2.185l.167.004 9.976-.001a2.613 2.613 0 0 0 2.61-1.748l.03-.106 1.755-7.82.032-.107a2.546 2.546 0 0 0-.311-1.986l-.108-.157a2.604 2.604 0 0 0-2.197-1.076L6.042 5l-.56-3.17a1 1 0 0 0-.864-.82l-.12-.007L2.001 1ZM20.35 6.996a.63.63 0 0 1 .54.26.55.55 0 0 1 .082.505l-.028.1L19.2 15.63l-.022.05c-.094.177-.282.299-.526.317l-10.145.002a.61.61 0 0 1-.618-.515L6.394 6.999l13.955-.003ZM18 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4ZM8 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z" fill="currentColor" fill-rule="nonzero">
           </path>
          </svg>
          <span style="padding-left:10px">
           Cart
          </span>
          <span class="cart-info" style="display:none;position:absolute;top:10px;right:45px;background-color:#C65301;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center">
          </span>
         </a>
         <script>
          (function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    console.log("listen to updatedCart event");
    document.body.addEventListener("updatedCart", function () {
        console.log("updatedCart happened");
        updateCartIcon().then(function () { return console.log("Cart state update upon event"); });
    }, false);
    return updateCartIcon().then(function () { return console.log("Initial cart state update"); });
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function () { return console.log("Could not fetch cart info"); });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart-springer-com.proxy.lib.ohio-state.edu/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()
         </script>
        </div>
       </div>
      </div>
     </div>
    </div>
   </nav>
  </header>
  <div class="c-header__expander has-tethered u-js-hide" hidden="" id="popup-search">
   <h2 class="c-header__heading">
    Search
   </h2>
   <div class="u-container">
    <div class="c-header__search">
     <form action="//link-springer-com.proxy.lib.ohio-state.edu/search" data-track="submit" data-track-action="submit search form" data-track-category="unified header" data-track-label="form" method="GET" role="search">
      <label class="c-header__search-label" for="header-search">
       Search by keyword or author
      </label>
      <div class="c-header__search-container">
       <input autocomplete="off" class="c-header__search-input" id="header-search" name="query" required="" type="text" value=""/>
       <button class="c-header__search-button" type="submit">
        <svg aria-hidden="true" class="c-header__icon" focusable="false">
         <use xlink:href="#icon-eds-search">
         </use>
        </svg>
        <span class="u-visually-hidden">
         Search
        </span>
       </button>
      </div>
     </form>
    </div>
   </div>
  </div>
  <div class="c-header__expander c-header__expander--menu has-tethered u-js-hide" hidden="" id="header-nav">
   <h2 class="c-header__heading">
    Navigation
   </h2>
   <ul class="c-header__list">
    <li class="c-header__list-item">
     <a class="c-header__link" data-track="click" data-track-action="click find a journal" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/journals/a/1">
      Find a journal
     </a>
    </li>
    <li class="c-header__list-item">
     <a class="c-header__link" data-track="click" data-track-action="click publish with us link" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/authors">
      Publish with us
     </a>
    </li>
   </ul>
  </div>
  <article class="c-masthead__colour-18" id="main" lang="en">
   <header class="c-masthead">
    <div class="c-masthead__container">
     <div class="app-article-masthead u-sans-serif" data-test="masthead-component" data-track-component="article">
      <div class="app-article-masthead__info">
       <nav aria-label="breadcrumbs" data-test="breadcrumbs">
        <ol class="c-breadcrumbs c-breadcrumbs--contrast" itemscope="" itemtype="https://schema.org/BreadcrumbList">
         <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
          <a class="c-breadcrumbs__link" data-track="click" data-track-action="breadcrumbs" data-track-category="article" data-track-label="breadcrumb1" href="/" itemprop="item">
           <span itemprop="name">
            Home
           </span>
          </a>
          <meta content="1" itemprop="position"/>
          <svg aria-hidden="true" class="c-breadcrumbs__chevron" focusable="false" height="10" role="img" viewbox="0 0 10 10" width="10">
           <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
           </path>
          </svg>
         </li>
         <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
          <a class="c-breadcrumbs__link" data-track="click" data-track-action="breadcrumbs" data-track-category="article" data-track-label="breadcrumb2" href="/journal/11263" itemprop="item">
           <span itemprop="name">
            International Journal of Computer Vision
           </span>
          </a>
          <meta content="2" itemprop="position"/>
          <svg aria-hidden="true" class="c-breadcrumbs__chevron" focusable="false" height="10" role="img" viewbox="0 0 10 10" width="10">
           <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)">
           </path>
          </svg>
         </li>
         <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
          <span itemprop="name">
           Article
          </span>
          <meta content="3" itemprop="position"/>
         </li>
        </ol>
       </nav>
       <h1 class="c-article-title" data-article-title="" data-test="article-title">
        3-D Depth Reconstruction from a Single Still Image
       </h1>
       <ul class="c-article-identifiers">
        <li class="c-article-identifiers__item">
         <a class="u-color-open-access" data-test="open-access" data-track="click" data-track-action="open access" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/open-research/about/the-fundamentals-of-open-access-and-open-research">
          Open access
         </a>
        </li>
        <li class="c-article-identifiers__item">
         <a data-track="click" data-track-action="publication date" data-track-label="link" href="#article-info">
          Published:
          <time datetime="2007-08-16">
           16 August 2007
          </time>
         </a>
        </li>
        <li class="c-article-identifiers__item">
         <b data-test="journal-volume">
          <span class="u-visually-hidden">
           volume
          </span>
          76
         </b>
         ,
         <span class="u-visually-hidden">
          pages
         </span>
         53–69 (
         <span data-test="article-publication-year">
          2008
         </span>
         )
        </li>
       </ul>
       <div class="app-article-masthead__buttons">
        <div class="c-pdf-container">
         <div class="c-pdf-download u-clear-both u-mb-16">
          <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="pdf-link" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="button" download="" href="/content/pdf/10.1007/s11263-007-0071-y.pdf?pdf=button">
           <span class="c-pdf-download__text">
            Download PDF
           </span>
           <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
            <use xlink:href="#icon-download">
            </use>
           </svg>
          </a>
         </div>
        </div>
        <p class="app-article-masthead__access">
         <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
          <use xlink:href="#icon-success" xmlns:xlink="http://www.w3.org/1999/xlink">
          </use>
         </svg>
         You have full access to this
         <a data-track="click" data-track-action="open access" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/open-research/about/the-fundamentals-of-open-access-and-open-research">
          open access
         </a>
         article
        </p>
       </div>
      </div>
      <div class="app-article-masthead__brand">
       <a class="app-article-masthead__journal-link" data-track="click" data-track-action="journal homepage" data-track-label="link" href="/journal/11263">
        <picture>
         <source srcset="https://media-springernature-com.proxy.lib.ohio-state.edu/w120/springer-static/cover/journal/11263.jpg?as=webp" type="image/webp"/>
         <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w120/springer-static/cover/journal/11263.jpg"/>
        </picture>
        <span class="app-article-masthead__journal-title">
         International Journal of Computer Vision
        </span>
       </a>
       <a class="app-article-masthead__submission-link" data-track="click" data-track-action="aims and scope" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/journal/11263/aims-and-scope">
        Aims and scope
        <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
         <use xlink:href="#icon-arrow-right" xmlns:xlink="http://www.w3.org/1999/xlink">
         </use>
        </svg>
       </a>
       <a class="app-article-masthead__submission-link" data-track="click" data-track-action="submit manuscript" data-track-label="link" href="https://www.editorialmanager.com/visi">
        Submit manuscript
        <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
         <use xlink:href="#icon-arrow-right" xmlns:xlink="http://www.w3.org/1999/xlink">
         </use>
        </svg>
       </a>
      </div>
     </div>
    </div>
   </header>
   <div class="c-article-main u-container u-mt-32 u-mb-32 l-with-sidebar" data-component="article-container" id="main-content">
    <main class="u-serif js-main-column" data-track-component="article body">
     <div aria-hidden="true" class="c-context-bar u-hide" data-context-bar="" data-context-bar-with-recommendations="" data-test="context-bar">
      <div class="c-context-bar__container u-container">
       <div class="c-context-bar__title">
        3-D Depth Reconstruction from a Single Still Image
       </div>
       <div data-test="inCoD">
        <div class="c-pdf-container">
         <div class="c-pdf-download u-clear-both u-mb-16">
          <a class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-draft-ignore="true" data-readcube-pdf-url="true" data-test="pdf-link" data-track="click" data-track-action="download pdf" data-track-external="" data-track-label="button" download="" href="/content/pdf/10.1007/s11263-007-0071-y.pdf?pdf=button">
           <span class="c-pdf-download__text">
            Download PDF
           </span>
           <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
            <use xlink:href="#icon-download">
            </use>
           </svg>
          </a>
         </div>
        </div>
       </div>
      </div>
      <div id="recommendations">
       <div class="c-recommendations__container u-container u-display-none" data-component-recommendations="">
        <aside class="c-status-message c-status-message--success u-display-none" data-component-status-msg="">
         <svg aria-label="success:" class="c-status-message__icon" focusable="false" height="24" role="img" width="24">
          <use xlink:href="#icon-success">
          </use>
         </svg>
         <div class="c-status-message__message" id="success-message" tabindex="-1">
          Your content has downloaded
         </div>
        </aside>
        <div class="c-recommendations-header u-display-flex u-justify-content-space-between">
         <h2 class="c-recommendations-title" id="recommendation-heading">
          Similar content being viewed by others
         </h2>
         <button aria-label="Close" class="c-recommendations-close u-flex-static" data-track="click" data-track-action="close recommendations" type="button">
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" width="16">
           <use xlink:href="#icon-close">
           </use>
          </svg>
         </button>
        </div>
        <section aria-labelledby="recommendation-heading" aria-roledescription="carousel">
         <p class="u-visually-hidden">
          Slider with three content items shown per slide. Use the Previous and Next buttons to navigate the slides or the slide controller buttons at the end to navigate through each slide.
         </p>
         <div class="c-recommendations-list-container">
          <div class="c-recommendations-list">
           <div aria-label="Recommendation 1 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w92h120/springer-static/cover-hires/book/978-3-642-33709-3?as=webp"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 1" data-track-label="10.1007/978-3-642-33709-3_43" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/978-3-642-33709-3_43" itemprop="url">
                  3D Reconstruction of Dynamic Scenes with Multiple Handheld Cameras
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Chapter
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  © 2012
                 </span>
                </div>
               </div>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 2 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w92h120/springer-static/cover-hires/book/978-3-642-33715-4?as=webp"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 2" data-track-label="10.1007/978-3-642-33715-4_4" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/978-3-642-33715-4_4" itemprop="url">
                  Continuous Markov Random Fields for Robust Stereo Estimation
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Chapter
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  © 2012
                 </span>
                </div>
               </div>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 3 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w92h120/springer-static/cover-hires/book/978-1-4471-5520-1?as=webp"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 3" data-track-label="10.1007/978-1-4471-5520-1_10" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/978-1-4471-5520-1_10" itemprop="url">
                  Top–Down Bayesian Inference of Indoor Scenes
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Chapter
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  © 2013
                 </span>
                </div>
               </div>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 4 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1007%2Fs11263-015-0843-8/MediaObjects/11263_2015_843_Fig1_HTML.gif"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 4" data-track-label="10.1007/s11263-015-0843-8" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/s11263-015-0843-8" itemprop="url">
                  Integrating Geometrical Context for Semantic Labeling of Indoor Scenes using RGBD Images
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Article
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  03 July 2015
                 </span>
                </div>
               </div>
               <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
                Salman H. Khan, Mohammed Bennamoun, … Imran Naseem
               </p>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 5 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w92h120/springer-static/cover-hires/book/978-3-642-34091-8?as=webp"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 5" data-track-label="10.1007/978-3-642-34091-8_17" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/978-3-642-34091-8_17" itemprop="url">
                  Semantic Structure from Motion: A Novel Framework for Joint Object Recognition and 3D Reconstruction
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Chapter
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  © 2012
                 </span>
                </div>
               </div>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 6 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1007%2Fs11263-014-0734-4/MediaObjects/11263_2014_734_Fig1_HTML.gif"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 6" data-track-label="10.1007/s11263-014-0734-4" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/s11263-014-0734-4" itemprop="url">
                  3DNN: 3D Nearest Neighbor
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Article
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  22 July 2014
                 </span>
                </div>
               </div>
               <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
                Scott Satkin, Maheen Rashid, … Martial Hebert
               </p>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 7 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w92h120/springer-static/cover-hires/book/978-3-642-33715-4?as=webp"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 7" data-track-label="10.1007/978-3-642-33715-4_11" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/978-3-642-33715-4_11" itemprop="url">
                  A Generative Model for Online Depth Fusion
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Chapter
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  © 2012
                 </span>
                </div>
               </div>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 8 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w136h75/springer-static/image/art%3A10.1007%2Fs11263-014-0704-x/MediaObjects/11263_2014_704_Fig1_HTML.gif"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 8" data-track-label="10.1007/s11263-014-0704-x" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/s11263-014-0704-x" itemprop="url">
                  Putting the User in the Loop for Image-Based Modeling
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Article
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  12 March 2014
                 </span>
                </div>
               </div>
               <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">
                Adarsh Kowdle, Yao-Jen Chang, … Tsuhan Chen
               </p>
              </div>
             </div>
            </article>
           </div>
           <div aria-label="Recommendation 9 of 9" aria-roledescription="slide" class="c-recommendations-list__item" role="group">
            <article class="u-full-height c-card c-card--flush" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
             <div class="c-card__layout u-full-height">
              <div class="c-card__image">
               <img alt="" src="https://media-springernature-com.proxy.lib.ohio-state.edu/w92h120/springer-static/cover-hires/book/978-3-642-38628-2?as=webp"/>
              </div>
              <div class="c-card__body u-display-flex u-flex-direction-column">
               <div class="c-recommendations-column-switch">
                <h3 class="c-card__title-recommendation u-sans-serif" itemprop="name headline">
                 <a class="c-card__link" data-track="click" data-track-action="click recommendations - 9" data-track-label="10.1007/978-3-642-38628-2_7" href="https://link-springer-com.proxy.lib.ohio-state.edu/10.1007/978-3-642-38628-2_7" itemprop="url">
                  Modeling Pose/Appearance Relations for Improved Object Localization and Pose Estimation in 2D images
                 </a>
                </h3>
                <div class="c-card__section c-meta">
                 <span class="c-meta__item u-sans-serif">
                  Chapter
                 </span>
                 <span class="c-meta__item u-sans-serif">
                  © 2013
                 </span>
                </div>
               </div>
              </div>
             </div>
            </article>
           </div>
          </div>
         </div>
        </section>
       </div>
       <div class="js-greyout-page-background" data-component-grey-background="" style="display:none">
       </div>
      </div>
     </div>
     <div class="c-article-header">
      <header>
       <ul class="c-article-author-list c-article-author-list--short js-no-scroll" data-component-authors-activator="authors-list" data-test="authors-list">
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Ashutosh-Saxena-Aff1" data-corresp-id="c1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ashutosh-Saxena-Aff1">
          Ashutosh Saxena
          <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
           <use xlink:href="#icon-email-new" xmlns:xlink="http://www.w3.org/1999/xlink">
           </use>
          </svg>
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         ,
        </li>
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Sung_H_-Chung-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Sung_H_-Chung-Aff1">
          Sung H. Chung
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
         &amp;
        </li>
        <li class="c-article-author-list__item">
         <a data-author-popup="auth-Andrew_Y_-Ng-Aff1" data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Andrew_Y_-Ng-Aff1">
          Andrew Y. Ng
         </a>
         <sup class="u-js-hide">
          <a href="#Aff1" tabindex="-1">
           1
          </a>
         </sup>
        </li>
       </ul>
       <div data-test="article-metrics">
        <ul class="app-article-metrics-bar u-list-reset">
         <li class="app-article-metrics-bar__item">
          <p class="app-article-metrics-bar__count">
           <svg aria-hidden="true" class="u-icon app-article-metrics-bar__icon" focusable="false" height="24" width="24">
            <use xlink:href="#icon-metrics-accesses">
            </use>
           </svg>
           10k
           <span class="app-article-metrics-bar__label">
            Accesses
           </span>
          </p>
         </li>
         <li class="app-article-metrics-bar__item">
          <p class="app-article-metrics-bar__count">
           <svg aria-hidden="true" class="u-icon app-article-metrics-bar__icon" focusable="false" height="24" width="24">
            <use xlink:href="#icon-citations">
            </use>
           </svg>
           419
           <span class="app-article-metrics-bar__label">
            Citations
           </span>
          </p>
         </li>
         <li class="app-article-metrics-bar__item">
          <p class="app-article-metrics-bar__count">
           <svg aria-hidden="true" class="u-icon app-article-metrics-bar__icon" focusable="false" height="24" width="24">
            <use xlink:href="#icon-altmetric">
            </use>
           </svg>
           9
           <span class="app-article-metrics-bar__label">
            Altmetric
           </span>
          </p>
         </li>
         <li class="app-article-metrics-bar__item app-article-metrics-bar__item--metrics">
          <p class="app-article-metrics-bar__details">
           <a data-track="click" data-track-action="view metrics" data-track-label="link" href="/article/10.1007/s11263-007-0071-y/metrics" rel="nofollow">
            Explore all metrics
            <svg aria-hidden="true" class="u-icon app-article-metrics-bar__arrow-icon" focusable="false" height="24" width="24">
             <use xlink:href="#icon-arrow-right">
             </use>
            </svg>
           </a>
          </p>
         </li>
         <li class="app-article-metrics-bar__item app-cite-as u-hide-print">
          <a data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link" href="#citeas">
           Cite this article
          </a>
         </li>
        </ul>
       </div>
      </header>
     </div>
     <div class="c-article-body" data-article-body="true" data-track-component="article body">
      <section aria-labelledby="Abs1" data-title="Abstract" lang="en">
       <div class="c-article-section" id="Abs1-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">
         Abstract
        </h2>
        <div class="c-article-section__content" id="Abs1-content">
         <p>
          We consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured indoor and outdoor environments which include forests, sidewalks, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the value of the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a hierarchical, multiscale Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models the depths and the relation between depths at different points in the image. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. We further propose a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone.
         </p>
        </div>
       </div>
      </section>
      <div data-test="cobranding-download">
       <div class="note test-pdf-link" id="cobranding-and-download-availability-text">
        <div aria-hidden="true" class="c-article-access-provider" data-component="provided-by-box">
         <p class="c-article-access-provider__text">
          <a class="c-pdf-download__link" data-track="click" data-track-action="download pdf" data-track-label="inline link" download="" href="/content/pdf/10.1007/s11263-007-0071-y.pdf?pdf=inline%20link" rel="noopener" style="display: inline; padding:0px!important;" target="_blank">
           Download
          </a>
          to read the full article text
         </p>
        </div>
       </div>
      </div>
      <div class="app-checklist-banner--on-mobile">
       <div class="c-card-service" data-test="article-checklist-banner">
        <div>
         <a class="c-card-service__link" data-track="click" data-track-action="clicked article page checklist banner test 2 old version" data-track-category="pre-submission-checklist" data-track-label="link" href="https://beta-springernature-com.proxy.lib.ohio-state.edu/pre-submission?journalId=11263">
          <span class="c-card-service__link-text">
           Use our pre-submission checklist
          </span>
          <svg aria-hidden="true" class="c-card-service__link-icon" focusable="false">
           <use xlink:href="#icon-eds-small-arrow-right">
           </use>
          </svg>
         </a>
         <p class="c-card-service__description">
          Avoid common mistakes on your manuscript.
         </p>
        </div>
        <div class="c-card-service__icon-container">
         <svg aria-hidden="true" class="c-card-service__icon" focusable="false">
          <use xlink:href="#icon-eds-checklist">
          </use>
         </svg>
        </div>
       </div>
      </div>
      <div class="main-content">
      </div>
      <div id="MagazineFulltextArticleBodySuffix">
       <section aria-labelledby="Bib1" data-title="References">
        <div class="c-article-section" id="Bib1-section">
         <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">
          References
         </h2>
         <div class="c-article-section__content" id="Bib1-content">
          <div data-container-section="references">
           <ul class="c-article-references" data-track-component="outbound reference">
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR1">
              Anguelov, D., Srinivasan, P., Koller, D., Thrun, S., Rodgers, J., &amp; Davis, J. (2005). SCAPE: shape completion and animation of people.
              <i>
               ACM Transactions on Graphics
              </i>
              ,
              <i>
               24
              </i>
              (3), 408–416.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 1" data-doi="10.1145/1073204.1073207" data-track="click" data-track-action="article reference" data-track-label="10.1145/1073204.1073207" href="https://doi-org.proxy.lib.ohio-state.edu/10.1145%2F1073204.1073207" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 1" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=SCAPE%3A%20shape%20completion%20and%20animation%20of%20people&amp;journal=ACM%20Transactions%20on%20Graphics&amp;doi=10.1145%2F1073204.1073207&amp;volume=24&amp;issue=3&amp;pages=408-416&amp;publication_year=2005&amp;author=Anguelov%2CD.&amp;author=Srinivasan%2CP.&amp;author=Koller%2CD.&amp;author=Thrun%2CS.&amp;author=Rodgers%2CJ.&amp;author=Davis%2CJ." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR2">
              Barron, J. L., Fleet, D. J., &amp; Beauchemin, S. S. (1994). Performance of optical flow techniques.
              <i>
               International Journal of Computer Vision
              </i>
              ,
              <i>
               12
              </i>
              , 43–77.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 2" data-doi="10.1007/BF01420984" data-track="click" data-track-action="article reference" data-track-label="10.1007/BF01420984" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2FBF01420984" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 2" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance%20of%20optical%20flow%20techniques&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1007%2FBF01420984&amp;volume=12&amp;pages=43-77&amp;publication_year=1994&amp;author=Barron%2CJ.%20L.&amp;author=Fleet%2CD.%20J.&amp;author=Beauchemin%2CS.%20S." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR3">
              Brown, M. Z., Burschka, D., &amp; Hager, G. D. (2003). Advances in computational stereo.
              <i>
               IEEE Transactions on Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               25
              </i>
              (8), 993–1008.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 3" data-doi="10.1109/TPAMI.2003.1217603" data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2003.1217603" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2003.1217603" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 3" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Advances%20in%20computational%20stereo&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2003.1217603&amp;volume=25&amp;issue=8&amp;pages=993-1008&amp;publication_year=2003&amp;author=Brown%2CM.%20Z.&amp;author=Burschka%2CD.&amp;author=Hager%2CG.%20D." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR4">
              Bulthoff, I., Bulthoff, H., &amp; Sinha, P. (1998). Top-down influences on stereoscopic depth-perception.
              <i>
               Nature Neuroscience
              </i>
              ,
              <i>
               1
              </i>
              , 254–257.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 4" data-doi="10.1038/699" data-track="click" data-track-action="article reference" data-track-label="10.1038/699" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F699" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 4" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Top-down%20influences%20on%20stereoscopic%20depth-perception&amp;journal=Nature%20Neuroscience&amp;doi=10.1038%2F699&amp;volume=1&amp;pages=254-257&amp;publication_year=1998&amp;author=Bulthoff%2CI.&amp;author=Bulthoff%2CH.&amp;author=Sinha%2CP." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR5">
              Cornelis, N., Leibe, B., Cornelis, K., &amp; Van Gool, L. (2006). 3d city modeling using cognitive loops. In
              <i>
               Video proceedings of CVPR (VPCVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR6">
              Criminisi, A., Reid, I., &amp; Zisserman, A. (2000). Single view metrology.
              <i>
               International Journal of Computer Vision
              </i>
              ,
              <i>
               40
              </i>
              , 123–148.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 6" data-doi="10.1023/A:1026598000963" data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1026598000963" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1026598000963" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="MATH reference 6" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1012.68704" rel="nofollow noopener">
               MATH
              </a>
              <a aria-label="Google Scholar reference 6" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Single%20view%20metrology&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1026598000963&amp;volume=40&amp;pages=123-148&amp;publication_year=2000&amp;author=Criminisi%2CA.&amp;author=Reid%2CI.&amp;author=Zisserman%2CA." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR7">
              Das, S., &amp; Ahuja, N. (1995). Performance analysis of stereo, vergence, and focus as depth cues for active vision.
              <i>
               IEEE Transactions on Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               17
              </i>
              (12), 1213–1219.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 7" data-doi="10.1109/34.476513" data-track="click" data-track-action="article reference" data-track-label="10.1109/34.476513" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F34.476513" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 7" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance%20analysis%20of%20stereo%2C%20vergence%2C%20and%20focus%20as%20depth%20cues%20for%20active%20vision&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2F34.476513&amp;volume=17&amp;issue=12&amp;pages=1213-1219&amp;publication_year=1995&amp;author=Das%2CS.&amp;author=Ahuja%2CN." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR8">
              Davies, E. R. (1997). Laws’ texture energy in
              <span class="u-small-caps">
               texture
              </span>
              . In
              <i>
               Machine vision: theory, algorithms, practicalities
              </i>
              (2nd ed.). San Diego: Academic Press.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Google Scholar reference 8" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Laws%E2%80%99%20texture%20energy%20in%20texture&amp;publication_year=1997&amp;author=Davies%2CE.%20R." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR9">
              Delage, E., Lee, H., &amp; Ng, A. Y. (2005). Automatic single-image 3d reconstructions of indoor Manhattan world scenes. In
              <i>
               12th International Symposium of Robotics Research (ISRR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR10">
              Delage, E., Lee, H., &amp; Ng, A. Y. (2006). A dynamic Bayesian network model for autonomous 3D reconstruction from a single indoor image. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR11">
              Forsyth, D. A., &amp; Ponce, J. (2003).
              <i>
               Computer vision: a modern approach
              </i>
              . New York: Prentice Hall.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Google Scholar reference 11" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer%20vision%3A%20a%20modern%20approach&amp;publication_year=2003&amp;author=Forsyth%2CD.%20A.&amp;author=Ponce%2CJ." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR12">
              Frueh, C., &amp; Zakhor, A. (2003). Constructing 3D city models by merging ground-based and airborne views. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR13">
              Gini, G., &amp; Marchi, A. (2002). Indoor robot navigation with single camera vision. In
              <i>
               PRIS
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR14">
              Harkness, L. (1977). Chameleons use accommodation cues to judge distance.
              <i>
               Nature
              </i>
              ,
              <i>
               267
              </i>
              , 346–349.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 14" data-doi="10.1038/267346a0" data-track="click" data-track-action="article reference" data-track-label="10.1038/267346a0" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F267346a0" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 14" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Chameleons%20use%20accommodation%20cues%20to%20judge%20distance&amp;journal=Nature&amp;doi=10.1038%2F267346a0&amp;volume=267&amp;pages=346-349&amp;publication_year=1977&amp;author=Harkness%2CL." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR15">
              He, X., Zemel, R., &amp; Perpinan, M. (2004). Multiscale conditional random fields for image labeling. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR16">
              Hertzmann, A., &amp; Seitz, S. M. (2005). Example-based photometric stereo: Shape reconstruction with general, varying brdfs.
              <i>
               IEEE Transactions on Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               27
              </i>
              (8), 1254–1264.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 16" data-doi="10.1109/TPAMI.2005.158" data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2005.158" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2005.158" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 16" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Example-based%20photometric%20stereo%3A%20Shape%20reconstruction%20with%20general%2C%20varying%20brdfs&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2005.158&amp;volume=27&amp;issue=8&amp;pages=1254-1264&amp;publication_year=2005&amp;author=Hertzmann%2CA.&amp;author=Seitz%2CS.%20M." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR17">
              Hoiem, D., Efros, A. A., &amp; Herbert, M. (2005a). Geometric context from a single image. In
              <i>
               International conference on computer vision (ICCV)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR18">
              Hoiem, D., Efros, A. A., &amp; Herbert, M. (2005b). Automatic photo pop-up. In
              <i>
               ACM SIGGRAPH
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR19">
              Hoiem, D., Efros, A. A., &amp; Herbert, M. (2006). Putting objects in perspective. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR20">
              Huang, J., Lee, A. B., &amp; Mumford, D. (2000). Statistics of range images. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR21">
              Kolmogorov, V., Criminisi, A., Blake, A., Cross, G., &amp; Rother, C. (2006). Probabilistic fusion of stereo with color and contrast for bilayer segmentation.
              <i>
               IEEE Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               28
              </i>
              (9), 1480–1492.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 21" data-doi="10.1109/TPAMI.2006.193" data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2006.193" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2006.193" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 21" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Probabilistic%20fusion%20of%20stereo%20with%20color%20and%20contrast%20for%20bilayer%20segmentation&amp;journal=IEEE%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2006.193&amp;volume=28&amp;issue=9&amp;pages=1480-1492&amp;publication_year=2006&amp;author=Kolmogorov%2CV.&amp;author=Criminisi%2CA.&amp;author=Blake%2CA.&amp;author=Cross%2CG.&amp;author=Rother%2CC." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR22">
              Konishi, S., &amp; Yuille, A. (2000). Statistical cues for domain specific image segmentation with performance analysis. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR23">
              Kumar, S., &amp; Hebert, M. (2003). Discriminative fields for modeling spatial dependencies in natural images. In
              <i>
               Neural information processing systems (NIPS)
              </i>
              (Vol. 16).
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR24">
              Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional random fields: probabilistic models for segmenting and labeling sequence data. In
              <i>
               International conference on machine learning (ICML)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR25">
              Lindeberg, T., &amp; Garding, J. (1993). Shape from texture from a multi-scale perspective. In
              <i>
               International conference on computer vision (ICCV)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR26">
              Loomis, J. M. (2001). Looking down is looking up.
              <i>
               Nature News and Views
              </i>
              ,
              <i>
               414
              </i>
              , 155–156.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 26" data-doi="10.1038/35102648" data-track="click" data-track-action="article reference" data-track-label="10.1038/35102648" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F35102648" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 26" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Looking%20down%20is%20looking%20up&amp;journal=Nature%20News%20and%20Views&amp;doi=10.1038%2F35102648&amp;volume=414&amp;pages=155-156&amp;publication_year=2001&amp;author=Loomis%2CJ.%20M." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR27">
              Maki, A., Watanabe, M., &amp; Wiles, C. (2002). Geotensity: combining motion and lighting for 3d surface reconstruction.
              <i>
               International Journal of Computer Vision
              </i>
              ,
              <i>
               48
              </i>
              (2), 75–90.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 27" data-doi="10.1023/A:1016057422703" data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1016057422703" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1016057422703" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="MATH reference 27" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1012.68753" rel="nofollow noopener">
               MATH
              </a>
              <a aria-label="Google Scholar reference 27" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Geotensity%3A%20combining%20motion%20and%20lighting%20for%203d%20surface%20reconstruction&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1016057422703&amp;volume=48&amp;issue=2&amp;pages=75-90&amp;publication_year=2002&amp;author=Maki%2CA.&amp;author=Watanabe%2CM.&amp;author=Wiles%2CC." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR28">
              Malik, J., &amp; Perona, P. (1990). Preattentive texture discrimination with early vision mechanisms.
              <i>
               Journal of the Optical Society of America A
              </i>
              ,
              <i>
               7
              </i>
              (5), 923–932.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 28" data-doi="10.1364/JOSAA.7.000923" data-track="click" data-track-action="article reference" data-track-label="10.1364/JOSAA.7.000923" href="https://doi-org.proxy.lib.ohio-state.edu/10.1364%2FJOSAA.7.000923" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 28" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Preattentive%20texture%20discrimination%20with%20early%20vision%20mechanisms&amp;journal=Journal%20of%20the%20Optical%20Society%20of%20America%20A&amp;doi=10.1364%2FJOSAA.7.000923&amp;volume=7&amp;issue=5&amp;pages=923-932&amp;publication_year=1990&amp;author=Malik%2CJ.&amp;author=Perona%2CP." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR29">
              Malik, J., &amp; Rosenholtz, R. (1997). Computing local surface orientation and shape from texture for curved surfaces.
              <i>
               International Journal of Computer Vision
              </i>
              ,
              <i>
               23
              </i>
              (2), 149–168.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 29" data-doi="10.1023/A:1007958829620" data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1007958829620" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1007958829620" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 29" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computing%20local%20surface%20orientation%20and%20shape%20from%20texture%20for%20curved%20surfaces&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1007958829620&amp;volume=23&amp;issue=2&amp;pages=149-168&amp;publication_year=1997&amp;author=Malik%2CJ.&amp;author=Rosenholtz%2CR." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR30">
              Michels, J., Saxena, A., &amp; Ng, A. Y. (2005). High speed obstacle avoidance using monocular vision and reinforcement learning. In
              <i>
               22nd international conference on machine learning (ICML)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR31">
              Moldovan, T. M., Roth, S., &amp; Black, M. J. (2006). Denoising archival films using a learned Bayesian model. In
              <i>
               International conference on image processing (ICIP)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR32">
              Mortensen, E. N., Deng, H., &amp; Shapiro, L. (2005). A SIFT descriptor with global context. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR33">
              Murphy, K., Torralba, A., &amp; Freeman, W. T. (2003). Using the forest to see the trees: a graphical model relating features, objects, and scenes. In
              <i>
               Neural information processing systems (NIPS)
              </i>
              (Vol. 16).
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR34">
              Nagai, T., Naruse, T., Ikehara, M., &amp; Kurematsu, A. (2002). Hmm-based surface reconstruction from single images. In
              <i>
               IEEE international conference on image processing (ICIP)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR35">
              Narasimhan, S. G., &amp; Nayar, S. K. (2003). Shedding light on the weather. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR36">
              Nestares, O., Navarro, R., Portilia, J., &amp; Tabernero, A. (1998). Efficient spatial-domain implementation of a multiscale image representation based on Gabor functions.
              <i>
               Journal of Electronic Imaging
              </i>
              ,
              <i>
               7
              </i>
              (1), 166–173.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 36" data-doi="10.1117/1.482638" data-track="click" data-track-action="article reference" data-track-label="10.1117/1.482638" href="https://doi-org.proxy.lib.ohio-state.edu/10.1117%2F1.482638" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 36" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Efficient%20spatial-domain%20implementation%20of%20a%20multiscale%20image%20representation%20based%20on%20Gabor%20functions&amp;journal=Journal%20of%20Electronic%20Imaging&amp;doi=10.1117%2F1.482638&amp;volume=7&amp;issue=1&amp;pages=166-173&amp;publication_year=1998&amp;author=Nestares%2CO.&amp;author=Navarro%2CR.&amp;author=Portilia%2CJ.&amp;author=Tabernero%2CA." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR37">
              Oliva, A., &amp; Torralba, A. (2006). Building the gist of a scene: the role of global image features in recognition.
              <i>
               IEEE Transactions on Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               155
              </i>
              , 23–36.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Google Scholar reference 37" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20the%20gist%20of%20a%20scene%3A%20the%20role%20of%20global%20image%20features%20in%20recognition&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;volume=155&amp;pages=23-36&amp;publication_year=2006&amp;author=Oliva%2CA.&amp;author=Torralba%2CA." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR38">
              Olshausen, B. A., &amp; Field, D. J. (1997). Sparse coding with an over-complete basis set: a strategy employed by v1?
              <i>
               Vision Research
              </i>
              ,
              <i>
               37
              </i>
              , 3311–3325.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 38" data-doi="10.1016/S0042-6989(97)00169-7" data-track="click" data-track-action="article reference" data-track-label="10.1016/S0042-6989(97)00169-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0042-6989%2897%2900169-7" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 38" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Sparse%20coding%20with%20an%20over-complete%20basis%20set%3A%20a%20strategy%20employed%20by%20v1%3F&amp;journal=Vision%20Research&amp;doi=10.1016%2FS0042-6989%2897%2900169-7&amp;volume=37&amp;pages=3311-3325&amp;publication_year=1997&amp;author=Olshausen%2CB.%20A.&amp;author=Field%2CD.%20J." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR39">
              Porrill, J., Frisby, J. P., Adams, W. J., &amp; Buckley, D. (1999). Robust and optimal use of information in stereo vision.
              <i>
               Nature
              </i>
              ,
              <i>
               397
              </i>
              , 63–66.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 39" data-doi="10.1038/16244" data-track="click" data-track-action="article reference" data-track-label="10.1038/16244" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F16244" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 39" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20and%20optimal%20use%20of%20information%20in%20stereo%20vision&amp;journal=Nature&amp;doi=10.1038%2F16244&amp;volume=397&amp;pages=63-66&amp;publication_year=1999&amp;author=Porrill%2CJ.&amp;author=Frisby%2CJ.%20P.&amp;author=Adams%2CW.%20J.&amp;author=Buckley%2CD." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR40">
              Quartulli, M., &amp; Datcu, M. (2001). Bayesian model based city reconstruction from high resolution ISAR data. In
              <i>
               IEEE/ISPRS joint workshop remote sensing and data fusion over urban areas
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR41">
              Saxena, A., Anand, A., &amp; Mukerjee, A. (2004). Robust facial expression recognition using spatially localized geometric model. In
              <i>
               International conf systemics, cybernetics and informatics (ICSCI)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR42">
              Saxena, A., Chung, S. H., &amp; Ng, A. Y. (2005). Learning depth from single monocular images. In
              <i>
               Neural information processing system (NIPS)
              </i>
              (Vol. 18).
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR43">
              Saxena, A., Driemeyer, J., Kearns, J., Osondu, C., &amp; Ng, A. Y. (2006a). Learning to grasp novel objects using vision. In
              <i>
               10th international symposium on experimental robotics (ISER)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR44">
              Saxena, A., Sun, M., Agarwal, R., &amp; Ng, A. Y. (2006b).
              <i>
               Learning 3-d scene structure from a single still image
              </i>
              . Stanford Technical Report, November 2006.
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR45">
              Saxena, A., Driemeyer, J., Kearns, J., &amp; Ng, A. Y. (2006c). Robotic grasping of novel objects. In
              <i>
               Neural information processing systems (NIPS)
              </i>
              (Vol. 19).
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR46">
              Saxena, A., Schulte, J., &amp; Ng, A. Y. (2007). Depth estimation using monocular and stereo cues. In
              <i>
               International joint conference on artificial intelligence (IJCAI)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR47">
              Scharstein, D., &amp; Szeliski, R. (2002). A taxonomy and evaluation of dense two-frame stereo correspondence algorithms.
              <i>
               International Journal of Computer Vision
              </i>
              ,
              <i>
               47
              </i>
              (1), 7–42.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 47" data-doi="10.1023/A:1014573219977" data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1014573219977" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1014573219977" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="MATH reference 47" data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1012.68731" rel="nofollow noopener">
               MATH
              </a>
              <a aria-label="Google Scholar reference 47" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20taxonomy%20and%20evaluation%20of%20dense%20two-frame%20stereo%20correspondence%20algorithms&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1014573219977&amp;volume=47&amp;issue=1&amp;pages=7-42&amp;publication_year=2002&amp;author=Scharstein%2CD.&amp;author=Szeliski%2CR." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR48">
              Scharstein, D., &amp; Szeliski, R. (2003) High-accuracy stereo depth maps using structured light. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR49">
              Schwartz, S. H. (1999).
              <i>
               Visual perception
              </i>
              (2nd ed.). Connecticut: Appleton and Lange.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Google Scholar reference 49" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20perception&amp;publication_year=1999&amp;author=Schwartz%2CS.%20H." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR50">
              Serre, T., Wolf, L., &amp; Poggio, T. (2005). Object recognition with features inspired by visual cortex. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR51">
              Strang, G., &amp; Nguyen, T. (1997).
              <i>
               Wavelets and filter banks
              </i>
              . Wellesley: Wellesley-Cambridge Press.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Google Scholar reference 51" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Wavelets%20and%20filter%20banks&amp;publication_year=1997&amp;author=Strang%2CG.&amp;author=Nguyen%2CT." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR52">
              Sudderth, E. B., Torralba, A., Freeman, W. T., &amp; Willisky, A. S. (2006). Depth from familiar objects: A hierarchical model for 3D scenes. In
              <i>
               Computer vision and pattern recognition (CVPR)
              </i>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR53">
              Szeliski, R. (1990). Bayesian modeling of uncertainty in low-level vision. In
              <i>
               International conference on computer vision (ICCV)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR54">
              Thrun, S., &amp; Wegbreit, B. (2005). Shape from symmetry. In
              <i>
               International conference on computer vision (ICCV)
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR55">
              Torralba, A., &amp; Oliva, A. (2002). Depth estimation from image structure.
              <i>
               IEEE Transactions on Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               24
              </i>
              (9), 1–13.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 55" data-doi="10.1109/TPAMI.2002.1033214" data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2002.1033214" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2002.1033214" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 55" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Depth%20estimation%20from%20image%20structure&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2002.1033214&amp;volume=24&amp;issue=9&amp;pages=1-13&amp;publication_year=2002&amp;author=Torralba%2CA.&amp;author=Oliva%2CA." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR56">
              Torresani, L., &amp; Hertzmann, A. (2004). Automatic non-rigid 3D modeling from video. In
              <i>
               European conference on computer vision
              </i>
              .
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR57">
              Wandell, B. A. (1995).
              <i>
               Foundations of vision
              </i>
              . Sunderland: Sinauer Associates.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Google Scholar reference 57" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Foundations%20of%20vision&amp;publication_year=1995&amp;author=Wandell%2CB.%20A." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR58">
              Welchman, A. E., Deubelius, A., Conrad, V., Bülthoff, H. H., &amp; Kourtzi, Z. (2005). 3D shape perception from combined depth cues in human visual cortex.
              <i>
               Nature Neuroscience
              </i>
              ,
              <i>
               8
              </i>
              , 820–827.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 58" data-doi="10.1038/nn1461" data-track="click" data-track-action="article reference" data-track-label="10.1038/nn1461" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnn1461" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 58" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=3D%20shape%20perception%20from%20combined%20depth%20cues%20in%20human%20visual%20cortex&amp;journal=Nature%20Neuroscience&amp;doi=10.1038%2Fnn1461&amp;volume=8&amp;pages=820-827&amp;publication_year=2005&amp;author=Welchman%2CA.%20E.&amp;author=Deubelius%2CA.&amp;author=Conrad%2CV.&amp;author=B%C3%BClthoff%2CH.%20H.&amp;author=Kourtzi%2CZ." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR59">
              Wexler, M., Panerai, F., Lamouret, I., &amp; Droulez, J. (2001). Self-motion and the perception of stationary objects.
              <i>
               Nature
              </i>
              ,
              <i>
               409
              </i>
              , 85–88.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 59" data-doi="10.1038/35051081" data-track="click" data-track-action="article reference" data-track-label="10.1038/35051081" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F35051081" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 59" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Self-motion%20and%20the%20perception%20of%20stationary%20objects&amp;journal=Nature&amp;doi=10.1038%2F35051081&amp;volume=409&amp;pages=85-88&amp;publication_year=2001&amp;author=Wexler%2CM.&amp;author=Panerai%2CF.&amp;author=Lamouret%2CI.&amp;author=Droulez%2CJ." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR60">
              Willsky, A. S. (2002). Multiresolution Markov models for signal and image processing.
              <i>
               Proceedings IEEE
              </i>
              ,
              <i>
               90
              </i>
              (8), 1396–1458.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 60" data-doi="10.1109/JPROC.2002.800717" data-track="click" data-track-action="article reference" data-track-label="10.1109/JPROC.2002.800717" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FJPROC.2002.800717" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 60" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Multiresolution%20Markov%20models%20for%20signal%20and%20image%20processing&amp;journal=Proceedings%20IEEE&amp;doi=10.1109%2FJPROC.2002.800717&amp;volume=90&amp;issue=8&amp;pages=1396-1458&amp;publication_year=2002&amp;author=Willsky%2CA.%20S." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR61">
              Wu, B., Ooi, T. L., &amp; He, Z. J. (2004). Perceiving distance accurately by a directional process of integrating ground information.
              <i>
               Letters to Nature
              </i>
              ,
              <i>
               428
              </i>
              , 73–77.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 61" data-doi="10.1038/nature02350" data-track="click" data-track-action="article reference" data-track-label="10.1038/nature02350" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature02350" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 61" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceiving%20distance%20accurately%20by%20a%20directional%20process%20of%20integrating%20ground%20information&amp;journal=Letters%20to%20Nature&amp;doi=10.1038%2Fnature02350&amp;volume=428&amp;pages=73-77&amp;publication_year=2004&amp;author=Wu%2CB.&amp;author=Ooi%2CT.%20L.&amp;author=He%2CZ.%20J." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR62">
              Zhang, R., Tsai, P.-S., Cryer, J. E., &amp; Shah, M. (1999). Shape from shading: a survey.
              <i>
               IEEE Transactions on Pattern Analysis and Machine Intelligence
              </i>
              ,
              <i>
               21
              </i>
              (8), 690–706.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 62" data-doi="10.1109/34.784284" data-track="click" data-track-action="article reference" data-track-label="10.1109/34.784284" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F34.784284" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 62" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Shape%20from%20shading%3A%20a%20survey&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2F34.784284&amp;volume=21&amp;issue=8&amp;pages=690-706&amp;publication_year=1999&amp;author=Zhang%2CR.&amp;author=Tsai%2CP.-S.&amp;author=Cryer%2CJ.%20E.&amp;author=Shah%2CM." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
            <li class="c-article-references__item js-c-reading-companion-references-item">
             <p class="c-article-references__text" id="ref-CR63">
              Zhao, W., Chellappa, R., Phillips, P. J., &amp; Rosenfield, A. (2003). Face recognition: a literature survey.
              <i>
               ACM Computing Surveys
              </i>
              ,
              <i>
               35
              </i>
              , 399–458.
             </p>
             <p class="c-article-references__links u-hide-print">
              <a aria-label="Article reference 63" data-doi="10.1145/954339.954342" data-track="click" data-track-action="article reference" data-track-label="10.1145/954339.954342" href="https://doi-org.proxy.lib.ohio-state.edu/10.1145%2F954339.954342" rel="nofollow noopener">
               Article
              </a>
              <a aria-label="Google Scholar reference 63" data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Face%20recognition%3A%20a%C2%A0literature%20survey&amp;journal=ACM%20Computing%20Surveys&amp;doi=10.1145%2F954339.954342&amp;volume=35&amp;pages=399-458&amp;publication_year=2003&amp;author=Zhao%2CW.&amp;author=Chellappa%2CR.&amp;author=Phillips%2CP.%20J.&amp;author=Rosenfield%2CA." rel="nofollow noopener">
               Google Scholar
              </a>
             </p>
            </li>
           </ul>
           <p class="c-article-references__download u-hide-print">
            <a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed-springer-com.proxy.lib.ohio-state.edu/v2/references/10.1007/s11263-007-0071-y?format=refman&amp;flavour=references" rel="nofollow">
             Download references
             <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
              <use xlink:href="#icon-download" xmlns:xlink="http://www.w3.org/1999/xlink">
              </use>
             </svg>
            </a>
           </p>
          </div>
         </div>
        </div>
       </section>
      </div>
      <section aria-labelledby="author-information" data-title="Author information">
       <div class="c-article-section" id="author-information-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">
         Author information
        </h2>
        <div class="c-article-section__content" id="author-information-content">
         <h3 class="c-article__sub-heading" id="affiliations">
          Authors and Affiliations
         </h3>
         <ol class="c-article-author-affiliation__list">
          <li id="Aff1">
           <p class="c-article-author-affiliation__address">
            Computer Science Department, Stanford University, Stanford, CA, 94305, USA
           </p>
           <p class="c-article-author-affiliation__authors-list">
            Ashutosh Saxena, Sung H. Chung &amp; Andrew Y. Ng
           </p>
          </li>
         </ol>
         <div class="u-js-hide u-hide-print" data-test="author-info">
          <span class="c-article__sub-heading">
           Authors
          </span>
          <ol class="c-article-authors-search u-list-reset">
           <li id="auth-Ashutosh-Saxena-Aff1">
            <span class="c-article-authors-search__title u-h3 js-search-name">
             Ashutosh Saxena
            </span>
            <div class="c-article-authors-search__list">
             <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
              <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?dc.creator=Ashutosh%20Saxena" rel="nofollow">
               View author publications
              </a>
             </div>
             <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
              <p class="search-in-title-js c-article-authors-search__text">
               You can also search for this author in
               <span class="c-article-identifiers">
                <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Ashutosh%20Saxena" rel="nofollow">
                 PubMed
                </a>
                <span class="u-hide">
                </span>
                <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ashutosh%20Saxena%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                 Google Scholar
                </a>
               </span>
              </p>
             </div>
            </div>
           </li>
           <li id="auth-Sung_H_-Chung-Aff1">
            <span class="c-article-authors-search__title u-h3 js-search-name">
             Sung H. Chung
            </span>
            <div class="c-article-authors-search__list">
             <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
              <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?dc.creator=Sung%20H.%20Chung" rel="nofollow">
               View author publications
              </a>
             </div>
             <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
              <p class="search-in-title-js c-article-authors-search__text">
               You can also search for this author in
               <span class="c-article-identifiers">
                <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Sung%20H.%20Chung" rel="nofollow">
                 PubMed
                </a>
                <span class="u-hide">
                </span>
                <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Sung%20H.%20Chung%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                 Google Scholar
                </a>
               </span>
              </p>
             </div>
            </div>
           </li>
           <li id="auth-Andrew_Y_-Ng-Aff1">
            <span class="c-article-authors-search__title u-h3 js-search-name">
             Andrew Y. Ng
            </span>
            <div class="c-article-authors-search__list">
             <div class="c-article-authors-search__item c-article-authors-search__list-item--left">
              <a class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" href="/search?dc.creator=Andrew%20Y.%20Ng" rel="nofollow">
               View author publications
              </a>
             </div>
             <div class="c-article-authors-search__item c-article-authors-search__list-item--right">
              <p class="search-in-title-js c-article-authors-search__text">
               You can also search for this author in
               <span class="c-article-identifiers">
                <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - pubmed" data-track-label="link" href="http://www-ncbi-nlm-nih-gov.proxy.lib.ohio-state.edu/entrez/query.fcgi?cmd=search&amp;term=Andrew%20Y.%20Ng" rel="nofollow">
                 PubMed
                </a>
                <span class="u-hide">
                </span>
                <a class="c-article-identifiers__item" data-track="click" data-track-action="author link - scholar" data-track-label="link" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Andrew%20Y.%20Ng%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" rel="nofollow">
                 Google Scholar
                </a>
               </span>
              </p>
             </div>
            </div>
           </li>
          </ol>
         </div>
         <h3 class="c-article__sub-heading" id="corresponding-author">
          Corresponding author
         </h3>
         <p id="corresponding-author-list">
          Correspondence to
          <a href="mailto:asaxena@cs.stanford.edu" id="corresp-c1">
           Ashutosh Saxena
          </a>
          .
         </p>
        </div>
       </div>
      </section>
      <section data-title="Rights and permissions">
       <div class="c-article-section" id="rightslink-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">
         Rights and permissions
        </h2>
        <div class="c-article-section__content" id="rightslink-content">
         <p>
          <b>
           Open Access
          </b>
          This is an open access article distributed under the terms of the Creative Commons Attribution Noncommercial License (
          <a href="https://creativecommons.org/licenses/by-nc/2.0" rel="license">
           https://creativecommons.org/licenses/by-nc/2.0
          </a>
          ), which permits any noncommercial use, distribution, and reproduction in any medium, provided the original author(s) and source are credited.
         </p>
         <p class="c-article-rights">
          <a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=3-D%20Depth%20Reconstruction%20from%20a%20Single%20Still%20Image&amp;author=Ashutosh%20Saxena%20et%20al&amp;contentID=10.1007%2Fs11263-007-0071-y&amp;copyright=Springer%20Science%2BBusiness%20Media%2C%20LLC&amp;publication=0920-5691&amp;publicationDate=2007-08-16&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY-NC">
           Reprints and Permissions
          </a>
         </p>
        </div>
       </div>
      </section>
      <section aria-labelledby="article-info" data-title="About this article">
       <div class="c-article-section" id="article-info-section">
        <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">
         About this article
        </h2>
        <div class="c-article-section__content" id="article-info-content">
         <div class="c-bibliographic-information">
          <div class="c-bibliographic-information__column">
           <h3 class="c-article__sub-heading" id="citeas">
            Cite this article
           </h3>
           <p class="c-bibliographic-information__citation">
            Saxena, A., Chung, S.H. &amp; Ng, A.Y. 3-D Depth Reconstruction from a Single Still Image.
            <i>
             Int J Comput Vis
            </i>
            <b>
             76
            </b>
            , 53–69 (2008). https://doi-org.proxy.lib.ohio-state.edu/10.1007/s11263-007-0071-y
           </p>
           <p class="c-bibliographic-information__download-citation u-hide-print">
            <a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-external="" data-track-label="link" href="https://citation-needed-springer-com.proxy.lib.ohio-state.edu/v2/references/10.1007/s11263-007-0071-y?format=refman&amp;flavour=citation" rel="nofollow">
             Download citation
             <svg aria-hidden="true" class="u-icon" focusable="false" height="16" role="img" width="16">
              <use xlink:href="#icon-download" xmlns:xlink="http://www.w3.org/1999/xlink">
              </use>
             </svg>
            </a>
           </p>
           <ul class="c-bibliographic-information__list" data-test="publication-history">
            <li class="c-bibliographic-information__list-item">
             <p>
              Received
              <span class="u-hide">
               :
              </span>
              <span class="c-bibliographic-information__value">
               <time datetime="2006-11-01">
                01 November 2006
               </time>
              </span>
             </p>
            </li>
            <li class="c-bibliographic-information__list-item">
             <p>
              Accepted
              <span class="u-hide">
               :
              </span>
              <span class="c-bibliographic-information__value">
               <time datetime="2007-06-06">
                06 June 2007
               </time>
              </span>
             </p>
            </li>
            <li class="c-bibliographic-information__list-item">
             <p>
              Published
              <span class="u-hide">
               :
              </span>
              <span class="c-bibliographic-information__value">
               <time datetime="2007-08-16">
                16 August 2007
               </time>
              </span>
             </p>
            </li>
            <li class="c-bibliographic-information__list-item">
             <p>
              Issue Date
              <span class="u-hide">
               :
              </span>
              <span class="c-bibliographic-information__value">
               <time datetime="2008-01">
                January 2008
               </time>
              </span>
             </p>
            </li>
            <li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width">
             <p>
              <abbr title="Digital Object Identifier">
               DOI
              </abbr>
              <span class="u-hide">
               :
              </span>
              <span class="c-bibliographic-information__value">
               https://doi.org/10.1007/s11263-007-0071-y
              </span>
             </p>
            </li>
           </ul>
           <div data-component="share-box">
            <div class="c-article-share-box u-display-block">
             <h3 class="c-article__sub-heading">
              Share this article
             </h3>
             <p class="c-article-share-box__description">
              Anyone you share the following link with will be able to read this content:
             </p>
             <button class="js-get-share-url c-article-share-box__button" data-track="click" data-track-action="get shareable link" data-track-external="" data-track-label="button" id="get-share-url" type="button">
              Get shareable link
             </button>
             <div class="js-no-share-url-container u-display-none" hidden="">
              <p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">
               Sorry, a shareable link is not currently available for this article.
              </p>
             </div>
             <div class="js-share-url-container u-display-none" hidden="">
              <p class="js-share-url c-article-share-box__only-read-input" data-track="click" data-track-action="select share url" data-track-label="button" id="share-url">
              </p>
              <button class="js-copy-share-url c-article-share-box__button--link-like" data-track="click" data-track-action="copy share url" data-track-external="" data-track-label="button" id="copy-share-url" type="button">
               Copy to clipboard
              </button>
             </div>
             <p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
              Provided by the Springer Nature SharedIt content-sharing initiative
             </p>
            </div>
           </div>
           <h3 class="c-article__sub-heading">
            Keywords
           </h3>
           <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Monocular%20vision&amp;facet-discipline=%20Computer%20Science%20">
               Monocular vision
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Learning%20depth&amp;facet-discipline=%20Computer%20Science%20">
               Learning depth
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=3D%20reconstruction&amp;facet-discipline=%20Computer%20Science%20">
               3D reconstruction
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Dense%20reconstruction&amp;facet-discipline=%20Computer%20Science%20">
               Dense reconstruction
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Markov%20random%20field&amp;facet-discipline=%20Computer%20Science%20">
               Markov random field
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Depth%20estimation&amp;facet-discipline=%20Computer%20Science%20">
               Depth estimation
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Monocular%20depth&amp;facet-discipline=%20Computer%20Science%20">
               Monocular depth
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Stereo%20vision&amp;facet-discipline=%20Computer%20Science%20">
               Stereo vision
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Hand-held%20camera&amp;facet-discipline=%20Computer%20Science%20">
               Hand-held camera
              </a>
             </span>
            </li>
            <li class="c-article-subject-list__subject">
             <span>
              <a data-track="click" data-track-action="view keyword" data-track-label="link" href="/search?query=Visual%20modeling&amp;facet-discipline=%20Computer%20Science%20">
               Visual modeling
              </a>
             </span>
            </li>
           </ul>
           <div data-component="article-info-list">
           </div>
          </div>
         </div>
        </div>
       </div>
      </section>
     </div>
    </main>
    <div class="c-article-sidebar u-text-sm u-hide-print l-with-sidebar__sidebar" data-container-type="reading-companion" data-track-component="reading companion" id="sidebar">
     <aside>
      <div class="c-card-service" data-test="article-checklist-banner">
       <div>
        <a class="c-card-service__link" data-track="click" data-track-action="clicked article page checklist banner test 2 old version" data-track-category="pre-submission-checklist" data-track-label="link" href="https://beta-springernature-com.proxy.lib.ohio-state.edu/pre-submission?journalId=11263">
         <span class="c-card-service__link-text">
          Use our pre-submission checklist
         </span>
         <svg aria-hidden="true" class="c-card-service__link-icon" focusable="false">
          <use xlink:href="#icon-eds-small-arrow-right">
          </use>
         </svg>
        </a>
        <p class="c-card-service__description">
         Avoid common mistakes on your manuscript.
        </p>
       </div>
       <div class="c-card-service__icon-container">
        <svg aria-hidden="true" class="c-card-service__icon" focusable="false">
         <use xlink:href="#icon-eds-checklist">
         </use>
        </svg>
       </div>
      </div>
      <div data-test="collections">
      </div>
      <div data-test="editorial-summary">
      </div>
      <div class="c-reading-companion">
       <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky" style="top: 40px;">
        <ul class="c-reading-companion__tabs" role="tablist">
         <li role="presentation">
          <button aria-controls="tabpanel-sections" aria-selected="true" class="c-reading-companion__tab c-reading-companion__tab--active" data-tab-target="sections" data-track="click" data-track-action="sections tab" data-track-label="tab" id="tab-sections" role="tab">
           Sections
          </button>
         </li>
         <li role="presentation">
          <button aria-controls="tabpanel-references" aria-selected="false" class="c-reading-companion__tab" data-tab-target="references" data-track="click" data-track-action="references tab" data-track-label="tab" id="tab-references" role="tab" tabindex="-1">
           References
          </button>
         </li>
        </ul>
        <div aria-labelledby="tab-sections" class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections" role="tabpanel">
         <div class="c-reading-companion__scroll-pane" style="max-height: none;">
          <ul class="c-reading-companion__sections-list">
           <li class="c-reading-companion__section-item c-reading-companion__section-item--active" id="rc-sec-Abs1">
            <a data-track="click" data-track-action="section anchor" data-track-label="link:Abstract" href="#Abs1">
             Abstract
            </a>
           </li>
           <li class="c-reading-companion__section-item" id="rc-sec-Bib1">
            <a data-track="click" data-track-action="section anchor" data-track-label="link:References" href="#Bib1">
             References
            </a>
           </li>
           <li class="c-reading-companion__section-item" id="rc-sec-author-information">
            <a data-track="click" data-track-action="section anchor" data-track-label="link:Author information" href="#author-information">
             Author information
            </a>
           </li>
           <li class="c-reading-companion__section-item" id="rc-sec-rightslink">
            <a data-track="click" data-track-action="section anchor" data-track-label="link:Rights and permissions" href="#rightslink">
             Rights and permissions
            </a>
           </li>
           <li class="c-reading-companion__section-item" id="rc-sec-article-info">
            <a data-track="click" data-track-action="section anchor" data-track-label="link:About this article" href="#article-info">
             About this article
            </a>
           </li>
          </ul>
         </div>
         <div class="u-lazy-ad-wrapper u-mt-16 u-show" data-component-mpu="">
          <div class="c-ad c-ad--300x250">
           <div class="c-ad__inner">
            <p class="c-ad__label">
             Advertisement
            </p>
            <div class="div-gpt-ad grade-c-hide" data-gpt="" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=s11263-007-0071-y;" data-gpt-unitpath="/270604982/springerlink/11263/article" data-pa11y-ignore="" data-test="MPU1-ad" id="div-gpt-ad-MPU1">
            </div>
           </div>
          </div>
         </div>
        </div>
        <div aria-labelledby="tab-references" class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references" role="tabpanel">
         <div class="c-reading-companion__scroll-pane">
          <ol class="c-reading-companion__references-list">
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR1">
             Anguelov, D., Srinivasan, P., Koller, D., Thrun, S., Rodgers, J., &amp; Davis, J. (2005). SCAPE: shape completion and animation of people.
             <i>
              ACM Transactions on Graphics
             </i>
             ,
             <i>
              24
             </i>
             (3), 408–416.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1145/1073204.1073207" href="https://doi-org.proxy.lib.ohio-state.edu/10.1145%2F1073204.1073207">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=SCAPE%3A%20shape%20completion%20and%20animation%20of%20people&amp;journal=ACM%20Transactions%20on%20Graphics&amp;doi=10.1145%2F1073204.1073207&amp;volume=24&amp;issue=3&amp;pages=408-416&amp;publication_year=2005&amp;author=Anguelov%2CD.&amp;author=Srinivasan%2CP.&amp;author=Koller%2CD.&amp;author=Thrun%2CS.&amp;author=Rodgers%2CJ.&amp;author=Davis%2CJ.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR2">
             Barron, J. L., Fleet, D. J., &amp; Beauchemin, S. S. (1994). Performance of optical flow techniques.
             <i>
              International Journal of Computer Vision
             </i>
             ,
             <i>
              12
             </i>
             , 43–77.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1007/BF01420984" href="https://doi-org.proxy.lib.ohio-state.edu/10.1007%2FBF01420984">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance%20of%20optical%20flow%20techniques&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1007%2FBF01420984&amp;volume=12&amp;pages=43-77&amp;publication_year=1994&amp;author=Barron%2CJ.%20L.&amp;author=Fleet%2CD.%20J.&amp;author=Beauchemin%2CS.%20S.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR3">
             Brown, M. Z., Burschka, D., &amp; Hager, G. D. (2003). Advances in computational stereo.
             <i>
              IEEE Transactions on Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              25
             </i>
             (8), 993–1008.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2003.1217603" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2003.1217603">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Advances%20in%20computational%20stereo&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2003.1217603&amp;volume=25&amp;issue=8&amp;pages=993-1008&amp;publication_year=2003&amp;author=Brown%2CM.%20Z.&amp;author=Burschka%2CD.&amp;author=Hager%2CG.%20D.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR4">
             Bulthoff, I., Bulthoff, H., &amp; Sinha, P. (1998). Top-down influences on stereoscopic depth-perception.
             <i>
              Nature Neuroscience
             </i>
             ,
             <i>
              1
             </i>
             , 254–257.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/699" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F699">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Top-down%20influences%20on%20stereoscopic%20depth-perception&amp;journal=Nature%20Neuroscience&amp;doi=10.1038%2F699&amp;volume=1&amp;pages=254-257&amp;publication_year=1998&amp;author=Bulthoff%2CI.&amp;author=Bulthoff%2CH.&amp;author=Sinha%2CP.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR5">
             Cornelis, N., Leibe, B., Cornelis, K., &amp; Van Gool, L. (2006). 3d city modeling using cognitive loops. In
             <i>
              Video proceedings of CVPR (VPCVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR6">
             Criminisi, A., Reid, I., &amp; Zisserman, A. (2000). Single view metrology.
             <i>
              International Journal of Computer Vision
             </i>
             ,
             <i>
              40
             </i>
             , 123–148.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1026598000963" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1026598000963">
              Article
             </a>
             <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1012.68704">
              MATH
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Single%20view%20metrology&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1026598000963&amp;volume=40&amp;pages=123-148&amp;publication_year=2000&amp;author=Criminisi%2CA.&amp;author=Reid%2CI.&amp;author=Zisserman%2CA.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR7">
             Das, S., &amp; Ahuja, N. (1995). Performance analysis of stereo, vergence, and focus as depth cues for active vision.
             <i>
              IEEE Transactions on Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              17
             </i>
             (12), 1213–1219.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/34.476513" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F34.476513">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance%20analysis%20of%20stereo%2C%20vergence%2C%20and%20focus%20as%20depth%20cues%20for%20active%20vision&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2F34.476513&amp;volume=17&amp;issue=12&amp;pages=1213-1219&amp;publication_year=1995&amp;author=Das%2CS.&amp;author=Ahuja%2CN.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR8">
             Davies, E. R. (1997). Laws’ texture energy in
             <span class="u-small-caps">
              texture
             </span>
             . In
             <i>
              Machine vision: theory, algorithms, practicalities
             </i>
             (2nd ed.). San Diego: Academic Press.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Laws%E2%80%99%20texture%20energy%20in%20texture&amp;publication_year=1997&amp;author=Davies%2CE.%20R.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR9">
             Delage, E., Lee, H., &amp; Ng, A. Y. (2005). Automatic single-image 3d reconstructions of indoor Manhattan world scenes. In
             <i>
              12th International Symposium of Robotics Research (ISRR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR10">
             Delage, E., Lee, H., &amp; Ng, A. Y. (2006). A dynamic Bayesian network model for autonomous 3D reconstruction from a single indoor image. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR11">
             Forsyth, D. A., &amp; Ponce, J. (2003).
             <i>
              Computer vision: a modern approach
             </i>
             . New York: Prentice Hall.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computer%20vision%3A%20a%20modern%20approach&amp;publication_year=2003&amp;author=Forsyth%2CD.%20A.&amp;author=Ponce%2CJ.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR12">
             Frueh, C., &amp; Zakhor, A. (2003). Constructing 3D city models by merging ground-based and airborne views. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR13">
             Gini, G., &amp; Marchi, A. (2002). Indoor robot navigation with single camera vision. In
             <i>
              PRIS
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR14">
             Harkness, L. (1977). Chameleons use accommodation cues to judge distance.
             <i>
              Nature
             </i>
             ,
             <i>
              267
             </i>
             , 346–349.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/267346a0" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F267346a0">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Chameleons%20use%20accommodation%20cues%20to%20judge%20distance&amp;journal=Nature&amp;doi=10.1038%2F267346a0&amp;volume=267&amp;pages=346-349&amp;publication_year=1977&amp;author=Harkness%2CL.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR15">
             He, X., Zemel, R., &amp; Perpinan, M. (2004). Multiscale conditional random fields for image labeling. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR16">
             Hertzmann, A., &amp; Seitz, S. M. (2005). Example-based photometric stereo: Shape reconstruction with general, varying brdfs.
             <i>
              IEEE Transactions on Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              27
             </i>
             (8), 1254–1264.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2005.158" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2005.158">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Example-based%20photometric%20stereo%3A%20Shape%20reconstruction%20with%20general%2C%20varying%20brdfs&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2005.158&amp;volume=27&amp;issue=8&amp;pages=1254-1264&amp;publication_year=2005&amp;author=Hertzmann%2CA.&amp;author=Seitz%2CS.%20M.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR17">
             Hoiem, D., Efros, A. A., &amp; Herbert, M. (2005a). Geometric context from a single image. In
             <i>
              International conference on computer vision (ICCV)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR18">
             Hoiem, D., Efros, A. A., &amp; Herbert, M. (2005b). Automatic photo pop-up. In
             <i>
              ACM SIGGRAPH
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR19">
             Hoiem, D., Efros, A. A., &amp; Herbert, M. (2006). Putting objects in perspective. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR20">
             Huang, J., Lee, A. B., &amp; Mumford, D. (2000). Statistics of range images. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR21">
             Kolmogorov, V., Criminisi, A., Blake, A., Cross, G., &amp; Rother, C. (2006). Probabilistic fusion of stereo with color and contrast for bilayer segmentation.
             <i>
              IEEE Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              28
             </i>
             (9), 1480–1492.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2006.193" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2006.193">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Probabilistic%20fusion%20of%20stereo%20with%20color%20and%20contrast%20for%20bilayer%20segmentation&amp;journal=IEEE%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2006.193&amp;volume=28&amp;issue=9&amp;pages=1480-1492&amp;publication_year=2006&amp;author=Kolmogorov%2CV.&amp;author=Criminisi%2CA.&amp;author=Blake%2CA.&amp;author=Cross%2CG.&amp;author=Rother%2CC.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR22">
             Konishi, S., &amp; Yuille, A. (2000). Statistical cues for domain specific image segmentation with performance analysis. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR23">
             Kumar, S., &amp; Hebert, M. (2003). Discriminative fields for modeling spatial dependencies in natural images. In
             <i>
              Neural information processing systems (NIPS)
             </i>
             (Vol. 16).
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR24">
             Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional random fields: probabilistic models for segmenting and labeling sequence data. In
             <i>
              International conference on machine learning (ICML)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR25">
             Lindeberg, T., &amp; Garding, J. (1993). Shape from texture from a multi-scale perspective. In
             <i>
              International conference on computer vision (ICCV)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR26">
             Loomis, J. M. (2001). Looking down is looking up.
             <i>
              Nature News and Views
             </i>
             ,
             <i>
              414
             </i>
             , 155–156.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/35102648" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F35102648">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Looking%20down%20is%20looking%20up&amp;journal=Nature%20News%20and%20Views&amp;doi=10.1038%2F35102648&amp;volume=414&amp;pages=155-156&amp;publication_year=2001&amp;author=Loomis%2CJ.%20M.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR27">
             Maki, A., Watanabe, M., &amp; Wiles, C. (2002). Geotensity: combining motion and lighting for 3d surface reconstruction.
             <i>
              International Journal of Computer Vision
             </i>
             ,
             <i>
              48
             </i>
             (2), 75–90.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1016057422703" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1016057422703">
              Article
             </a>
             <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1012.68753">
              MATH
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Geotensity%3A%20combining%20motion%20and%20lighting%20for%203d%20surface%20reconstruction&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1016057422703&amp;volume=48&amp;issue=2&amp;pages=75-90&amp;publication_year=2002&amp;author=Maki%2CA.&amp;author=Watanabe%2CM.&amp;author=Wiles%2CC.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR28">
             Malik, J., &amp; Perona, P. (1990). Preattentive texture discrimination with early vision mechanisms.
             <i>
              Journal of the Optical Society of America A
             </i>
             ,
             <i>
              7
             </i>
             (5), 923–932.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1364/JOSAA.7.000923" href="https://doi-org.proxy.lib.ohio-state.edu/10.1364%2FJOSAA.7.000923">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Preattentive%20texture%20discrimination%20with%20early%20vision%20mechanisms&amp;journal=Journal%20of%20the%20Optical%20Society%20of%20America%20A&amp;doi=10.1364%2FJOSAA.7.000923&amp;volume=7&amp;issue=5&amp;pages=923-932&amp;publication_year=1990&amp;author=Malik%2CJ.&amp;author=Perona%2CP.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR29">
             Malik, J., &amp; Rosenholtz, R. (1997). Computing local surface orientation and shape from texture for curved surfaces.
             <i>
              International Journal of Computer Vision
             </i>
             ,
             <i>
              23
             </i>
             (2), 149–168.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1007958829620" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1007958829620">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Computing%20local%20surface%20orientation%20and%20shape%20from%20texture%20for%20curved%20surfaces&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1007958829620&amp;volume=23&amp;issue=2&amp;pages=149-168&amp;publication_year=1997&amp;author=Malik%2CJ.&amp;author=Rosenholtz%2CR.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR30">
             Michels, J., Saxena, A., &amp; Ng, A. Y. (2005). High speed obstacle avoidance using monocular vision and reinforcement learning. In
             <i>
              22nd international conference on machine learning (ICML)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR31">
             Moldovan, T. M., Roth, S., &amp; Black, M. J. (2006). Denoising archival films using a learned Bayesian model. In
             <i>
              International conference on image processing (ICIP)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR32">
             Mortensen, E. N., Deng, H., &amp; Shapiro, L. (2005). A SIFT descriptor with global context. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR33">
             Murphy, K., Torralba, A., &amp; Freeman, W. T. (2003). Using the forest to see the trees: a graphical model relating features, objects, and scenes. In
             <i>
              Neural information processing systems (NIPS)
             </i>
             (Vol. 16).
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR34">
             Nagai, T., Naruse, T., Ikehara, M., &amp; Kurematsu, A. (2002). Hmm-based surface reconstruction from single images. In
             <i>
              IEEE international conference on image processing (ICIP)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR35">
             Narasimhan, S. G., &amp; Nayar, S. K. (2003). Shedding light on the weather. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR36">
             Nestares, O., Navarro, R., Portilia, J., &amp; Tabernero, A. (1998). Efficient spatial-domain implementation of a multiscale image representation based on Gabor functions.
             <i>
              Journal of Electronic Imaging
             </i>
             ,
             <i>
              7
             </i>
             (1), 166–173.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1117/1.482638" href="https://doi-org.proxy.lib.ohio-state.edu/10.1117%2F1.482638">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Efficient%20spatial-domain%20implementation%20of%20a%20multiscale%20image%20representation%20based%20on%20Gabor%20functions&amp;journal=Journal%20of%20Electronic%20Imaging&amp;doi=10.1117%2F1.482638&amp;volume=7&amp;issue=1&amp;pages=166-173&amp;publication_year=1998&amp;author=Nestares%2CO.&amp;author=Navarro%2CR.&amp;author=Portilia%2CJ.&amp;author=Tabernero%2CA.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR37">
             Oliva, A., &amp; Torralba, A. (2006). Building the gist of a scene: the role of global image features in recognition.
             <i>
              IEEE Transactions on Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              155
             </i>
             , 23–36.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20the%20gist%20of%20a%20scene%3A%20the%20role%20of%20global%20image%20features%20in%20recognition&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;volume=155&amp;pages=23-36&amp;publication_year=2006&amp;author=Oliva%2CA.&amp;author=Torralba%2CA.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR38">
             Olshausen, B. A., &amp; Field, D. J. (1997). Sparse coding with an over-complete basis set: a strategy employed by v1?
             <i>
              Vision Research
             </i>
             ,
             <i>
              37
             </i>
             , 3311–3325.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1016/S0042-6989(97)00169-7" href="https://doi-org.proxy.lib.ohio-state.edu/10.1016%2FS0042-6989%2897%2900169-7">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Sparse%20coding%20with%20an%20over-complete%20basis%20set%3A%20a%20strategy%20employed%20by%20v1%3F&amp;journal=Vision%20Research&amp;doi=10.1016%2FS0042-6989%2897%2900169-7&amp;volume=37&amp;pages=3311-3325&amp;publication_year=1997&amp;author=Olshausen%2CB.%20A.&amp;author=Field%2CD.%20J.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR39">
             Porrill, J., Frisby, J. P., Adams, W. J., &amp; Buckley, D. (1999). Robust and optimal use of information in stereo vision.
             <i>
              Nature
             </i>
             ,
             <i>
              397
             </i>
             , 63–66.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/16244" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F16244">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20and%20optimal%20use%20of%20information%20in%20stereo%20vision&amp;journal=Nature&amp;doi=10.1038%2F16244&amp;volume=397&amp;pages=63-66&amp;publication_year=1999&amp;author=Porrill%2CJ.&amp;author=Frisby%2CJ.%20P.&amp;author=Adams%2CW.%20J.&amp;author=Buckley%2CD.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR40">
             Quartulli, M., &amp; Datcu, M. (2001). Bayesian model based city reconstruction from high resolution ISAR data. In
             <i>
              IEEE/ISPRS joint workshop remote sensing and data fusion over urban areas
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR41">
             Saxena, A., Anand, A., &amp; Mukerjee, A. (2004). Robust facial expression recognition using spatially localized geometric model. In
             <i>
              International conf systemics, cybernetics and informatics (ICSCI)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR42">
             Saxena, A., Chung, S. H., &amp; Ng, A. Y. (2005). Learning depth from single monocular images. In
             <i>
              Neural information processing system (NIPS)
             </i>
             (Vol. 18).
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR43">
             Saxena, A., Driemeyer, J., Kearns, J., Osondu, C., &amp; Ng, A. Y. (2006a). Learning to grasp novel objects using vision. In
             <i>
              10th international symposium on experimental robotics (ISER)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR44">
             Saxena, A., Sun, M., Agarwal, R., &amp; Ng, A. Y. (2006b).
             <i>
              Learning 3-d scene structure from a single still image
             </i>
             . Stanford Technical Report, November 2006.
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR45">
             Saxena, A., Driemeyer, J., Kearns, J., &amp; Ng, A. Y. (2006c). Robotic grasping of novel objects. In
             <i>
              Neural information processing systems (NIPS)
             </i>
             (Vol. 19).
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR46">
             Saxena, A., Schulte, J., &amp; Ng, A. Y. (2007). Depth estimation using monocular and stereo cues. In
             <i>
              International joint conference on artificial intelligence (IJCAI)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR47">
             Scharstein, D., &amp; Szeliski, R. (2002). A taxonomy and evaluation of dense two-frame stereo correspondence algorithms.
             <i>
              International Journal of Computer Vision
             </i>
             ,
             <i>
              47
             </i>
             (1), 7–42.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1023/A:1014573219977" href="https://doi-org.proxy.lib.ohio-state.edu/10.1023%2FA%3A1014573219977">
              Article
             </a>
             <a data-track="click" data-track-action="math reference" data-track-label="link" href="http://www-emis-de.proxy.lib.ohio-state.edu/MATH-item?1012.68731">
              MATH
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20taxonomy%20and%20evaluation%20of%20dense%20two-frame%20stereo%20correspondence%20algorithms&amp;journal=International%20Journal%20of%20Computer%20Vision&amp;doi=10.1023%2FA%3A1014573219977&amp;volume=47&amp;issue=1&amp;pages=7-42&amp;publication_year=2002&amp;author=Scharstein%2CD.&amp;author=Szeliski%2CR.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR48">
             Scharstein, D., &amp; Szeliski, R. (2003) High-accuracy stereo depth maps using structured light. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR49">
             Schwartz, S. H. (1999).
             <i>
              Visual perception
             </i>
             (2nd ed.). Connecticut: Appleton and Lange.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20perception&amp;publication_year=1999&amp;author=Schwartz%2CS.%20H.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR50">
             Serre, T., Wolf, L., &amp; Poggio, T. (2005). Object recognition with features inspired by visual cortex. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR51">
             Strang, G., &amp; Nguyen, T. (1997).
             <i>
              Wavelets and filter banks
             </i>
             . Wellesley: Wellesley-Cambridge Press.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Wavelets%20and%20filter%20banks&amp;publication_year=1997&amp;author=Strang%2CG.&amp;author=Nguyen%2CT.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR52">
             Sudderth, E. B., Torralba, A., Freeman, W. T., &amp; Willisky, A. S. (2006). Depth from familiar objects: A hierarchical model for 3D scenes. In
             <i>
              Computer vision and pattern recognition (CVPR)
             </i>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR53">
             Szeliski, R. (1990). Bayesian modeling of uncertainty in low-level vision. In
             <i>
              International conference on computer vision (ICCV)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR54">
             Thrun, S., &amp; Wegbreit, B. (2005). Shape from symmetry. In
             <i>
              International conference on computer vision (ICCV)
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR55">
             Torralba, A., &amp; Oliva, A. (2002). Depth estimation from image structure.
             <i>
              IEEE Transactions on Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              24
             </i>
             (9), 1–13.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/TPAMI.2002.1033214" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FTPAMI.2002.1033214">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Depth%20estimation%20from%20image%20structure&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2FTPAMI.2002.1033214&amp;volume=24&amp;issue=9&amp;pages=1-13&amp;publication_year=2002&amp;author=Torralba%2CA.&amp;author=Oliva%2CA.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR56">
             Torresani, L., &amp; Hertzmann, A. (2004). Automatic non-rigid 3D modeling from video. In
             <i>
              European conference on computer vision
             </i>
             .
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR57">
             Wandell, B. A. (1995).
             <i>
              Foundations of vision
             </i>
             . Sunderland: Sinauer Associates.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Foundations%20of%20vision&amp;publication_year=1995&amp;author=Wandell%2CB.%20A.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR58">
             Welchman, A. E., Deubelius, A., Conrad, V., Bülthoff, H. H., &amp; Kourtzi, Z. (2005). 3D shape perception from combined depth cues in human visual cortex.
             <i>
              Nature Neuroscience
             </i>
             ,
             <i>
              8
             </i>
             , 820–827.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nn1461" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnn1461">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=3D%20shape%20perception%20from%20combined%20depth%20cues%20in%20human%20visual%20cortex&amp;journal=Nature%20Neuroscience&amp;doi=10.1038%2Fnn1461&amp;volume=8&amp;pages=820-827&amp;publication_year=2005&amp;author=Welchman%2CA.%20E.&amp;author=Deubelius%2CA.&amp;author=Conrad%2CV.&amp;author=B%C3%BClthoff%2CH.%20H.&amp;author=Kourtzi%2CZ.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR59">
             Wexler, M., Panerai, F., Lamouret, I., &amp; Droulez, J. (2001). Self-motion and the perception of stationary objects.
             <i>
              Nature
             </i>
             ,
             <i>
              409
             </i>
             , 85–88.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/35051081" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2F35051081">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Self-motion%20and%20the%20perception%20of%20stationary%20objects&amp;journal=Nature&amp;doi=10.1038%2F35051081&amp;volume=409&amp;pages=85-88&amp;publication_year=2001&amp;author=Wexler%2CM.&amp;author=Panerai%2CF.&amp;author=Lamouret%2CI.&amp;author=Droulez%2CJ.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR60">
             Willsky, A. S. (2002). Multiresolution Markov models for signal and image processing.
             <i>
              Proceedings IEEE
             </i>
             ,
             <i>
              90
             </i>
             (8), 1396–1458.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/JPROC.2002.800717" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2FJPROC.2002.800717">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Multiresolution%20Markov%20models%20for%20signal%20and%20image%20processing&amp;journal=Proceedings%20IEEE&amp;doi=10.1109%2FJPROC.2002.800717&amp;volume=90&amp;issue=8&amp;pages=1396-1458&amp;publication_year=2002&amp;author=Willsky%2CA.%20S.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR61">
             Wu, B., Ooi, T. L., &amp; He, Z. J. (2004). Perceiving distance accurately by a directional process of integrating ground information.
             <i>
              Letters to Nature
             </i>
             ,
             <i>
              428
             </i>
             , 73–77.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1038/nature02350" href="https://doi-org.proxy.lib.ohio-state.edu/10.1038%2Fnature02350">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceiving%20distance%20accurately%20by%20a%20directional%20process%20of%20integrating%20ground%20information&amp;journal=Letters%20to%20Nature&amp;doi=10.1038%2Fnature02350&amp;volume=428&amp;pages=73-77&amp;publication_year=2004&amp;author=Wu%2CB.&amp;author=Ooi%2CT.%20L.&amp;author=He%2CZ.%20J.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR62">
             Zhang, R., Tsai, P.-S., Cryer, J. E., &amp; Shah, M. (1999). Shape from shading: a survey.
             <i>
              IEEE Transactions on Pattern Analysis and Machine Intelligence
             </i>
             ,
             <i>
              21
             </i>
             (8), 690–706.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1109/34.784284" href="https://doi-org.proxy.lib.ohio-state.edu/10.1109%2F34.784284">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Shape%20from%20shading%3A%20a%20survey&amp;journal=IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence&amp;doi=10.1109%2F34.784284&amp;volume=21&amp;issue=8&amp;pages=690-706&amp;publication_year=1999&amp;author=Zhang%2CR.&amp;author=Tsai%2CP.-S.&amp;author=Cryer%2CJ.%20E.&amp;author=Shah%2CM.">
              Google Scholar
             </a>
            </p>
           </li>
           <li class="c-reading-companion__reference-item">
            <p class="c-reading-companion__reference-citation u-font-family-serif" id="rc-ref-CR63">
             Zhao, W., Chellappa, R., Phillips, P. J., &amp; Rosenfield, A. (2003). Face recognition: a literature survey.
             <i>
              ACM Computing Surveys
             </i>
             ,
             <i>
              35
             </i>
             , 399–458.
            </p>
            <p class="c-reading-companion__reference-links">
             <a data-track="click" data-track-action="article reference" data-track-label="10.1145/954339.954342" href="https://doi-org.proxy.lib.ohio-state.edu/10.1145%2F954339.954342">
              Article
             </a>
             <a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="http://scholar.google.com/scholar_lookup?&amp;title=Face%20recognition%3A%20a%C2%A0literature%20survey&amp;journal=ACM%20Computing%20Surveys&amp;doi=10.1145%2F954339.954342&amp;volume=35&amp;pages=399-458&amp;publication_year=2003&amp;author=Zhao%2CW.&amp;author=Chellappa%2CR.&amp;author=Phillips%2CP.%20J.&amp;author=Rosenfield%2CA.">
              Google Scholar
             </a>
            </p>
           </li>
          </ol>
         </div>
        </div>
       </div>
      </div>
     </aside>
    </div>
   </div>
  </article>
  <div class="app-elements">
   <footer data-test="universal-footer">
    <div class="c-footer" data-track-component="unified-footer">
     <div class="c-footer__container">
      <div class="c-footer__grid c-footer__group--separator">
       <div class="c-footer__group">
        <h3 class="c-footer__heading">
         Discover content
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="journals a-z" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/journals/a/1">
           Journals A-Z
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="books a-z" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/books/a/1">
           Books A-Z
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading">
         Publish with us
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="publish your research" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/authors">
           Publish your research
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="open access publishing" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/open-research/about/the-fundamentals-of-open-access-and-open-research">
           Open access publishing
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading">
         Products and services
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="our products" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/products">
           Our products
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="librarians" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/librarians">
           Librarians
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="societies" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/societies">
           Societies
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="partners and advertisers" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/partners">
           Partners and advertisers
          </a>
         </li>
        </ul>
       </div>
       <div class="c-footer__group">
        <h3 class="c-footer__heading">
         Our imprints
        </h3>
        <ul class="c-footer__list">
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Springer" data-track-label="link" href="https://www-springer-com.proxy.lib.ohio-state.edu/">
           Springer
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Nature Portfolio" data-track-label="link" href="https://www-nature-com.proxy.lib.ohio-state.edu/">
           Nature Portfolio
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="BMC" data-track-label="link" href="https://www-biomedcentral-com.proxy.lib.ohio-state.edu/">
           BMC
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Palgrave Macmillan" data-track-label="link" href="https://www.palgrave.com/">
           Palgrave Macmillan
          </a>
         </li>
         <li class="c-footer__item">
          <a class="c-footer__link" data-track="click" data-track-action="Apress" data-track-label="link" href="https://www.apress.com/">
           Apress
          </a>
         </li>
        </ul>
       </div>
      </div>
     </div>
     <div class="c-footer__container">
      <nav aria-label="footer navigation">
       <ul class="c-footer__links">
        <li class="c-footer__item">
         <button class="c-footer__link" data-cc-action="preferences" data-track="click" data-track-action="Manage cookies" data-track-label="link">
          <span class="c-footer__button-text">
           Your privacy choices/Manage cookies
          </span>
         </button>
        </li>
        <li class="c-footer__item">
         <a class="c-footer__link" data-track="click" data-track-action="california privacy statement" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/legal/ccpa">
          Your US state privacy rights
         </a>
        </li>
        <li class="c-footer__item">
         <a class="c-footer__link" data-track="click" data-track-action="accessibility statement" data-track-label="link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/gp/info/accessibility">
          Accessibility statement
         </a>
        </li>
        <li class="c-footer__item">
         <a class="c-footer__link" data-track="click" data-track-action="terms and conditions" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/termsandconditions">
          Terms and conditions
         </a>
        </li>
        <li class="c-footer__item">
         <a class="c-footer__link" data-track="click" data-track-action="privacy policy" data-track-label="link" href="https://link-springer-com.proxy.lib.ohio-state.edu/privacystatement">
          Privacy policy
         </a>
        </li>
        <li class="c-footer__item">
         <a class="c-footer__link" data-track="click" data-track-action="help and support" data-track-label="link" href="https://support-springernature-com.proxy.lib.ohio-state.edu/en/support/home">
          Help and support
         </a>
        </li>
       </ul>
      </nav>
      <div class="c-footer__user">
       <p class="c-footer__user-info">
        <span data-test="footer-user-ip">
         3.128.143.42
        </span>
       </p>
       <p class="c-footer__user-info" data-test="footer-business-partners">
        OhioLINK Consortium (3000266689)  - Ohio State University Libraries (8200724141)
       </p>
      </div>
      <a class="c-footer__link" href="https://www-springernature-com.proxy.lib.ohio-state.edu/">
       <img alt="Springer Nature" height="20" loading="lazy" src="/oscar-static/images/darwin/footer/img/logo-springernature_white-64dbfad7d8.svg" width="200"/>
      </a>
      <p class="c-footer__legal" data-test="copyright">
       © 2023 Springer Nature
      </p>
     </div>
    </div>
   </footer>
  </div>
  <script nomodule="true" src="/oscar-static/js/app-es5-bundle-774ca0a0f5.js">
  </script>
  <script src="/oscar-static/js/app-es6-bundle-047cc3c848.js" type="module">
  </script>
  <script nomodule="true" src="/oscar-static/js/global-article-es5-bundle-e58c6b68c9.js">
  </script>
  <script src="/oscar-static/js/global-article-es6-bundle-c14b406246.js" type="module">
  </script>
  <div class="c-cookie-banner">
   <div class="c-cookie-banner__container">
    <p>
     This website sets only cookies which are necessary for it to function. They are used to enable core functionality such as security, network management and accessibility. These cookies cannot be switched off in our systems. You may disable these by changing your browser settings, but this may affect how the website functions. Please view our privacy policy for further details on how we process your information.
     <button class="c-cookie-banner__dismiss">
      Dismiss
     </button>
    </p>
   </div>
  </div>
 </body>
</html>
