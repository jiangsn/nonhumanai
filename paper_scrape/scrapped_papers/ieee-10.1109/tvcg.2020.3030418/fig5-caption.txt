Fig. 5. Cnn explainer helps users learn about the connection between the output layer and its previous layer via three tightly integrated views. users can smoothly transition between these views to gain a more holistic understanding of the output layer's [lifeboat] prediction computation. (a) the overview summarizes neurons and their connections. (b) the flatten elastic explanation view visualizes the often-overlooked flatten layer, helping users more easily understand how a high-dimensional max_pool_2 layer is connected to the 1-dimensional output layer. (c) the softmax interactive formula view further explains how the softmax function that precedes the output layer normalizes the penultimate computation results (i.e., logits) into class probabilities through linking the (c1) numbers from the formula to (c2) their visual representations within the model structure.