Fig. 2. 
An overview of the proposed 3D human pose machine framework. Our model predicts the 3D human poses for the given monocular image frames, and it progressively refines its predictions with the proposed self-supervised correction. Specifically, the estimated 2D pose p2dt with the corresponding pose representation f2dt for each frame of the input sequence is first obtained and further passed into two neural network modules: i) a 2D-to-3D pose transformer module for transforming the pose representations from the 2D domain to the 3D domain to intermediately predict the human joints p3dt in the 3D coordinates, and ii) a 3D-to-2D pose projector module to obtain the projected 2D pose p^2dt after regressing p_t^{3d}p3dt into \hat{p}_t^{3d}. Through minimizing the difference between p_t^{2d} and \hat{p}_t^{2d}, our model is capable of bidirectionally refining the regressed 3D poses \hat{p}_t^{3d} via the proposed self-supervised correction mechanism. Note that the parameters of the 2D-to-3D pose transformer module for all frames are shared to preserve the temporal motion coherence. 3K and 2K denotes the dimension of the vector for representing the 3D and 2D human pose formed by K skeleton joints, respectively.
