Fig. 1: Schematic view of the architecture of adversarial rl pcg (arlpcg). The model consists of two parts: one rl generator and one rl solver. The generator receives a reward depending on the performance of the solver as well as from the environment. The implicit reward (dashed) passed from solver to generator is merely conceptual as in practice all the rewards are passed from the environment. The auxiliary input is passed to both generator (as an observation) and the environment in order to let the environment adapt the reward function accordingly.