Figure 1: 
Natural adversarial examples from IMAGENET-A and IMAGENET-O. The black text is the actual class, and the red text is a ResNet-50 prediction and its confidence. IMAGENET-A contains images that classifiers should be able to classify, while IMAGENET-O contains anomalies of unforeseen classes which should result in low-confidence predictions. ImageNet-1K models do not train on examples from “Photosphere” nor “Verdigris” classes, so these images are anomalous. Most natural adversarial examples lead to wrong predictions despite occurring naturally.
