Figure 2. Illustration of our two-stream faster R-CNN network. The RGB stream models visual tampering artifacts, such as unusually high contrast along object edges, and regresses bounding boxes to the ground-truth. The noise stream first obtains the noise feature map by passing input RGB image through an SRM filter layer, and leverages the noise features to provide additional evidence for manipulation classification. The RGB and noise streams share the same region proposals from RPN network which only uses RGB features as input. The roi pooling layer selects spatial features from both RGB and noise streams. The predicted bounding boxes (denoted as ‘bbxpred’) are generated from RGB roi features. A bilinear pooling [23], [17] layer after roi pooling enables the network to combine the spatial co-occurrence features from the two streams. Finally, passing the results through a fully connected layer and a softmax layer, the network produces the predicted label (denoted as ‘cls_pred’) and determines whether predicted regions have been manipulated or not.