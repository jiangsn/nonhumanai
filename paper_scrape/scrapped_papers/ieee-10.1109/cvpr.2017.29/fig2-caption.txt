Figure 2. Learning 3DMatch from reconstructions. From existing RGB-D reconstructions (a), We extract local 3D patches and correspondence labels from scans of different views (b). We collect pairs of matching and non-matching local 3D patches and convert into a volumetric representation (c) To train a 3D convnet-based descriptor (d). This geometric descriptor can be used to establish correspondences for matching 3D geometry in various applications (e) Such as reconstruction, model alignment, and surface correspondence.