Figure 5. Analyzing the training of class-conditional LDMs with different downsampling factors f over 2\mathrm{M} train steps on the imagenet dataset. Pixel-based LDM-1 requires substantially larger train times compared to models with larger downsampling factors (LDM-\{4-16\}). Too much perceptual compression as in LDM-32 limits the overall sample quality. All models are trained on a single nvidia a100 with the same computational budget. Results obtained with 100 ddim steps [81] and \kappa=0.