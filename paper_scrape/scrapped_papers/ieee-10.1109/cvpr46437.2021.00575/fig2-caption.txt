Figure 2: 
Overview: Given an input image I0, our motion estimation network predicts a motion field M. Through Euler integration, M is used to generate future and past displacement fields F0→t and F0→t−N , which define the source pixel locations in all other frames t. To animate the input image using our estimated motion, we first use a feature encoder network to encode the image as a feature map D0. This feature map is warped by the displacement fields (using a novel symmetric splatting technique) to produce the corresponding warped feature map Dt. The warped features are provided to the decoder network to create the output video frame It.
