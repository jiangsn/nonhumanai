Figure 7. Reference-guided synthesis results on FFHQ with the model trained on celeba-hq. Despite the distribution gap between the two datasets, stargan v2 successfully extracts the style codes of the references and synthesizes faithful images. Nection between stochastic noise and the generated image for diversity, by marginal matching [1], latent regression [40], [13], and diversity regularization [35], [27]. Other approaches produce various outputs with the guidance of reference images [4], [5], [26], [32]. However, all theses methods consider only two domains, and their extension to multiple domains is non-trivial. Recently, FUNIT [24] tackles multi-domain image translation using a few reference images from a target domain, but it requires fine-grained class labels and can not generate images with random noise. Our method provides both latent-guided and reference-guided synthesis and can be trained with coarsely labeled dataset. In parallel work, yu et al. [37] tackle the same issue but they define the style as domain-shared characteristics rather than domain-specific ones, which limits the output diversity.