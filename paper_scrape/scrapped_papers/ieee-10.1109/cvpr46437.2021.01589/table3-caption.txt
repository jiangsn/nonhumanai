Table 3: 
Benchmarking on the High Quality Frames (HQF) DAVIS240 dataset. We do not fine-tune our method and other methods and use models provided by the authors. We evaluate methods on all sequences of the dataset. To compute SSIM and PSNR, we downsample the original video by skip 1 and 3 frames, reconstruct these frames and compare them to the skipped frames. In Uses frames and Uses events columns we specify if a method uses frames and events for interpolation. In the Color column, we indicate if a method works with color frames. In the table, we present two versions of our method: Time Lens-syn, which we trained only on synthetic data, and Time Lens-real, which we trained on synthetic data and fine-tuned on real event data from our own DAVIS346 camera. For SSIM and PSNR, we show mean and one standard deviation. We show the best result in each column in bold and the second-best using underscore text.
