Figure 2: 
Pseudo-ground truth generation. Left: We use a pretrained image-to-image translation model (SPADE [49]) to convert projected segmentation maps to images. Right: Sample input segmentation maps showing different labels (grass, trees, water, sand, sky) and SPADE outputs for different style codes. Note that some generated outputs can look unrealistic due to domain gap of the blocky segmentations and sampled camera poses, with the real image data used to train SPADE. Our method is designed to be robust to noise, varying styles, and inconsistencies present in these generated pseudo-ground truth images.
