Figure 5: (a) We measured the rate at which subjects chose an algorithm's synthesized sound over the actual sound. Our full system, which was pretrained from imagenet and used example-based synthesis to generate a waveform, significantly outperformed models based on image matching. For the neural network models, we computed the auditory metrics for the sound features that were predicted by the network, rather than those of the inverted sounds or transferred exemplars. (b) What sounds like what, according to our algorithm? we applied a classifier trained on real sounds to the sounds produced by our algorithm, resulting in a confusion matrix (c.f. Figure 3(b), which shows a confusion matrix for real sounds). It obtained 22.7% class-averaged accuracy. (c) Confusions made by a classifier trained on fc7 features (30.2% class-averaged accuracy). For both confusion matrices, we used the variation of our model that was trained from scratch.