Figure 3. 
Illustration of the rendering and refinement steps. Left: Our differentiable rendering stage takes a paired RGB image and disparity map from viewpoint P0 and creates a textured mesh representation, which we render from a new viewpoint P1, warping the textures, adjusting disparities, and returning a binary mask representing regions to fill in. Right: The refinement stage takes the output of the renderer and uses a deep network to fill in holes and add details. The output is a new RGB image and disparity map that can be supervised with reconstruction and adversarial losses.
