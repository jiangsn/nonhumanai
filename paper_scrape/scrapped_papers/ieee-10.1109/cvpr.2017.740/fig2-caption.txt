Figure 2: Given an input image (a) And a reference style image (e), the results (b) Of Gatys et al. [5] (neural style) and (c) Of Li et al. [10] (CNNMRF) present artifacts due to strong distortions when compared to (d) our result. In (f,g,h), we compute the correspondence between the output and the reference style where, for each pixel, we encode the XY coordinates of the nearest patch in the reference style image as a color with (R, G, B)=(0,255×Y /height, 255×X/ width). The nearest neural patch is found using the l2 norm on the neural responses of the VGG-19 conv3_1 layer, similarly to CNNMRF. Neural style computes global statistics of the reference style image which tends to produce texture mismatches as shown in the correspondence (f), e.g., parts of the sky in the output image map to the buildings from the reference style image. CNNMRF computes a nearest-neighbor search of the reference style image which tends to have many-to-one mappings as shown in the correspondence (g), e.g., see the buildings. In comparison, our result (d) prevents distortions and matches the texture correctly as shown in the correspondence (h).